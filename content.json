{"pages":[{"title":"about","text":"","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"linux上安装redis","text":"","link":"/2020/01/18/linux%E4%B8%8A%E5%AE%89%E8%A3%85redis/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post.Check documentation for more info. If you get any problems when using Hexo,you can find the answer introubleshootingor you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy 12345public class Student{ public static void main(String [] args){ System.out.println(\"Hello World\"); }} More info: Deployment","link":"/2020/01/17/hello/hello-world/"},{"title":"六、Mybatis中的# 和 $","text":"Mybatis中的# 和 $ 准备数据库12345678910111213141516171819202122232425262728SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for tb_role-- ----------------------------DROP TABLE IF EXISTS `tb_role`;CREATE TABLE `tb_role` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '角色id', `role_name` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '角色名称', `description` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '角色描述', `status` int(1) NOT NULL COMMENT '角色状态，0:启用，1:禁用', `create_time` datetime(0) NULL DEFAULT NULL COMMENT '创建时间', `create_user` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '创建人', `modify_time` datetime(0) NULL DEFAULT NULL COMMENT '修改时间', `modify_user` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '修改人', PRIMARY KEY (`id`) USING BTREE, INDEX `index_role_name`(`role_name`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ Records of tb_role-- ----------------------------INSERT INTO `tb_role` VALUES (1, 'admin', '超级管理员', 0, '2019-03-01 11:33:09', 'system', '2019-03-05 09:17:41', 'admin');INSERT INTO `tb_role` VALUES (2, 'develop', '开发人员', 0, '2019-03-01 17:19:55', 'admin', '2019-04-04 10:02:37', 'admin');INSERT INTO `tb_role` VALUES (3, 'testing', '用于测试人员测试', 0, '2019-03-01 22:14:33', 'admin', '2019-04-04 10:03:05', 'admin');INSERT INTO `tb_role` VALUES (5, 'guest', '运营', 1, '2019-03-16 10:59:38', 'admin', '2019-04-06 10:46:30', 'admin');INSERT INTO `tb_role` VALUES (6, 'root', 'root', 0, '2019-09-19 09:46:03', 'admin', '2019-09-19 09:55:25', 'admin'); ​ 本案例代码基于前面小节的整合案例，所以此处不再赘述整合代码，如有需要，可以参考前面的SSM整合。 $ 和 # 执行原理下面我们只讨论#{}与${}的差别. 使用#{}接收参数： 1select * from tb_role where role_name = #{roleName} 我们看一下上面sql的打印SQL结果： 使用${}接收参数： 1select * from tb_role where role_name = '${roleName}' 对应的SQL执行结果： 如上两个SQL的执行结果，可以看出： #{value} 会进行SQL预编译，即把参数替换成 ?占位符。 ${} 只是进行简单的字符串替换。 SQL 注入百度百科：所谓SQL注入，就是通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令 正是由于上述差别，${}可能会导致SQL注入，下面我们来看一下： 12-- 传入参数：a' or '1' = '1select * from tb_role where role_name = #{roleName} 执行结果如下，无法找到对应的数据： 而当我们使用${} : 12-- 传入参数：a' or '1' = '1select * from tb_role where role_name = '${roleName}' 所以，如果使用${} ，可以发现，sql注入是成功的，这样就把数据库中的所有数据，这里只是演示了查询的注入，最多可能会导致数据泄露，如果注入的是更新、删除操作，后果将不堪设想，所以，在这种情况下我们不能使用$ 来接收参数。 说明：我们使用 mybatis 编写 SQL 语句时，难免会使用模糊查询的方法，mybatis 提供了两种方式 #{} 和 ${} 。 #{value} 在预处理时，会把参数部分用一个占位符 ? 替代，其中 value 表示接受输入参数的名称。能有效解决 SQL 注入问题 ${} 表示使用拼接字符串，将接受到参数的内容不加任何修饰符拼接在 SQL 中，使用${}拼接 sql，将引起 SQL 注入问题。 少不了$​ 有些人看到前面的 ${} 会导致SQL注入问题，可能会认为，那以后的开发就不再使用 ${}了， 全部使用#{}.正所谓存在就有价值，所以，有些情况，${} 还是需要的使用的。 例如：当我们需要通过参数传递来指定排序字段的时候，我们需要使用${}. 12-- 参数：role_nameselect * from tb_role ORDER BY #{orderRoleName} 执行结果如下： 我们可以看出使用#{} 并没有进行排序，此时我们将其更换如下： 12-- 参数：role_nameselect * from tb_role ORDER BY ${orderRoleName} 执行结果： 说明： 如果需要动态的传递查询字段和排序字段等情况，我们需要使用$来进行字符串替换。 1select ${orderRoleName} from tb_role ORDER BY ${orderRoleName} 查询结果： 总结： 能使用#{}的地方，尽量使用 如查询字段，排序字段等，则需要使用${} 附：这里顺带提下防止sql注入的几种方式(可能不止这几种): (jdbc使用 PreparedStatement代替Statement， PreparedStatement 不仅提高了代码的可读性和可维护性.而且也提高了安全性，有效防止sql注入； 在程序代码中使用正则表达式过滤参数。使用正则表达式过滤可能造成注入的符号，如’ –等 在页面输入参数时也进行字符串检测和提交时进行参数检查，同样可以使用正则表达式，不允许特殊符号出现。 部分参考自:https://www.cnblogs.com/weixuqin/p/9522802.html","link":"/2020/01/18/SSM/mybatis/7Mybatis%E4%B8%AD%E7%9A%84%E4%BA%95%E5%92%8C%E6%98%9F/"},{"title":"三、Linux上安装单机版Nacos","text":"Linux上安装单机版Nacos 下载 地址:https://github.com/alibaba/nacos/releases 这里以下载.tar.gz版本为例： 上传并解压通过xftp等工具将下载包上传至LInux服务器上。 使用下列命令解压： 1tar -xvf nacos-server-1.1.3.tar.gz 配置数据持久化在conf目录下的application.properties的添加以下配置： 123456spring.datasource.platform = mysqldb.num = 1db.url.0 = jdbc:mysql://127.0.0.1:3306/nacos_devtest? characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=rootdb.password=root 启动进入bin目录下使用命令启动 1sh startup.sh -m standalone 后台启动 1sh startup.sh -m standalone &amp; 通过：127.0.0.1:8848/nacos 登录，使用nacos/nacos登录 通过命令查询Nacos启动进程 1ps -ef|grep nacos","link":"/2020/01/18/SSM/springcloudalibaba/0.3.Linux%E5%AE%89%E8%A3%85%E5%8D%95%E6%9C%BA%E7%89%88Nacos/"},{"title":"四、Nacos服务注册和发现","text":"Nacos服务注册和发现 依赖Nacos服务注册和发现的依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;0.9.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 项目结构本示例的项目结构如下： 服务提供者 服务提供方：是指提供可复用和可调用服务的应用方 使用Idea 的SpringBoot项目引导器创建SpringBoot项目 导入依赖123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;0.9.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 编写测试Controller12345678910111213141516@SpringBootApplication@EnableDiscoveryClient //启动服务注册发现public class ServiceProviderApplication { public static void main(String[] args) { SpringApplication.run(ServiceProviderApplication.class, args); } @RestController class EchoController { @RequestMapping(value = \"/echo/{string}\", method = RequestMethod.GET) public String echo(@PathVariable String string) { return \"Hello Nacos Discovery \" + string; } }} 注意：使用@EnableDiscoveryClient 注解来启用服务注册发现机制。 配置properties123server.port= 8070spring.application.name= service-providerspring.cloud.nacos.discovery.server-addr= 127.0.0.1:8848 服务消费者 服务消费者：是指会发起对某个服务调用的应用方 导入依赖这里没有什么不同，与服务提供者是一样的。 12345678910111213141516&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;0.9.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 编写消费服务示例123456789101112131415161718192021222324252627282930313233343536373839404142package com.ooyhao.serviceconsumer;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;@SpringBootApplication@EnableDiscoveryClientpublic class ServiceConsumerApplication { public static void main(String[] args) { SpringApplication.run(ServiceConsumerApplication.class, args); } @LoadBalanced @Bean public RestTemplate restTemplate() { return new RestTemplate(); } @RestController public class TestController { private final RestTemplate restTemplate; @Autowired public TestController(RestTemplate restTemplate) {this.restTemplate = restTemplate;} @RequestMapping(value = \"/echo/{str}\", method = RequestMethod.GET) public String echo(@PathVariable String str) { return restTemplate.getForObject(\"http://service-provider/echo/\" + str, String.class); } }} 这里使用RestTemplate进行调用，可以看出，此时这里可以看到使用的是服务名称 service-provider . 而不是使用IP地址。这也是服务注册中心的存在的重要意义，我们不需要知道服务提供方的IP地址，而只需要知道服务名，将IP地址和服务名的映射关系交给注册中心去动态维护，这样，如果同一个服务的IP地址变了，我们也不需要修改服务器消费者。 配置properties123server.port=8080spring.application.name= service-consumerspring.cloud.nacos.discovery.server-addr=127.0.0.1:8848 启动服务提供者和消费者项目。 我们可以使用spring.cloud.nacos.discovery.enabled=false 来禁用。 查询服务列表此时我们再查询服务列表，如图所示,服务提供者和服务消费者已经成功注册到服务注册中心了。 测试服务调用访问localhost:8080/echo/HelloNacos,结果如下： 此时，简单的服务注册和发现已经测试成功了。So Easy 有不有！ 更多配置信息 https://spring-cloud-alibaba-group.github.io/github-pages/greenwich/spring-cloud-alibaba.html#_more_information_about_nacos_discovery_starter_configurations","link":"/2020/01/18/SSM/springcloudalibaba/1.Nacos%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%92%8C%E5%8F%91%E7%8E%B0/"},{"title":"二、Docker安装单机版Nacos","text":"Docker安装单机版Nacos 安装wget1234# 安装wgetyum install wget# 查询版本wget --version 安装Git1234# 安装gityum install git# 查询git版本git --version 安装curl 部分参考：https://www.cnblogs.com/suidouya/p/7387861.html 获取安装包，从网上直接下载或者其他途径，这里使用wget 1wget https://curl.haxx.se/download/curl-7.55.1.tar.gz 解压安装包 1tar -zxf curl-7.55.1.tar.gz 进入解压后的包 1cd curl-7.55.1 配置，指定安装路径，这里是/usr/local/curl 12./configure --prefix=/usr/local/curlmake 安装 1sudo make install 查询版本 1curl --version 安装docker-compose 方式一 1234567curl -L https://github.com/docker/compose/releases/download/1.24.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose# 修改权限chmod +x /usr/local/bin/docker-compose# 查询版本docker-compose version 方式二 12345yum -y install epel-releaseyum -y install python-pippip --versionpip install docker-composedocker-compose version 安装Nacos clone项目 12git clone https://github.com/nacos-group/nacos-docker.gitcd nacos-docker 单机模式MySQL 1docker-compose -f example/standalone-mysql.yaml up 启动时出现权限异常异常可以使用sudo -i 12345678#查看SELinux状态（如果SELinux status参数为enabled即为开启状态）/usr/sbin/sestatus -v #临时关闭setenforce 0#修改配置文件重启机器禁用（将SELINUX=enforcing改为SELINUX=disabled）vim /etc/selinux/config","link":"/2020/01/18/SSM/springcloudalibaba/0.2.Docker%E5%AE%89%E8%A3%85%E5%8D%95%E6%9C%BA%E7%89%88Nacos/"},{"title":"十四、unable to find local peer 172.16.26.250:8848","text":"问题描述 当我在虚拟机搭建成集群之后，（单机的虚拟机需要注意配置局域网IP而不要配置127.0.0.1）。打算拿三台实际的云服务器来搭建一台可以用于生产的Nacos集群. 但是遇到了一些问题：主要异常如下： 123456789101112131415161718java.lang.IllegalStateException: unable to find local peer: 172.16.26.250:8848, all peers: [120.79.167.88:8848, 119.23.104.130:8848, 47.101.47.127:8848] at com.alibaba.nacos.naming.consistency.persistent.raft.RaftPeerSet.local(RaftPeerSet.java:224) at com.alibaba.nacos.naming.monitor.PerformanceLoggerThread.collectMetrics(PerformanceLoggerThread.java:100) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84) at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54) at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:93) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)2019-10-18 14:06:45,000 ERROR Unexpected error occurred in scheduled task. 这个日志是从logs/nacos.log中查询到的。我们在部署的时候，可以关注一下下列三个日志文件： 123logs/nacos.loglogs/naming-raft.loglogs/start.out 主要是查看nacos.log日志。一开始启动三个节点，均没有出错，但是在控制页面的节点列表中一直无法显示出节点信息。所以我怀疑没有真正搭建成功，于是从网上得知查询启动日志的文件，如上。发现nacos读取的是内网IP，但是在集群列表中不存在这个IP，所以报异常。网上大部分的集群ip都是在一个网段的，直接配置外网ip都是可以搭建成功，我按照这个方式一致搭建不成功。后面参考了下面这篇文章，修改启动配置，才得以搭建成功。 https://www.wandouip.com/t5i278697/ 结果如下： 解决方案修改每个节点的startup.sh启动文件 123456789101112131415161718#===========================================================================================# JVM Configuration#===========================================================================================if [[ \"${MODE}\" == \"standalone\" ]]; then JAVA_OPT=\"${JAVA_OPT} -Xms512m -Xmx512m -Xmn256m\" JAVA_OPT=\"${JAVA_OPT} -Dnacos.standalone=true\"else JAVA_OPT=\"${JAVA_OPT} -server -Xms512m -Xmx512m -Xmn256m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\" JAVA_OPT=\"${JAVA_OPT} -XX:-OmitStackTraceInFastThrow -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=${BASE_DIR}/logs/java_heapdump.hprof\" JAVA_OPT=\"${JAVA_OPT} -XX:-UseLargePages\" JAVA_OPT=\"${JAVA_OPT} -Dnacos.server.ip=120.79.167.88\"fiif [[ \"${FUNCTION_MODE}\" == \"config\" ]]; then JAVA_OPT=\"${JAVA_OPT} -Dnacos.functionMode=config\"elif [[ \"${FUNCTION_MODE}\" == \"naming\" ]]; then JAVA_OPT=\"${JAVA_OPT} -Dnacos.functionMode=naming\"fi 添加这一行：JAVA_OPT=&quot;${JAVA_OPT} -Dnacos.server.ip=120.79.167.88&quot; ip分别改为对应主机的外网IP即可。 我们也查询一下源码： 在config模块下，utils/SystemConfig.java中。 12345678910111213141516171819202122232425262728293031public class SystemConfig { public static final String LOCAL_IP = getHostAddress(); private static final Logger log = LoggerFactory.getLogger(SystemConfig.class); private static String getHostAddress() { String address = System.getProperty(\"nacos.server.ip\"); if (StringUtils.isNotEmpty(address)) { return address; } else { address = \"127.0.0.1\"; } try { Enumeration&lt;NetworkInterface&gt; en = NetworkInterface.getNetworkInterfaces(); while (en.hasMoreElements()) { NetworkInterface ni = en.nextElement(); Enumeration&lt;InetAddress&gt; ads = ni.getInetAddresses(); while (ads.hasMoreElements()) { InetAddress ip = ads.nextElement(); // 兼容集团不规范11网段 if (!ip.isLoopbackAddress() &amp;&amp; ip.getHostAddress().indexOf(\":\") == -1 /* &amp;&amp; ip.isSiteLocalAddress() */) { return ip.getHostAddress(); } } } } catch (Exception e) { log.error(\"get local host address error\", e); } return address; }} 读取nacos.server.ip 的值。 停节点将130节点停止之后，会选择一个先的leader节点 88. 我们再把130节点启动起来：可以方式，130节点并不会恢复之前的leader节点，而是变为了follower节点。","link":"/2020/01/18/SSM/springcloudalibaba/11.Nacos%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E5%BC%82%E5%B8%B8/"},{"title":"十五、安装sentinel控制台","text":"前面我们结束了nacos的注册中心和配置中心的基础知识，以及Ribbon和Feign的简单使用，接下来我们学习一下alibaba的流量防卫兵–sentinel。在使用sentinel之前，我们先安装一下sentinel的管理控制台– sentinel-dashboard 。 下载 地址:https://github.com/alibaba/Sentinel/releases 当前最新版本是1.6.3，我们下载这个jar包。 启动注意：sentinel控制台需要在JDK 1.8+的版本上运行。 使用下列命令启动： 1java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar 如果我们需要修改端口，其中 -Dserver.port=8080 用于指定 Sentinel 控制台端口为 8080。需要注意，我们启动的时候需要使用绝对路径来启动，如果sentinel-dashboard.jar像我一样放置于/data/soft/sentinel ,那么启动命令为： 1java -Dserver.port=8082 -Dcsp.sentinel.dashboard.server=localhost:8082 -Dproject.name=sentinel-dashboard -jar /data/soft/sentinel/sentinel-dashboard-1.6.3.jar &amp; &amp; 表示后台启动应用。并且将端口修改为了8082.默认登录用户名和密码为：sentinel/sentinel; 修改登录信息 https://github.com/alibaba/Sentinel/wiki/%E6%8E%A7%E5%88%B6%E5%8F%B0#%E9%89%B4%E6%9D%83 如果需要自定义登录用户名和密码等信息可以参考上面的文档； 用户可以通过如下参数进行配置： -Dsentinel.dashboard.auth.username=sentinel 用于指定控制台的登录用户名为 sentinel； -Dsentinel.dashboard.auth.password=123456 用于指定控制台的登录密码为 123456；如果省略这两个参数，默认用户和密码均为 sentinel； -Dserver.servlet.session.timeout=7200 用于指定 Spring Boot 服务端 session 的过期时间，如 7200 表示 7200 秒；60m 表示 60 分钟，默认为 30 分钟； 我们可以下载到源码包，修改相应的配置。如下： 效果： 登录：sentinel / sentinel","link":"/2020/01/18/SSM/springcloudalibaba/12.%E5%AE%89%E8%A3%85sentinel%E6%8E%A7%E5%88%B6%E5%8F%B0/"},{"title":"十三、Nacos集群部署","text":"前面已经学习了Nacos的注册中心功能以及分布式配置中心的各个功能。在前一节我们知道了如何实现Nacos的数据持久化（其实在安装的时候就有涉及到）。前面为了方便演示和测试，使用的都是单机版，而没有实现集群搭建。但是在分布式架构中，微服务解决方案里，都是要满足三大特性：高并发，高性能，高可用。所以，单机版本的Nacos(注册中心&amp;配置中心)已经不够满足实际场景了，所以本节来搭建一个Nacos集群。 集群部署架构图我们看看nacos官网的介绍： 因此开源的时候推荐用户把所有服务列表放到一个vip下面，然后挂到一个域名下面 http://ip1:port/openAPI 直连ip模式，机器挂则需要修改ip才可以使用。 http://VIP:port/openAPI 挂载VIP模式，直连vip即可，下面挂server真实ip，可读性不好。 http://nacos.com:port/openAPI 域名 + VIP模式，可读性好，而且换ip方便，推荐模式 预备环境 64 bit的 linux/unix/mac，推荐使用Linux。 64 bit的 JDK 1.8+。 Maven 3.2.x+。 3个或3个以上Nacos节点才能构成集群。 单机部署集群我们准备已经下载好的Nacos压缩包，并解压，配置好mysql数据连接（可参考前一节）。 在Nacos的conf 目录下有一个cluster.conf.example , 可以直接把.example 去掉使用，也可以单独创建一个cluster.conf文件,用于后续搭建集群的实例地址配置。 我们打开cluster.conf， 删除默认配置，添加下述配置： 1234#it is ip192.168.1.104:8085192.168.1.104:8086192.168.1.104:8087 需要保证部署3个或3个以上节点，这样才能搭建成集群。注意ip不可填写127.0.0.1，必须是内网ip，否则在nacos.log中会报 1java.lang.IllegalStateException: unable to find local peer 修改完cluster.conf之后，我们将bin/startup.sh 复制三份，分别命名为： 123startup-8085.shstartup-8086.shstartup-8087.sh 然后分别打开这三个文件，进行修改，如下： 我们可以看到： 设置相应的启动端口。 如果内存不够，设置不同的内容。 8087就不展示了，分别启动 123sh startup-8085.shsh startup-8086.shsh startup-8087.sh 然后选择其中一个端口进行登录，可以看到集群管理的节点列表中就有了节点信息，可以看到节点状态。如下图： 192.168.1.104:8087 为leader节点，192.168.1.104:8085/8086 为Follower节点。 生产部署集群生产环境部署集群，无非就是将不同的节点部署到不同的服务器上，这样不会因为一台服务器宕机而导致整个Nacos集群不可用。 第一步：修改cluster.conf文件，三个节点均需要配置 123120.79.167.88:8848119.23.104.130:884847.101.47.127:8848 第二步：修改application.properties 文件，配置数据源，三个节点均要 12345spring.datasource.platform = mysqldb.num = 1db.url.0 = jdbc:mysql://120.79.167.xxx:3306/nacos_devtest?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=rootdb.password=pwd 第三步：分别启动每个节点的startup.sh 1sh startup.sh 注意：如果服务器内存不足，需要先修改startup.sh . 结果如图： 依照上述的配置，如果没有部署成功，请看下一节【Nacos集群部署异常】。我自己按照上述的生产部署也没有成功。","link":"/2020/01/18/SSM/springcloudalibaba/10.Nocos%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"title":"十六、连接sentinel控制台并实现限流","text":"连接sentinel控制台并实现限流 连接sentinel控制台我们这里依赖之前 依赖12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置文件12345678910spring: cloud: sentinel: transport: dashboard: 192.168.56.101:8080 port: 8719 application: name: sentinel-simpleserver: port: 8081 说明： spring.cloud.sentinel.transport.dashboard 来配置连接sentinel控制台的 ip:port； port: 默认是8719，这是端口是配置与sentinel dashboard来实时通信端口； server.port : 是当前项目的端口。 Controller我们先简单编写一个测试的controller，来测试连接sentinel控制台的效果： 1234567@RestControllerpublic class TestController { @GetMapping(value = \"/hello\") public String hello() { return \"Hello Sentinel\"; }} 下面我们通过在控制台使用curl命令或是在浏览器访问几次 http://localhost:8081/hello 。 1curl http://localhost:8081/hello sentinel控制台效果实时监控： 机器列表： 限流配置下面我们利用sentinel 的dashboard管理页面来配置流控规则： 我们点击簇点链路菜单，选择我们当前的/hello 接口的流控 按钮，配置相应的流控规则： 我们通过流控规则添加页面添加一条针对/hello 的流控规则. 阈值类型： 线程数：顾名思义就是当前接口的并发数。 QPS：Queries Per Second,中文就是，每秒查询数。 当前我们将单机阈值的值设置为2.下面我们测试一下： 我们通过测试可以发现，当我们快速的访问接口时，在一秒之内的第三次访问会自动被sentinel限制，返回默认值Blocked by Sentinel (flow limiting) .我们可以再看一下流控规则 的页面：","link":"/2020/01/18/SSM/springcloudalibaba/13.%E8%BF%9E%E6%8E%A5sentinel%E5%B9%B6%E9%99%90%E6%B5%81/"},{"title":"二十、Sentinel规则之熔断降级规则","text":"Sentinel规则之热点参数限流规则 文档： https://github.com/alibaba/Sentinel/wiki/%E7%83%AD%E7%82%B9%E5%8F%82%E6%95%B0%E9%99%90%E6%B5%81 概述何为热点？热点即经常访问的数据。很多时候我们希望统计某个热点数据中访问频次最高的 Top K 数据，并对其访问进行限制。比如： 商品 ID 为参数，统计一段时间内最常购买的商品 ID 并进行限制 用户 ID 为参数，针对一段时间内频繁访问的用户 ID 进行限制 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流。热点参数限流可以看做是一种特殊的流量控制，仅对包含热点参数的资源调用生效。 Sentinel 利用 LRU 策略统计最近最常访问的热点参数，结合令牌桶算法来进行参数级别的流控。 热点参数规则热点参数规则（ParamFlowRule）类似于流量控制规则（FlowRule）： 属性 说明 默认值 resource 资源名，必填 count 限流阈值，必填 grade 限流模式 QPS 模式 durationInSec 统计窗口时间长度（单位为秒），1.6.0 版本开始支持 1s controlBehavior 流控效果（支持快速失败和匀速排队模式），1.6.0 版本开始支持 快速失败 maxQueueingTimeMs 最大排队等待时长（仅在匀速排队模式生效），1.6.0 版本开始支持 0ms paramIdx 热点参数的索引，必填，对应 SphU.entry(xxx, args) 中的参数索引位置 paramFlowItemList 参数例外项，可以针对指定的参数值单独设置限流阈值，不受前面 count 阈值的限制。仅支持基本类型和字符串类型 clusterMode 是否是集群参数流控规则 false clusterConfig 集群流控相关配置 上面都是摘抄子官方网站，下面使用代码来测试。 我们先看一下热点参数规则的源码： 12345678910111213141516171819202122232425262728293031323334public class ParamFlowRule extends AbstractRule { //限流模式 private int grade = RuleConstant.FLOW_GRADE_QPS; //热点参数的索引 private Integer paramIdx; //The threshold count. private double count; //流控效果 private int controlBehavior = RuleConstant.CONTROL_BEHAVIOR_DEFAULT; //最大排队等待时长 private int maxQueueingTimeMs = 0; private int burstCount = 0; //统计窗口时间长度 private long durationInSec = 1; //参数的额外项，可以针对指定的参数值单独设置限流阈值，不受前面的count影响，仅支持基本数据类型和字符串 private List&lt;ParamFlowItem&gt; paramFlowItemList = new ArrayList&lt;ParamFlowItem&gt;(); //额外参数 private Map&lt;Object, Integer&gt; hotItems = new HashMap&lt;Object, Integer&gt;(); //是否是集群参数流控规则 默认是false private boolean clusterMode = false; private ParamFlowClusterConfig clusterConfig;}public class ParamFlowItem { private String object;//参数值 private Integer count;//限流阈值 private String classType;//参数类型} 实验初始化规则123456789101112131415161718192021222324252627282930public static void initParamFlowRule(){ List&lt;ParamFlowRule&gt; rules = new ArrayList&lt;&gt;(); ParamFlowRule rule = new ParamFlowRule(); //阈值类型：只支持QPS rule.setGrade(RuleConstant.FLOW_GRADE_QPS); //阈值 rule.setCount(1); //资源名 rule.setResource(\"test\"); rule.setParamIdx(0);//指配热点参数的下标 //统计窗口时间长度 rule.setDurationInSec(10); List&lt;ParamFlowItem&gt; items = new ArrayList&lt;&gt;(); ParamFlowItem item = new ParamFlowItem(); item.setClassType(String.class.getTypeName()); item.setCount(2); item.setObject(\"123456\");//需要统计的值 ParamFlowItem item1 = new ParamFlowItem(); item1.setClassType(int.class.getName()); item1.setCount(3); item1.setObject(\"12\"); items.add(item); items.add(item1); rule.setParamFlowItemList(items); rules.add(rule); ParamFlowRuleManager.loadRules(rules);} 上述初始化规则代码相当于按如下在控制台页面配置 ： 逻辑代码1234567891011121314151617181920212223242526272829@GetMapping(\"/test\")public String test( @RequestParam(\"username\") String username, @RequestParam(\"password\") String password, @RequestParam(\"age\") int age) { String echo = echoService.test(username,password,age); SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss:SSS\"); System.out.println(echo+\" | t:\"+dateFormat.format(new Date())); return \"访问成功\";}public interface EchoService { String test(String username, String password, int age);}@Servicepublic class EchoServiceImpl implements EchoService { @Override @SentinelResource(value = \"test\",blockHandler = \"handleBlockForTest\") public String test(String username,String password, int age) { return \"username:\"+username +\" password:\"+password + \" age:\"+age; } public String handleBlockForTest(String username, String password,int age, BlockException e){ return \"username:\"+username +\" password:\"+password +\" age:\"+age+\" e:\"+e.getClass().getSimpleName(); }} 测试112localhost:8083/test?username=admin&amp;password=123456&amp;age=12参数索引设置为：0 如果使用上述路径测试，结果为： 可以看出，passed的数量为1条，所以有效的阈值为1，统计的热点参数是username。 测试212localhost:8083/test?username=admin&amp;password=123456&amp;age=12参数索引设置为：1 可以看出，passed的数量为2条，所以有效的阈值为2，统计的热点参数，由于上面设置的为1，所以为password。 我们将password的123456修改一下，设置为12345，测试结果如下： passed的条数为1条，所以在额外的参数不匹配时，阈值还原到了第一个热点参数：username。 总结热点参数限流规则主要是针对请求参数来统计，并实现限流的。首先热点参数是基于QPS统计，如果参数索引设置为0，则以第一个参数统计为准，阈值也是按照基本参数中的阈值来控制的，但是指定的是额外的参数列表的下标，则需要提供指定的热点参数的值，如果当前访问的参数与预设定的参数不一致，依旧与第一个参数的阈值为准。","link":"/2020/01/18/SSM/springcloudalibaba/17.sentinel%E8%A7%84%E5%88%99%E4%B9%8B%E7%83%AD%E7%82%B9%E5%8F%82%E6%95%B0%E9%99%90%E6%B5%81%E8%A7%84%E5%88%99/"},{"title":"二十二、SpringCloud Gateway 的初体验","text":"SpringCloud Gateway 的初体验 引入gateway12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;groupId&gt;com.ooyhao&lt;/groupId&gt; &lt;artifactId&gt;gateway&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Greenwich.SR1&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 配置文件配置映射123456789101112spring: application: name: spring-cloud-gateway cloud: gateway: routes: - id: 163_route uri: http://www.163.com/ predicates: - Path=/163server: port: 8080 配置文件配置映射123456789101112131415/** * @author hao.ouYang * @create 2019-10-25 11:38 */@Configurationpublic class RouteConfig { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder){ return builder.routes() .route(\"ooyhao_route\",r -&gt; r.path(\"/164\") .uri(\"http://www.163.com/\")) .build(); }} 测试： 当我使用https://localhost:8080/163 和 https://localhost:8080/164访问时，都可以转发到https://www.163.com. 效果如下： 总结这一节主要是简单尝试一下SpringCloud Gateway的使用，利用配置属性文件和配置类的方式来实现路径转发，这是就可以实现屏蔽真实路径的效果。","link":"/2020/01/18/SSM/springcloudalibaba/20.gateway%E7%9A%84%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"title":"二十一、Sentinel规则之黑白名单规则","text":"很多时候，我们需要根据调用方来限制资源是否通过，这时候可以使用 Sentinel 的黑白名单控制的功能。黑白名单根据资源的请求来源（origin）限制资源是否通过，若配置白名单则只有请求来源位于白名单内时才可通过；若配置黑名单则请求来源位于黑名单时不通过，其余的请求通过。 调用方信息通过 ContextUtil.enter(resourceName, origin) 方法中的 origin 参数传入 规则配置黑白名单规则（AuthorityRule）非常简单，主要有以下配置项： resource：资源名，即限流规则的作用对象 limitApp：对应的黑名单/白名单，不同 origin 用 , 分隔，如 appA,appB strategy：限制模式，AUTHORITY_WHITE 为白名单模式，AUTHORITY_BLACK 为黑名单模式，默认为白名单模式 源码1234public class AuthorityRule extends AbstractRule { //Mode: 0 for whitelist; 1 for blacklist. private int strategy = RuleConstant.AUTHORITY_WHITE;} 实验这个规则比前面的规则都更加简单，而且更加容易理解： 12345678910111213141516171819202122232425public static void testAuthorityRuleWithWhite() { ContextUtil.enter(\"entrance1\",\"App3\"); Entry entry = null; try { entry = SphU.entry(\"login\"); System.out.println(\"访问通过！\"); } catch (BlockException e) { System.out.println(\"访问受限！\"); } finally { if (entry != null) { entry.exit(); } }}public static void initAuthorityRule() { List&lt;AuthorityRule&gt; rules = new ArrayList&lt;&gt;(); AuthorityRule rule = new AuthorityRule(); rule.setResource(\"login\"); //配置白名单 rule.setStrategy(RuleConstant.AUTHORITY_WHITE); rule.setLimitApp(\"App1,App2\"); rules.add(rule); AuthorityRuleManager.loadRules(rules);} 上面代码测试结果为：访问受限！ 通过Strategy 来设置规则策略，白名单和黑名单。 通过LimitApp 来配置白名单列表或黑名单列表。多个之间使用逗号隔开。 上面的初始化规则在页面显示如下：","link":"/2020/01/18/SSM/springcloudalibaba/18.sentinel%E8%A7%84%E5%88%99%E4%B9%8B%E9%BB%91%E7%99%BD%E5%90%8D%E5%8D%95%E8%A7%84%E5%88%99/"},{"title":"二十五、Gateway全局过滤器","text":"全局过滤器GlobalFilte 接口与 GatewayFilter 具有相同的签名，这些特定的过滤器有条件的应用到所有的路由上。 https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.0.RC1/reference/html/#global-filters 组合使用GlobalFilter和GatewayFilter当请求进来的时候，过滤器Web处理器将会将所有的GlobalFilter 实例和所有特定的GatewayFilter 路由实例添加到过滤器filter链中，该组合的过滤器按org.springframework.core.Ordered接口排序，通过实现getOrder()方法来设置。 由于Spring Cloud Gateway 区分了过滤器逻辑执行器的”前”阶段和”后”阶段，因此优先级最高的过滤器在pre 阶段中处于第一个，而在post 阶段处于最后一个。 CustomGlobalFilter.java 123456789101112public class CustomGlobalFilter implements GlobalFilter,Ordered { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { return chain.filter(exchange); } @Override public int getOrder() { return 0; }} 注意：数值越小，越靠前执行。 LoadBalancerClient 将LoadBalancerClientFilter在交换属性查找一个URI ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR。如果url有一个lb方案（即lb://myservice），它将使用Spring Cloud LoadBalancerClient将名称（myservice在前面的示例中）解析为实际的主机和端口，并在同一属性中替换URI。未经修改的原始url将附加到ServerWebExchangeUtils.GATEWAY_ORIGINAL_REQUEST_URL_ATTR属性中的列表。过滤器还将在ServerWebExchangeUtils.GATEWAY_SCHEME_PREFIX_ATTR属性中查找是否相等lb，然后应用相同的规则 application.yaml 12345678spring: cloud: gateway: routes: - id: myRoute uri: lb://service predicates: - Path=/service/** 上面的介绍难以理解，其实通过代码可以看出，就是使用lb 来指定是否使用ribbon负载均衡。可以发现，这里Gateway也是使用ribbon来实现负载均衡的。 默认情况下，当一个服务示例不能被LoadBalancer发现,将会返回503, 我们可以配置spring.cloud.gateway.loadbalancer.use404 = false 来使得Gateway返回404. 我们建议使用ReactiveLoadBalancerClientFilter。您可以通过设置spring.cloud.loadbalancer.ribbon.enabled的值为false来使用ReactiveLoadBalancerClientFilter. ReactiveLoadBalancerClientFilter如上，见识使用这个，只需要将spring.cloud.loadbalancer.ribbon.enabled设置为false就可以了。 Sentinel 整合Gateway12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-sentinel-gateway&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116/** * @author hao.ouYang * @create 2019-10-29 14:15 */@Configurationpublic class GatewayConfiguration { private final List&lt;ViewResolver&gt; viewResolvers; private final ServerCodecConfigurer serverCodecConfigurer; public GatewayConfiguration(ObjectProvider&lt;List&lt;ViewResolver&gt;&gt; viewResolversProvider, ServerCodecConfigurer serverCodecConfigurer) { this.viewResolvers = viewResolversProvider.getIfAvailable(Collections::emptyList); this.serverCodecConfigurer = serverCodecConfigurer; }// 这两个在SentinelSCGAutoConfiguration已经配置好了 /*@Bean @Order(Ordered.HIGHEST_PRECEDENCE) public SentinelGatewayBlockExceptionHandler sentinelGatewayBlockExceptionHandler() { return new SentinelGatewayBlockExceptionHandler(viewResolvers, serverCodecConfigurer); } @Bean @Order(-1) public GlobalFilter sentinelGatewayFilter() { return new SentinelGatewayFilter(); }*/ /*@PostConstruct public void doInit() { initCustomizedApis(); initGatewayRules(); }*/ /*可以使用管理控制台进行管理*/ /*初始化自定义的Api*/ private void initCustomizedApis() { Set&lt;ApiDefinition&gt; definitions = new HashSet&lt;&gt;(); // some_customized_api api名称 ApiDefinition api1 = new ApiDefinition(\"some_customized_api\") .setPredicateItems(new HashSet&lt;ApiPredicateItem&gt;() {{ add(new ApiPathPredicateItem().setPattern(\"/ahas\")); add(new ApiPathPredicateItem().setPattern(\"/product/**\") .setMatchStrategy(SentinelGatewayConstants.URL_MATCH_STRATEGY_PREFIX)); }}); ApiDefinition api2 = new ApiDefinition(\"another_customized_api\") .setPredicateItems(new HashSet&lt;ApiPredicateItem&gt;() {{ add(new ApiPathPredicateItem().setPattern(\"/**\") .setMatchStrategy(SentinelGatewayConstants.URL_MATCH_STRATEGY_PREFIX)); }}); definitions.add(api1); definitions.add(api2); GatewayApiDefinitionManager.loadApiDefinitions(definitions); } /*初始化网关流控规则*/ private void initGatewayRules() { Set&lt;GatewayFlowRule&gt; rules = new HashSet&lt;&gt;(); rules.add(new GatewayFlowRule(\"aliyun_route\") .setCount(10) .setIntervalSec(1) ); rules.add(new GatewayFlowRule(\"aliyun_route\") .setCount(2) .setIntervalSec(2) .setBurst(2) .setParamItem(new GatewayParamFlowItem() .setParseStrategy(SentinelGatewayConstants.PARAM_PARSE_STRATEGY_CLIENT_IP) ) ); rules.add(new GatewayFlowRule(\"httpbin_route\") .setCount(10) .setIntervalSec(1) .setControlBehavior(RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER) .setMaxQueueingTimeoutMs(600) .setParamItem(new GatewayParamFlowItem() .setParseStrategy(SentinelGatewayConstants.PARAM_PARSE_STRATEGY_HEADER) .setFieldName(\"X-Sentinel-Flag\") ) ); rules.add(new GatewayFlowRule(\"httpbin_route\") .setCount(1) .setIntervalSec(1) .setParamItem(new GatewayParamFlowItem() .setParseStrategy(SentinelGatewayConstants.PARAM_PARSE_STRATEGY_URL_PARAM) .setFieldName(\"pa\") ) ); rules.add(new GatewayFlowRule(\"httpbin_route\") .setCount(2) .setIntervalSec(30) .setParamItem(new GatewayParamFlowItem() .setParseStrategy(SentinelGatewayConstants.PARAM_PARSE_STRATEGY_URL_PARAM) .setFieldName(\"type\") .setPattern(\"warn\") .setMatchStrategy(SentinelGatewayConstants.PARAM_MATCH_STRATEGY_CONTAINS) ) ); rules.add(new GatewayFlowRule(\"some_customized_api\") .setResourceMode(SentinelGatewayConstants.RESOURCE_MODE_CUSTOM_API_NAME) .setCount(5) .setIntervalSec(1) .setParamItem(new GatewayParamFlowItem() .setParseStrategy(SentinelGatewayConstants.PARAM_PARSE_STRATEGY_URL_PARAM) .setFieldName(\"pn\") ) ); GatewayRuleManager.loadRules(rules); }}","link":"/2020/01/18/SSM/springcloudalibaba/23.gateway%E5%85%A8%E5%B1%80%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"title":"二十六、Gateway 配置实例","text":"Gateway 配置实例 开启微服务名称转发123456789101112131415161718192021spring: application: name: SERVICE-GATEWAY cloud: nacos: discovery: server-addr: 120.79.167.88:8848 namespace: 0a1c17ae-b270-470f-881d-18e22e1e3e20 service: ${spring.application.name} sentinel: transport: dashboard: 127.0.0.1:8080 port: 8719 gateway: loadbalancer: use404: true# 以下使用服务名自动转发的方式，可以自动实现LoadBalancer discovery: locator: enabled: true # 开启根据服务名称自动转发 lower-case-service-id: true # 微服务名称以小写的形式呈现","link":"/2020/01/18/SSM/springcloudalibaba/24.Gateway/"},{"title":"七、No Feign Client for loadBalancing defined","text":"No Feign Client for loadBalancing defined 这是在使用Feign调服务的时候，报的一个错误，完整错误如下： 12No Feign Client for loadBalancing defined. Did you forget to include spring-cloud-starter-netflix-ribbon? 从错误中看到，说的是我们是不是忘记引入spring-cloud-starter-netflix-ribbon 包了，但是我自己查看之后，发现这个包是存在。于是开启了面向度娘编程, 哈哈。 网上说有可能是因为没有引入eureka 包，但是，很显然我们使用的是alibaba系列，于是就想到了eureka的作用，所以是因为没有导入服务注册中心的包和配置。 于是添加配置就可以了： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置文件： 1spring.cloud.nacos.discovery.server-addr=120.79.167.88:8848","link":"/2020/01/18/SSM/springcloudalibaba/4.No%20Feign%20Client%20for%20loadBalancing%20defined/"},{"title":"九、初识Nacos 配置中心","text":"初识Nacos 配置中心 文档SpringCloud官方文档： https://spring-cloud-alibaba-group.github.io/github-pages/greenwich/spring-cloud-alibaba.html#_spring_cloud_alibaba_nacos_config Github中文文档： https://github.com/alibaba/spring-cloud-alibaba/wiki/Nacos-config 依赖创建一个SpringBoot，引入相关的依赖，如下： 123456&lt;!--nacos配置中心--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; Properties类型创建配置在Nacos控制页面配置相关的配置信息，由于上面的配置文件中未指定拓展名(properties/yml),默认是properties。 配置文件在classpath目录下创建一个名为bootstrap.properties文件，必须为bootstrap.properties。内容如下： 12spring.application.name=nacos-configspring.cloud.nacos.config.server-addr=127.0.0.1:8848 程序我们建立简单的web项目： User123456@Data@AllArgsConstructorpublic class User { private String username; private Integer age;} UserService1234567891011121314@Servicepublic class UserService { @Value(\"${user.name}\") private String username; @Value(\"${user.age}\") private Integer age; public User findUser(){ User user = new User(username,age); return user; }} UserController1234567891011@RestControllerpublic class UserController { @Autowired private UserService userService; @RequestMapping(value = \"/findUser\", method = RequestMethod.GET) public User findUser(){ return userService.findUser(); }} 测试结果 Yaml类型创建配置 配置文件将Bootstrap文件修改如下： 123456# 服务名，配置名spring.application.name=nacos-config# 配置格式spring.cloud.nacos.config.file-extension=yaml# 配置中心地址spring.cloud.nacos.config.server-addr=127.0.0.1:8848 测试结果 注意： 如果Nacos配置的是xxx.yaml.而服务配置上写的是yml，那么也读取不到配置，需要配置文件和Nacos配置的DataId一致。 如果使用的是域名的方式来访问配置中心Nacos时，spring.cloud.nacos.config.server-addr 配置方式为：域名:port ;例如Nocos的域名为abc.com.nacos,监听端口为80，则spring.cloud.nacos.config.server-addr=abc.com.nacos:80 . 80端口不能省略。","link":"/2020/01/18/SSM/springcloudalibaba/6.%E5%88%9D%E8%AF%86Nacos%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"},{"title":"十二、Nacos的数据持久化","text":"Nacos的数据持久化 Nacos部署文档:https://nacos.io/zh-cn/docs/deployment.html 按照我们之前使用本地启动方式来测试Nacos，如果没有进行数据持久化配置的话，那么默认是使用嵌入式数据库来存储数据的。 目录结构我们下载下来的Nacos包，解压之后如下：以Windows为例： 单机模式支持mysql在0.7版本之前，在单机模式时nacos使用嵌入式数据库实现数据存储，但是由于是内嵌式的，不方便我们观察数据存储的基本情况。0.7版本增加了支持mysql数据源能力，具体的操作步骤： 安装数据库，版本要求：5.6.5+ 初始化mysql数据库，数据库初始化文件是 conf/nacos-mysql.sql 修改conf/application.properties文件，增加支持mysql的配置信息(目前只支持mysql)，添加mysql数据源的url，用户名和密码。 123456spring.datasource.platform = mysqldb.num = 1db.url.0 = jdbc:mysql://127.0.0.1:3306/nacos_devtest? characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=rootdb.password=root 然后再以单机模式启动nacos，nacos所有写嵌入式数据库的数据都写到了mysql。 数据库存储表","link":"/2020/01/18/SSM/springcloudalibaba/9.Nacos%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/"},{"title":"八、Ribbon 负载均衡的坑","text":"由于Feign一般使用更加方便，所以这个问题是在Feign调用多个服务的时候出现了404. 描述：案例中 是 服务A 调用了服务B，然后调用了服务C，再次调用B的时候出现了404. 控制台输出如下异常： 12345feign.FeignException: status 404 reading FeignService#echo(String) at feign.FeignException.errorStatus(FeignException.java:78) ~[feign-core-10.1.0.jar:na] at feign.codec.ErrorDecoder$Default.decode(ErrorDecoder.java:93) ~[feign-core-10.1.0.jar:na] at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:149) ~[feign-core-10.1.0.jar:na] at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:78) ~[feign-core-10.1.0.jar:na] 其实异常是由于Ribbon引起的，由于Feign中封装使用了Ribbon，所以虽然是在使用Feign，但是是由于Ribbon造成的，我们来看看如何解决： 这个问题是由于Ribbon配置扫描的问题导致的：我们到官网看一下： https://cloud.spring.io/spring-cloud-static/spring-cloud-netflix/2.2.0.M3/reference/html/#customizing-the-ribbon-client 我们看一下警告的地方：自定义的配置类(CustomConfiguration)必须是一个被@configuration 注解标识的类，并且不应该被@ComponentScan 扫描到。当然也不能被@component 和 @SpringBootApplication 注解扫描到，如果扫描到会被所有的RibbonClient共享。 解决方法 配置文件： 123456789@Configurationpublic class LoadBalanceConfig { @Bean public IRule iRule(){// return new RandomRule();//随机策略 return new RoundRobinRule();//轮询策略 }}","link":"/2020/01/18/SSM/springcloudalibaba/5.Feign%E8%B0%83%E7%94%A8%E5%A4%9A%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%87%BA%E7%8E%B0404/"},{"title":"RabbitMQ","text":"RabbitMQ基础操作指南 RabbitMQ 2.收发信息的步骤1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677生产者：1.创建连接工厂ConnectionFactory factory = new ConnectionFactory();需要设置参数： .setHost(String); .setPort(int); .setUsername(String); .setPassword(String); .setVirtualHost(String);2.通过工厂对象创建连接Connection connection = factory.newConnection();3.通过连接对象创建通道Channel channel = connection.createChannel(); 3.1队列声明 /** * 声明队列，如果rabbit中没有此队列将自动创建 * param1: 队列名称 * param2: 是否持久化 * param3: 队列是否独占此连接 * param4: 队列不再使用时是否自动删除此队列 * param5: 队列参数 */ .queueDeclare(String,boolean,boolean,boolean,Map); 3.2消息发布 /** * 消息发布方法 * param1: Exchange的名称，如果没有指定名称，则使用 Default Exchange * param2: routingKey，消息的路由Key，用于Exchange（交换机）将消息转发到指定的消息队列 * param3: 消息包含的属性 * param4: 消息体 */ /** * 这里没有指定交换机，消息将发送给默认的交换机，每个队列也会绑定那个默认的交换机， * 但是不能 * 绑定显示或是解除绑定 * 默认的交换机，routingKey等于队列名称 */ .basicPublish(\"\",QUEUE,null,message.getBytes());消费者：1.创建连接工厂ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ所在服务器的ip和端口 factory.setHost(\"127.0.0.1\"); factory.setPort(5672);2.通过工厂对象创建连接Connection connection = factory.newConnection();3.通过连接对象创建通道Channel channel = connection.createChannel(); 3.1队列声明 3.2创建消费方法 /** * 消费者接受消息调用此方法 * @param consumerTag 消费者的标签，在channel.basicConsume()去指定 * @param envelope 消息包的内容，可以从中获取消息id，消息的routingKey，交换机，消息 * 和重传标志（收到消息失败后是否需要重新发送） * @param properties * @param body * @throws IOException */ DefaultConsumer consumer = new DefaultComsumer(channel){ @Override handleDelivery(); }; 3.3进行监听 /** * 监听消息String queue，boolean autoAck，Consumer callback * 参数明细： * 1.队列名称 * 2.是否自动回复，设置为true表示消息接收到自动向mq回复接收到了， * mq接收到回复消息会删除消息， * 设置为false则需要手动回复 * 3.消费消息的方法，消费者接收到消息后调用此方法 */ channel.basicConsume(QUEUE,true,consumer); 1、发送端操作流程 1）创建连接 2）创建通道 3）声明队列 4）发送消息 2、接收端 1）创建连接 2）创建通道 3）声明队列 4）监听队列 5）接收消息 6）ack回复 3.简单队列1.模型 2.获取连接的工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ConnectionUtils { /** * 服务器地址 */ public static final String HOST = \"127.0.0.1\"; /** * 服务器端口 AMQP */ public static final Integer PORT = 5672; /** * 用户名 */ public static final String USERNAME = \"guest\"; /** * 密码 */ public static final String PASSWORD = \"guest\"; /** * 主机访问地址 */ public static final String VIRTUALHOST = \"/\"; public static Connection getConnection(){ ConnectionFactory factory = new ConnectionFactory(); factory.setHost(HOST); factory.setPort(PORT); factory.setUsername(USERNAME); factory.setPassword(PASSWORD); factory.setVirtualHost(VIRTUALHOST); Connection connection = null; try { connection = factory.newConnection(); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } return connection; }} 3.生产者生产消息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Producer01 { //对列名称 private static final String QUEUE = \"helloworld\"; public static void main(String[] args) throws IOException, TimeoutException { Connection connection = null; Channel channel = null; try{ ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"localhost\"); factory.setPort(5672); factory.setUsername(\"guest\"); factory.setPassword(\"guest\"); //rabbitmq 默认虚拟机名称为\"/\"，虚拟机相当于一个独立的mq服务器 factory.setVirtualHost(\"/\"); //创建与RabbitMQ服务的TCP连接 connection = factory.newConnection(); //创建与Exchange的通道，每个连接可以创建多个通道，每一个通道代表一个会话任务。 channel = connection.createChannel(); /** * 声明队列，如果rabbit中没有此队列将自动创建 * param1: 队列名称 * param2: 是否持久化 * param3: 队列是否独占此连接 * param4: 队列不再使用时是否自动删除此队列 * param5: 队列参数 */ channel.queueDeclare(QUEUE,true,false,false,null); String message = \"helloworld小明：\"+System.currentTimeMillis(); /** * 消息发布方法 * param1: Exchange的名称，如果没有指定名称，则使用 Default Exchange * param2: routingKey，消息的路由Key，用于Exchange（交换机）将消息转发到指定的消息队列 * param3: 消息包含的属性 * param4: 消息体 */ /** * 这里没有指定交换机，消息将发送给默认的交换机，每个队列也会绑定那个默认的交换机， * 但是不能 * 绑定显示或是解除绑定 * 默认的交换机，routingKey等于队列名称 */ channel.basicPublish(\"\",QUEUE,null, message.getBytes()); System.out.println(\"Send Message is：\"+message); }catch (Exception e){ e.printStackTrace(); }finally { if (channel != null){ channel.close(); } if (connection != null){ connection.close(); } } }} 4.消费者消费消息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class Consumer01 { private static final String QUEUE = \"helloworld\"; public static void main(String[] args) throws IOException, TimeoutException { ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ所在服务器的ip和端口 factory.setHost(\"127.0.0.1\"); factory.setPort(5672); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); //声明队列 channel.queueDeclare(QUEUE,true,false,false,null); //定义消费方法 DefaultConsumer consumer = new DefaultConsumer(channel){ /** * 消费者接受消息调用此方法 * @param consumerTag 消费者的标签，在channel.basicConsume()去指定 * @param envelope 消息包的内容，可以从中获取消息id，消息的routingKey，交换机，消息 * 和重传标志（收到消息失败后是否需要重新发送） * @param properties * @param body * @throws IOException */ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { //交换机 String exchange = envelope.getExchange(); //路由key String routingKey = envelope.getRoutingKey(); //消息id long deliveryTag = envelope.getDeliveryTag(); //消息内容 String message = new String(body,\"utf-8\"); //是否重传 boolean isRedeliver = envelope.isRedeliver(); System.out.println(\"exchange:\"+exchange); System.out.println(\"routingKey:\"+routingKey); System.out.println(\"deliveryTag:\"+deliveryTag); System.out.println(\"isRedeliver:\"+isRedeliver); System.out.println(\"message:\"+message); } }; /** * 监听消息String queue，boolean autoAck，Consumer callback * 参数明细： * 1.队列名称 * 2.是否自动回复，设置为true表示消息接收到自动向mq回复接收到了， * mq接收到回复消息会删除消息，设置为false则需要手动回复 * 3.消费消息的方法，消费者接收到消息后调用此方法 */ channel.basicConsume(QUEUE,true,consumer); }} 5.简单队列的不足耦合性高，生产者一一对应消费者（如何我想要有多个消费者消费队列中消息，这时候就不行了），队列名变更，这时候得同事变更。 4.work queues 工作队列模式1.模型 为什么会出现工作队列 simple队列是一一对应的，而且实际开发，生产者发送消息是毫不费力的，而消费者一般是要跟业务相结合的，消费者接受到消息之后就需要处理，可能需要花费时间，这时候队列就会积压了很多消息 2.生产者12345678910111213141516171819202122232425public class Send { /** * |-- C1 * p -- Queue -- | * |-- C2 */ public static final String QUEUE_NAME = \"test_work_queue\"; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException { //获取连接 Connection connection = ConnectionUtils.getConnection(); //获取Channel Channel channel = connection.createChannel(); //声明Queue(String queueName, Boolean durable, Boolean exclusive, Boolean autoDelete, Map&lt;String, Object&gt; arguments) channel.queueDeclare(QUEUE_NAME,true,false,false,null); for (int i = 0; i &lt; 50; i++) { String message = \"MQ \"+i; channel.basicPublish(\"\",QUEUE_NAME,null,message.getBytes()); System.out.println(\"send message: \"+message); Thread.sleep(i*20); } channel.close(); connection.close(); }} 3.消费者1123456789101112131415161718192021222324252627282930public class Receive1 { public static final String QUEUE_NAME = \"test_work_queue\"; public static void main(String[] args) throws IOException { //获取连接 Connection connection = ConnectionUtils.getConnection(); //获取Channel Channel channel = connection.createChannel(); //声明Queue channel.queueDeclare(QUEUE_NAME,true,false,false,null); DefaultConsumer consumer = new DefaultConsumer(channel){ //消息到达 触发方法 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { System.out.println(\"[1] get message :\"+ new String(body,\"utf-8\")); try { Thread.sleep(1000*2); } catch (InterruptedException e) { e.printStackTrace(); } finally { System.out.println(\"[1] over\"); } } }; boolean autoAck = true; //监听消息String queue，boolean autoAck，Consumer callback channel.basicConsume(QUEUE_NAME,autoAck,consumer); }} 4.消费者2123456789101112131415161718192021222324252627282930public class Receive2 { public static final String QUEUE_NAME = \"test_work_queue\"; public static void main(String[] args) throws IOException { //获取连接 Connection connection = ConnectionUtils.getConnection(); //获取Channel Channel channel = connection.createChannel(); //声明Queue channel.queueDeclare(QUEUE_NAME,true,false,false,null); DefaultConsumer consumer = new DefaultConsumer(channel){ //消息到达 触发方法 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { System.out.println(\"[2] get message :\"+ new String(body,\"utf-8\")); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } finally { System.out.println(\"[2] over\"); } } }; boolean autoAck = true; //监听消息String queue，boolean autoAck，Consumer callback channel.basicConsume(QUEUE_NAME,autoAck,consumer); }} 5.现象消费者1和消费者2处理的消息是一样的。 消费者1：偶数 消费者2：奇数 这种方式叫做轮询分发（roun-robin）结果就是：不管谁忙活着谁清闲 都不会多给一个消息任务 任务消息总是平均分配。（你一个我一个） 5.公平分发 fair depatch1.说明使用公平分发，必须关闭自动应答ack,改为手动 2.生产者12345678910111213141516171819202122232425262728293031public class Send { /** * |-- C1 * p -- Queue -- | * |-- C2 */ public static final String QUEUE_NAME = \"test_work_queue\"; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException { //获取连接 Connection connection = ConnectionUtils.getConnection(); //获取Channel Channel channel = connection.createChannel(); //声明Queue(String queueName, Boolean durable, Boolean exclusive, Boolean autoDelete, Map&lt;String, Object&gt; arguments) channel.queueDeclare(QUEUE_NAME,true,false,false,null); /** * 每个消费者 发送确认消息消息之前，消息队列不发送下一个消息到消费者，一次只处理一个消息 * * 限制发送给同一个消费者不得超过一条消息 */ int prefetchCount = 1; channel.basicQos(prefetchCount); for (int i = 0; i &lt; 50; i++) { String message = \"MQ \"+i; channel.basicPublish(\"\",QUEUE_NAME,null,message.getBytes()); System.out.println(\"send message: \"+message); Thread.sleep(i*20); } channel.close(); connection.close(); }} 3.消费者1123456789101112131415161718192021222324252627282930313233public class Receive1 { public static final String QUEUE_NAME = \"test_work_queue\"; public static void main(String[] args) throws IOException { //获取连接 Connection connection = ConnectionUtils.getConnection(); //获取Channel final Channel channel = connection.createChannel(); //声明Queue channel.queueDeclare(QUEUE_NAME,true,false,false,null); int prefetchCount = 1; channel.basicQos(prefetchCount); DefaultConsumer consumer = new DefaultConsumer(channel){ //消息到达 触发方法 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { System.out.println(\"[1] get message :\"+ new String(body,\"utf-8\")); try { Thread.sleep(1000*2); } catch (InterruptedException e) { e.printStackTrace(); } finally { //手动回执应答 channel.basicAck(envelope.getDeliveryTag(),false); System.out.println(\"[1] over\"); } } }; boolean autoAck = false;//非自动应答 //监听消息String queue，boolean autoAck，Consumer callback channel.basicConsume(QUEUE_NAME,autoAck,consumer); }} 4.消费者2123456789101112131415161718192021222324252627282930313233public class Receive2 { public static final String QUEUE_NAME = \"test_work_queue\"; public static void main(String[] args) throws IOException { //获取连接 Connection connection = ConnectionUtils.getConnection(); //获取Channel final Channel channel = connection.createChannel(); //声明Queue channel.queueDeclare(QUEUE_NAME,true,false,false,null); int prefetchCount = 1; channel.basicQos(prefetchCount); DefaultConsumer consumer = new DefaultConsumer(channel){ //消息到达 触发方法 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { System.out.println(\"[2] get message :\"+ new String(body,\"utf-8\")); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } finally { //手动回执应答 channel.basicAck(envelope.getDeliveryTag(),false); System.out.println(\"[2] over\"); } } }; boolean autoAck = false; //监听消息String queue，boolean autoAck，Consumer callback channel.basicConsume(QUEUE_NAME,autoAck,consumer); }} 5.与work queues的差别之处5.1 生产者 5.2 消费者 6.现象消费者2处理的消息比消费者1多（能者多劳，公平分发） 6.消息应答 与 消息持久化6.1消息应答自动确认模式： ​ RabbitMQ一旦将消息分发非消费之后，就会从内存中删除这个消息 现象： ​ 这种情况下，如果杀死（kill）当前正在执行的消费者，就会丢失正在执行的消息。 12boolean autoAck = true;//自动应答channel.basicConsume(QUEUE_NAME,autoAck,consumer); 手动确认模式： 123boolean autoAck = false;//非自动应答//监听消息String queue，boolean autoAck，Consumer callbackchannel.basicConsume(QUEUE_NAME,autoAck,consumer); 如果有一个消费者挂掉，就会交付给其他消费者。RabbitMQ支持消息应答，消费者发送一个消息应答，告诉RabbitMQ这个消息我已经处理完成，RabbitMQ可以将这个消息从内存中删除了。 (message acknowledgment)消息应答模式（Ack）是打开的， false。 如果RabbitMQ挂了，消息仍然会丢失。 6.2消息持久化12345678910/** * 参数： * queue:队列的名称 * durable:能否持久化 * exclusive:是否独占连接 * autoDelete:是否自动删除 * arguments:参数 */boolean durable = true;channel.queueDeclare(QUEUE_NAME,durable,false,false,null); 我们将程序中的boolean durable = true; 改为false是不可以的，会报错。尽管代码是正确的，但是该队列应该声明定义好了，就不可以再进行修改了。（RabbitMQ不允许用不同的参数重新定义一个已经存在的队列（可以先删除再创建）） 7.Exchange(交换机，转发器)一方面是接收生产者的消息，另一方面是向队列推送消息。 匿名转发：“”; 7.1 Fanout Exchange(不处理路由键) 只需要将生产者与exchange进行bind，就会把exchange中的信息转发到与exchange绑定的所有Queue中。 123456789任何发送到Fanout Exchange的消息都会被转发到与该Exchange绑定(Binding)的所有Queue上。1.可以理解为路由表的模式2.这种模式不需要RouteKey3.这种模式需要提前将Exchange与Queue进行绑定，一个Exchange可以绑定多个Queue，一个Queue可以同多个Exchange进行绑定。4.如果接受到消息的Exchange没有与任何Queue绑定，则消息会被抛弃。 7.2 Direct Exchange 处理路径键 123456789任何发送到Direct Exchange的消息都会被转发到RouteKey中指定的Queue。1.一般情况可以使用rabbitMQ自带的Exchange：”\"(该Exchange的名字为空字符串，下文称其为default Exchange)。2.这种模式下不需要将Exchange进行任何绑定(binding)操作3.消息传递时需要一个“RouteKey”，可以简单的理解为要发送到的队列名字。4.如果vhost中不存在RouteKey中指定的队列名，则该消息会被抛弃。 7.3 Topic Exchange 123456789101112任何发送到Topic Exchange的消息都会被转发到所有关心RouteKey中指定话题的Queue上1.这种模式较为复杂，简单来说，就是每个队列都有其关心的主题，所有的消息都带有一个“标题”(RouteKey)，Exchange会将消息转发到所有关注主题能与RouteKey模糊匹配的队列。2.这种模式需要RouteKey，也许要提前绑定Exchange与Queue。3.在进行绑定时，要提供一个该队列关心的主题，如“#.log.#”表示该队列关心所有涉及log的消息(一个RouteKey为”MQ.log.error”的消息会被转发到该队列)。4.“#”表示0个或若干个关键字，“*”表示一个关键字。如“log.*”能与“log.warn”匹配，无法与“log.warn.timeout”匹配；但是“log.#”能与上述两者匹配。5.同样，如果Exchange没有发现能够与RouteKey匹配的Queue，则会抛弃此消息。 性能排序：fanout &gt; direct &gt;&gt; topic。比例大约为11：10：6 8.订阅模式Publish/Subscribe(fanout)1.模型 2.解读 一个生产者，多个消费者。 每一个消费者都有自己对应的队列。 生产者没有直接把消息发送到队列 而是发送到了交换机 （转发器exchange） 每个队列都要绑定到交换机上 生产者发送的消息经过交换机到达队列 ，就能实现一个消息就可以被多个消费者消费。 1234发布订阅模式：1、每个消费者监听自己的队列。2、生产者将消息发给broker，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收到消息 注册 –&gt; 邮件 –&gt; 短信 3.发送者1234567891011121314151617181920212223public class Send { public static final String QUEUE_NAME = \"test_queue_fanout\"; public static final String EXCHANGE_NAME = \"test_exchange_fanout\"; public static void main(String[] args) throws IOException, TimeoutException { //通过工具类获取连接 Connection connection = ConnectionUtils.getConnection(); //创建Channel Channel channel = connection.createChannel(); /** * 声明交换机 * 参数： * exchange:exchange的名字 * type:exchange的类型 */ channel.exchangeDeclare(EXCHANGE_NAME,\"fanout\");//分发 //发送消息 String message = \"hello publish/subscribe\"; channel.basicPublish(EXCHANGE_NAME,\"\",null,message.getBytes()); System.out.println(\"send message : \"+message); channel.close(); connection.close(); }} 4.exchange图示 消息去哪里了？？丢失了，因为交换机没有存储的能力，在RabbitMQ里面只有队列有存储能力。因为此时没有把交换机和相应的队列进行绑定，所以数据就丢失了。 5.发送者1234567891011121314151617181920212223public class Send { public static final String EXCHANGE_NAME = \"test_exchange_fanout\"; public static void main(String[] args) throws IOException, TimeoutException { //通过工具类获取连接 Connection connection = ConnectionUtils.getConnection(); //创建Channel Channel channel = connection.createChannel(); //声明交换机 /** * 参数： * exchange:exchange的名字 * type:exchange的类型 */ channel.exchangeDeclare(EXCHANGE_NAME,\"fanout\");//分发 //发送消息 String message = \"hello publish/subscribe\"; channel.basicPublish(EXCHANGE_NAME,\"\",null,message.getBytes()); System.out.println(\"send message : \"+message); channel.close(); connection.close(); }} 6.消费者1123456789101112131415161718192021222324252627282930public class Receive1 { public static final String QUEUE_NAME = \"test_queue_fanout_email\"; public static final String EXCHANGE_NAME = \"test_exchange_fanout\"; public static void main(String[] args) throws IOException { Connection connection = ConnectionUtils.getConnection(); final Channel channel = connection.createChannel(); //队列声明 channel.queueDeclare(QUEUE_NAME,true,false,false,null); channel.basicQos(1); //绑定队列到交换机 channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,\"\"); DefaultConsumer consumer = new DefaultConsumer(channel){ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { System.out.println(\"[1] receive message:\"+new String(body,\"utf-8\")); try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); }finally { System.out.println(\"[1] over\"); channel.basicAck(envelope.getDeliveryTag(),false); } } }; channel.basicConsume(QUEUE_NAME,false,consumer); }} 7.消费者21234567891011121314151617181920212223242526272829public class Receive2 { public static final String QUEUE_NAME = \"test_queue_fanout_sms\"; public static final String EXCHANGE_NAME = \"test_exchange_fanout\"; public static void main(String[] args) throws IOException { Connection connection = ConnectionUtils.getConnection(); final Channel channel = connection.createChannel(); //队列声明 channel.queueDeclare(QUEUE_NAME,true,false,false,null); channel.basicQos(1); //绑定队列到交换机 channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,\"\"); DefaultConsumer consumer = new DefaultConsumer(channel){ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { System.out.println(\"[2] receive message:\"+new String(body,\"utf-8\")); try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); }finally { System.out.println(\"[2] over\"); channel.basicAck(envelope.getDeliveryTag(),false); } } }; channel.basicConsume(QUEUE_NAME,false,consumer); }} 8.管理界面 9.Routing(direct)1.路由模型 2.生产者12345678910111213141516171819202122public class Send { //exchange name public static final String EXCHANGE_NAME = \"test_exchange_direct\"; //routing key public static final String ROUTING_KEY = \"error\"; public static void main(String[] args) throws IOException, TimeoutException { //获得连接 Connection connection = ConnectionUtils.getConnection(); //创建Channel Channel channel = connection.createChannel(); //声明交换机 channel.exchangeDeclare(EXCHANGE_NAME,\"direct\"); //消息 String message = \"hello direct!\"+ROUTING_KEY; //发布消息 channel.basicPublish(EXCHANGE_NAME,ROUTING_KEY,null,message.getBytes()); System.out.println(\"send message:\"+message); //资源释放 channel.close(); connection.close(); }} 3.消费者1123456789101112131415161718192021public class Receive1 { //queue name public static final String QUEUE_NAME = \"test_queue_direct_1\"; //exchange name public static final String EXCHANGE_NAME = \"test_exchange_direct\"; //routing key public static final String ROUTING_KEY = \"error\"; public static void main(String[] args) throws IOException, TimeoutException { //获得Connection Connection connection = ConnectionUtils.getConnection(); //创建Channel final Channel channel = connection.createChannel(); //声明Queue channel.queueDeclare(QUEUE_NAME,true,false,false,null); channel.basicQos(1); //绑定 channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,ROUTING_KEY); DefaultConsumer consumer = new MyDefaultConsumer(channel,\"1\"); channel.basicConsume(QUEUE_NAME,false,consumer); }} 4.消费者212345678910111213141516171819202122232425public class Receive2 { //queue name public static final String QUEUE_NAME = \"test_queue_direct_2\"; //exchange name public static final String EXCHANGE_NAME = \"test_exchange_direct\"; //routing key public static final String ROUTING_KEY1 = \"info\"; public static final String ROUTING_KEY2 = \"error\"; public static final String ROUTING_KEY3 = \"warning\"; public static void main(String[] args) throws IOException, TimeoutException { //获得Connection Connection connection = ConnectionUtils.getConnection(); //创建Channel final Channel channel = connection.createChannel(); //声明Queue channel.queueDeclare(QUEUE_NAME,true,false,false,null); channel.basicQos(1); //绑定 channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,ROUTING_KEY1); channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,ROUTING_KEY2); channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,ROUTING_KEY3); DefaultConsumer consumer = new MyDefaultConsumer(channel,\"2\"); channel.basicConsume(QUEUE_NAME,false,consumer); }} 5.MyDefaultConsumer 123456789101112131415161718192021public class MyDefaultConsumer extends DefaultConsumer { private Channel channel = null; private String name = \"\"; public MyDefaultConsumer(Channel channel,String name) { super(channel); this.channel = channel; this.name = name; } @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { System.out.println(name+\" receive message: \"+new String(body,\"utf-8\")); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); }finally { System.out.println(name+\" over\"); channel.basicAck(envelope.getDeliveryTag(),false); } }} 5.Exchanges图示 10.Topic(topic)1.模型 12345.“#”表示0个或若干个关键字，“”表示一个关键字。如“log.”能与“log.warn”匹配，无法与“log.warn.timeout”匹配；但是“log.#”能与上述两者匹配。Goods.insert |Goods.update | ==&gt; Goods.# Goods.delete | 2.生产者1234567891011121314151617public class Send { public static final String EXCHANGE_NAME = \"test_exchange_topic\"; public static void main(String[] args) throws IOException, TimeoutException { //获得连接 Connection connection = ConnectionUtils.getConnection(); //创建Channel Channel channel = connection.createChannel(); //声明交换机 channel.exchangeDeclare(EXCHANGE_NAME,\"topic\"); String message = \"商品。。。\"; //发布消息 channel.basicPublish(EXCHANGE_NAME,\"goods.delete\",null,message.getBytes()); System.out.println(\"topic send message:\"+message); channel.close(); connection.close(); }} 3.消费者1123456789101112131415161718192021public class Receive1 { //queue name public static final String QUEUE_NAME = \"test_queue_topic_1\"; //exchange name public static final String EXCHANGE_NAME = \"test_exchange_topic\"; //routing key public static final String ROUTING_KEY = \"goods.add\"; public static void main(String[] args) throws IOException, TimeoutException { //获得Connection Connection connection = ConnectionUtils.getConnection(); //创建Channel final Channel channel = connection.createChannel(); //声明Queue channel.queueDeclare(QUEUE_NAME,true,false,false,null); channel.basicQos(1); //绑定 channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,ROUTING_KEY); DefaultConsumer consumer = new MyDefaultConsumer(channel,\"topic1\"); channel.basicConsume(QUEUE_NAME,false,consumer); }} 4.消费者2123456789101112131415161718192021public class Receive2 { //queue name public static final String QUEUE_NAME = \"test_queue_topic_2\"; //exchange name public static final String EXCHANGE_NAME = \"test_exchange_topic\"; //routing key public static final String ROUTING_KEY = \"goods.#\"; public static void main(String[] args) throws IOException, TimeoutException { //获得Connection Connection connection = ConnectionUtils.getConnection(); //创建Channel final Channel channel = connection.createChannel(); //声明Queue channel.queueDeclare(QUEUE_NAME,true,false,false,null); channel.basicQos(1); //绑定 channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,ROUTING_KEY); DefaultConsumer consumer = new MyDefaultConsumer(channel,\"topic2\"); channel.basicConsume(QUEUE_NAME,false,consumer); }} 11.RabbitMQ的消息确认机制(事务+confirm)在rabbitMQ中 我们可以通过持久化数据，解决rabbitmq服务器异常的数据丢失问题。 问题：生产者将消息发送出来之后，消息到底有没有到RabbitMQ服务器，默认的情况是不知道的。 两种方式： ​ AMQP实现了事务机制 ​ Confirm模式 事务机制： txSelect txCommit txRollback txSelect:用户将当前channel设置成transaction模式、 txCommit:用于提交事务 txRollback：回滚事务 1事务机制生产者1234567891011121314151617181920212223242526272829public class TxSend { private static final String QUEUE_NAME = \"test_queue_tx\"; public static void main(String[] args) throws IOException, TimeoutException { Connection connection = ConnectionUtils.getConnection(); Channel channel = connection.createChannel(); //声明queue channel.queueDeclare(QUEUE_NAME,false,false,false,null); String msgString = \"hello tx message!\"; System.out.println(\"send message:\"+msgString); try{ //开始事务 channel.txSelect(); channel.basicPublish(\"\",QUEUE_NAME,null,msgString.getBytes()); int i = 1/0; channel.txCommit(); //事务提交 }catch (Exception e){ //事务回滚 channel.txRollback(); System.out.println(\"send mesage txRollback\"); } channel.close(); connection.close(); }} 消费者123456789101112131415161718192021public class TxReceive { private static final String QUEUE_NAME = \"test_queue_tx\"; public static void main(String[] args) throws IOException, TimeoutException { Connection connection = ConnectionUtils.getConnection(); Channel channel = connection.createChannel(); //声明queue channel.queueDeclare(QUEUE_NAME, false, false, false, null); DefaultConsumer consumer = new DefaultConsumer(channel){ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { System.out.println(\"receive:\"+new String(body,\"utf-8\")); } }; channel.basicConsume(QUEUE_NAME,true,consumer); }} 2.Confirm模式生产者端confirm模式的实现原理123生产者将信道设置成confirm模式，一旦信道进入confirm模式，所有在该信道上面发布的消息都会指派成一个唯一的id（从1开始），一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，broker回传给生产者的确认消息中deliver-tag域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。 Confirm模式最大的好处就在于它是异步的、 Nack； 开启confirm模式。 Channel.confirmSelect(); 编程模式： 1.普通 发一条 waitForConfirms() 2.批量 发一批 waitForConfirms() 3.异步 Confirm模式：提供一个回调的方法， 生产者： 123456789101112131415161718192021222324252627282930313233/** * 批量模式 */public class Send2 { private static final String QUEUE_NAME = \"test_queue_confirm1\"; public static void main(String[] args) throws IOException, InterruptedException, TimeoutException { Connection connection = ConnectionUtils.getConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME,false,false,false,null); //生产者调用confirmSelect模式 将channel设置为Confirm模式 channel.confirmSelect(); String msgString = \"Hello confirm message batch\"; //批量发送消息 for (int i = 0; i &lt; 10; i++) { channel.basicPublish(\"\",QUEUE_NAME,null,msgString.getBytes()); } //确认 if(!channel.waitForConfirms()){ System.out.println(\"message send failed\"); }else{ System.out.println(\"message send ok\"); } channel.close(); connection.close(); }} 异步模式： 1Channel对象提供的confirmListener（）回调方法值包deliveryTag（当前Channel发出的消息序号），我们需要自己为每一个Channel维护一个unconfirm的消息序列集合，每publish一条数据，集合中元素加1.每回到一次handleAck方法，unconfirm集合删除相应的一条（multiple=false）或多条（multiple=true），从程序的运行效率来看，这个unconfirm集合最好采用有序集合sortedset存储结构。 publish-subscribe和work queues的区别123456789101112131、publish/subscribe与work queues有什么区别。区别：1）work queues不用定义交换机，而publish/subscribe需要定义交换机。2）publish/subscribe的生产方是面向交换机发送消息，work queues的生产方是面向队列发送消息(底层使用默 认交换机)。3）publish/subscribe需要设置队列和交换机的绑定，work queues不需要设置，实质上work queues会将队列绑定到默认的交换机 。相同点：所以两者实现的发布/订阅的效果是一样的，多个消费端监听同一个队列不会重复消费消息。 2、实质工作用什么 publish/subscribe还是work queues。建议使用 publish/subscribe，发布订阅模式比工作队列模式更强大，并且发布订阅模式可以指定自己专用的交换机。 4.4.4思考1、本案例的需求使用Routing工作模式能否实现？使用Routing模式也可以实现本案例，共设置三个 routingkey，分别是email、sms、all，email队列绑定email和all，sms队列绑定sms和all，这样就可以实现上边案例的功能，实现过程比topics复杂。Topic模式更多加强大，它可以实现Routing、publish/subscirbe模式的功能。 Routing 与 Topic的区别 1234使用Routing模式时，生产者生产信息是带有特殊的rountingKey,一条消息只会发送到一个Queue中，消费者通过唯一的routingKey来监听指定的Queue使用Topic模式时，生产者生产消息时带有通用的routingKey，一条信息可以发送到符合条件的Queue中，消费者通过配置带有#通配符的routingKey来监听满足条件的Queue。 6.headers12345678Headers类型的Exchanges是不处理路由键的，而是根据发送的消息内容中的headers属性进行匹配。在绑定Queue与Exchange时指定一组键值对；当消息发送到RabbitMQ时会取到该消息的headers与Exchange绑定时指定的键值对进行匹配；如果完全匹配则消息会路由到该队列，否则不会路由到该队列。headers属性是一个键值对，可以是Hashtable，键值对的值可以是任何类型，而fanout，direct，topic的路由必须都需要字符串形式的。匹配规则x-match有下列两种类型：x-match=all:表示所有的键值对都可匹配才可以接收到消息。x-match=any:表示只有有键值对匹配就可以接收到到消息。 header模式与routing不同的地方在于，header模式取消routingkey，使用header中的 key/value（键值对）匹配队列。案例：根据用户的通知设置去通知用户，设置接收Email的用户只接收Email，设置接收sms的用户只接收sms，设置两种通知类型都接收的则两种通知都有效。代码：1）生产者队列与交换机绑定的代码与之前不同，如下： 123456Map&lt;String, Object&gt; headers_email = new Hashtable&lt;String, Object&gt;();headers_email.put(\"inform_type\", \"email\");Map&lt;String, Object&gt; headers_sms = new Hashtable&lt;String, Object&gt;();headers_sms.put(\"inform_type\", \"sms\");channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_HEADERS_INFORM,\"\",headers_email);channel.queueBind(QUEUE_INFORM_SMS,EXCHANGE_HEADERS_INFORM,\"\",headers_sms); 通知： 12345678String message = \"email inform to user\"+i;Map&lt;String,Object&gt; headers = new Hashtable&lt;String, Object&gt;();headers.put(\"inform_type\", \"email\");//匹配email通知消费者绑定的header//headers.put(\"inform_type\", \"sms\");//匹配sms通知消费者绑定的headerAMQP.BasicProperties.Builder properties = new AMQP.BasicProperties.Builder();properties.headers(headers);//Email通知channel.basicPublish(EXCHANGE_HEADERS_INFORM, \"\", properties.build(), message.getBytes()); 消费者： 1234567channel.exchangeDeclare(EXCHANGE_HEADERS_INFORM, BuiltinExchangeType.HEADERS);Map&lt;String, Object&gt; headers_email = new Hashtable&lt;String, Object&gt;();headers_email.put(\"inform_email\", \"email\");//交换机和队列绑定channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_HEADERS_INFORM,\"\",headers_email);//指定消费队列channel.basicConsume(QUEUE_INFORM_EMAIL, true, consumer); 7.RPC RPC即客户端远程调用服务端的方法 ，使用MQ可以实现RPC的异步调用，基于Direct交换机实现，流程如下： 1、客户端即是生产者就是消费者，向RPC请求队列发送RPC调用消息，同时监听RPC响应队列。 2、服务端监听RPC请求队列的消息，收到消息后执行服务端的方法，得到方法返回的结果 3、服务端将RPC方法 的结果发送到RPC响应队列 4、客户端（RPC调用方）监听RPC响应队列，接收到RPC调用结果。","link":"/2020/01/18/RabbitMQ/"},{"title":"二、Mybatis配置文件","text":"​在第一节中我们看到了Mybatis的部分配置信息，这些信息是基础信息，足以先将Mybatis拿来玩弄一下，但是在把玩一番之后，我们知道了Mybatis的基本使用方法，但是对于配置文件的详细信息和结果映射、动态Sql等好东西并没有好好研究，下面几节将一一进行介绍。 MyBatis 的配置文件包含了会深深影响 MyBatis 行为的设置和属性信息。 配置文档的顶层结构如下： configuration（配置） properties（属性） settings（设置） typeAliases（类型别名） typeHandlers（类型处理器） objectFactory（对象工厂） plugins（插件） environments（环境配置） environment（环境变量） transactionManager（事务管理器） dataSource（数据源） databaseIdProvider（数据库厂商标识） mappers（映射器） 配置文件结构123456&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt;&lt;/configuration&gt; 注意：这个配置文件的标签元素是有顺序的，需要按顺序配置。如下： 12configuration:properties -&gt; settings? -&gt; typeAliases -&gt; typeHandlers -&gt; objectFactory -&gt; objectWrapperFactory -&gt; reflectorFactory -&gt; plugins -&gt; environments -&gt; databaseIdProvider -&gt; mappers 我们回头看第一节中的配置文件也可以看出这个顺序，虽然其中有一些没有配置。 propertiesdb.properties: 12345678jdbc.driver= com.mysql.jdbc.Driverjdbc.url = jdbc:mysql://120.79.167.88:3306/mybatis? useUnicode=true &amp;characterEncoding=UTF-8 &amp;allowMultiQueries=true &amp;autoReconnect=true&amp;useSSL=falsejdbc.username = rootjdbc.password = root properties标签： 1234&lt;!--引入properties的属性文件--&gt;&lt;properties resource=\"mybatis.properties\"&gt; &lt;property name=\"username\" value=\"root\"/&gt;&lt;/properties&gt; 我们可以直接读取文件，也可以补充属性文件中没有的属性。 如果属性在不只一个地方进行了配置，那么 MyBatis 将按照下面的顺序来加载： 在 properties 元素体内指定的属性首先被读取。 然后根据 properties 元素中的 resource 属性读取类路径下属性文件或根据 url 属性指定的路径读取属性文件，并覆盖已读取的同名属性。 最后读取作为方法参数传递的属性，并覆盖已读取的同名属性。 因此，通过方法参数传递的属性具有最高优先级，resource/url 属性中指定的配置文件次之，最低优先级的是 properties 属性中指定的属性。 settings12345678&lt;!--设置使用驼峰命名--&gt;&lt;settings&gt; &lt;setting name=\"mapUnderscoreToCamelCase\" value=\"true\"/&gt; &lt;setting name=\"logPrefix\" value=\"##Mybatis##\"/&gt; &lt;setting name=\"logImpl\" value=\"STDOUT_LOGGING\"/&gt; &lt;setting name=\"lazyLoadingEnabled\" value=\"true\"/&gt; &lt;setting name=\"aggressiveLazyLoading\" value=\"false\"/&gt;&lt;/settings&gt; settings一般是一些配置，所以我们看一下官网的介绍： 一个配置完整的 settings 元素的示例如下： 1234567891011121314151617&lt;settings&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;setting name=\"lazyLoadingEnabled\" value=\"true\"/&gt; &lt;setting name=\"multipleResultSetsEnabled\" value=\"true\"/&gt; &lt;setting name=\"useColumnLabel\" value=\"true\"/&gt; &lt;setting name=\"useGeneratedKeys\" value=\"false\"/&gt; &lt;setting name=\"autoMappingBehavior\" value=\"PARTIAL\"/&gt; &lt;setting name=\"autoMappingUnknownColumnBehavior\" value=\"WARNING\"/&gt; &lt;setting name=\"defaultExecutorType\" value=\"SIMPLE\"/&gt; &lt;setting name=\"defaultStatementTimeout\" value=\"25\"/&gt; &lt;setting name=\"defaultFetchSize\" value=\"100\"/&gt; &lt;setting name=\"safeRowBoundsEnabled\" value=\"false\"/&gt; &lt;setting name=\"mapUnderscoreToCamelCase\" value=\"false\"/&gt; &lt;setting name=\"localCacheScope\" value=\"SESSION\"/&gt; &lt;setting name=\"jdbcTypeForNull\" value=\"OTHER\"/&gt; &lt;setting name=\"lazyLoadTriggerMethods\" value=\"equals,clone,hashCode,toString\"/&gt;&lt;/settings&gt; typeAliases类型别名就是为Java类型设置一个短的名字。它只和XML配置相关，存在的意义仅在于用来减少类全限定名的冗余。例如： 12345678&lt;typeAliases&gt; &lt;typeAlias alias=\"Bus\" type=\"com.ooyhao.mybatis3.bean.Bus\"/&gt; &lt;typeAlias alias=\"Car\" type=\"com.ooyhao.mybatis3.bean.Car\"/&gt; &lt;typeAlias alias=\"Subway\" type=\"com.ooyhao.mybatis3.bean.Subway\"/&gt; &lt;typeAlias alias=\"User\" type=\"com.ooyhao.mybatis3.bean.User\"/&gt; &lt;typeAlias alias=\"Role\" type=\"com.ooyhao.mybatis3.bean.Role\"/&gt; &lt;typeAlias alias=\"Card\" type=\"com.ooyhao.mybatis3.bean.Card\"/&gt;&lt;/typeAliases&gt; 如上所述配置计较麻烦，我们可以配置一个包，让其所有都遵循这个规则： 12345&lt;!--设置别名--&gt;&lt;!-- mybatis自动扫描包中的po类，自动定义别名，别名是类名(首字母大写或小写都可以,一般用小写) --&gt;&lt;typeAliases&gt; &lt;package name=\"com.ooyhao.mybatis3.bean\"/&gt;&lt;/typeAliases&gt; 我们还可以在此基础上使用注解修改默认取的别名： 12@Alias(\"card\")public class Card implements Serializable {} ​ 这是一些为常见的 Java 类型内建的相应的类型别名。它们都是不区分大小写的，注意对基本类型名称重复采取的特殊命名风格。 别名 映射的类型 _byte byte _long long _short short _int int _integer int _double double _float float _boolean boolean string String byte Byte long Long short Short int Integer integer Integer double Double float Float boolean Boolean date Date decimal BigDecimal bigdecimal BigDecimal object Object map Map hashmap HashMap list List arraylist ArrayList collection Collection iterator Iterator environmentsMyBatis 可以配置成适应多种环境，这种机制有助于将 SQL 映射应用于多种数据库之中， 现实情况下有多种理由需要这么做。例如，开发、测试和生产环境需要有不同的配置；或者想在具有相同 Schema 的多个生产数据库中 使用相同的 SQL 映射。有许多类似的使用场景。 不过要记住：尽管可以配置多个环境，但每个 SqlSessionFactory 实例只能选择一种环境。 所以，如果你想连接两个数据库，就需要创建两个 SqlSessionFactory 实例，每个数据库对应一个。而如果是三个数据库，就需要三个实例，依此类推，记起来很简单： 环境元素定义了如何配置环境: 123456789101112131415&lt;!--配置环境--&gt;&lt;environments default=\"development\"&gt; &lt;!--可以用来配置不同环境的参数，例如：开发，测试，生产--&gt; &lt;environment id=\"development\"&gt; &lt;!--事务管理--&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;!--数据源--&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"${jdbc.driver}\"/&gt; &lt;property name=\"url\" value=\"${jdbc.url}\"/&gt; &lt;property name=\"username\" value=\"${jdbc.username}\"/&gt; &lt;property name=\"password\" value=\"${jdbc.password}\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt;&lt;/environments&gt; 这里关键的点： 默认使用的环境ID（比如：default=”development”） 每个environment元素定义的环境ID（比如：id=”development”） 事务管理器的配置（比如：type=”JDBC”） 数据源的配置（比如：type=”POOLED”） 默认的环境和环境 ID 是自解释的，因此一目了然。 你可以对环境随意命名，但一定要保证默认的环境 ID 要匹配其中一个环境 ID。 事务管理器（TransactionManager） 在Mybatis中有两种类型的事务管理器（也就是type=”[JDBC|MANAGED]”）: JDBC - 这个配置就是直接使用了JDBC的提交和回滚设置，它依赖于从数据源得到的连接来管理事务作用域 MANAGED - 这个配置几乎没做什么。它从来不提交或回滚一个连接，而是让容器来管理事务的整个生命周期（比如 JEE 应用服务器的上下文）。 默认情况下它会关闭连接，然而一些容器并不希望这样，因此需要将 closeConnection 属性设置为 false 来阻止它默认的关闭行为。例如: 123&lt;transactionManager type=\"MANAGED\"&gt; &lt;property name=\"closeConnection\" value=\"false\"/&gt;&lt;/transactionManager&gt; 提示:如果你正在使用 Spring + MyBatis，则没有必要配置事务管理器， 因为 Spring 模块会使用自带的管理器来覆盖前面的配置。 ​ 数据源（dataSource） dataSource 元素使用标准的 JDBC 数据源接口来配置 JDBC 连接对象的资源。 许多 MyBatis 的应用程序会按示例中的例子来配置数据源。虽然这是可选的，但为了使用延迟加载，数据源是必须配置的。 有三种内建的数据源类型（也就是 type=”[UNPOOLED|POOLED|JNDI]”）： UNPOOLED 这个数据源的实现只是每次被请求时打开和关闭连接。虽然有点慢，但对于在数据库连接可用性方面没有太高要求的简单应用程序来说，是一个很好的选择。 不同的数据库在性能方面的表现也是不一样的，对于某些数据库来说，使用连接池并不重要，这个配置就很适合这种情形 driver – 这是 JDBC 驱动的 Java 类的完全限定名（并不是 JDBC 驱动中可能包含的数据源类）。 url – 这是数据库的 JDBC URL 地址。 username – 登录数据库的用户名。 password – 登录数据库的密码。 defaultTransactionIsolationLevel – 默认的连接事务隔离级别。 POOLED– 这种数据源的实现利用“池”的概念将 JDBC 连接对象组织起来，避免了创建新的连接实例时所必需的初始化和认证时间。 这是一种使得并发 Web 应用快速响应请求的流行处理方式 JNDI – 这个数据源的实现是为了能在如 EJB 或应用服务器这类容器中使用，容器可以集中或在外部配置数据源，然后放置一个 JNDI 上下文的引用 mappers既然 MyBatis 的行为已经由上述元素配置完了，我们现在就要定义 SQL 映射语句了。 但是首先我们需要告诉 MyBatis 到哪里去找到这些语句。 Java 在自动查找这方面没有提供一个很好的方法，所以最佳的方式是告诉 MyBatis 到哪里去找映射文件。 你可以使用相对于类路径的资源引用， 或完全限定资源定位符（包括 file:/// 的 URL），或类名和包名等。例如： 1234567&lt;!--mapper xml文件--&gt;&lt;mappers&gt; &lt;!--&lt;package name=\"mapper\"/&gt;--&gt; &lt;mapper resource=\"mapper/UserMapper.xml\"/&gt; &lt;mapper resource=\"mapper/RoleMapper.xml\"/&gt; &lt;mapper resource=\"mapper/VehicleMapper.xml\"/&gt;&lt;/mappers&gt; 123456&lt;!-- 使用完全限定资源定位符（URL） --&gt;&lt;mappers&gt; &lt;mapper url=\"file:///var/mappers/UserMapper.xml\"/&gt; &lt;mapper url=\"file:///var/mappers/RoleMapper.xml\"/&gt; &lt;mapper url=\"file:///var/mappers/VehicleMapper.xml\"/&gt;&lt;/mappers&gt; 总结：这节主要介绍一下Mybatis的全局配置文件中的常见配置，如果需要完整了解的可以参考官方文档。 源码地址： https://gitee.com/ooyhao/JavaRepo_Public/tree/master/Mybatis","link":"/2020/01/18/SSM/mybatis/2Mybatis%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"title":"四、Mybatis动态SQL","text":"Mybatis动态SQL 概念摘自官网：https://mybatis.org/mybatis-3/zh/dynamic-sql.html ​ MyBatis 的强大特性之一便是它的动态 SQL。如果你有使用 JDBC 或其它类似框架的经验，你就能体会到根据不同条件拼接 SQL 语句的痛苦。例如拼接时要确保不能忘记添加必要的空格，还要注意去掉列表最后一个列名的逗号。利用动态 SQL 这一特性可以彻底摆脱这种痛苦。 ​ 虽然在以前使用动态 SQL 并非一件易事，但正是 MyBatis 提供了可以被用在任意 SQL 映射语句中的强大的动态 SQL 语言得以改进这种情形。 ​ 动态 SQL 元素和 JSTL 或基于类似 XML 的文本处理器相似。在 MyBatis 之前的版本中，有很多元素需要花时间了解。MyBatis 3 大大精简了元素种类，现在只需学习原来一半的元素便可。MyBatis 采用功能强大的基于 OGNL 的表达式来淘汰其它大部分元素。 动态sql语句标签主要包括下面这几种： if choose…when…otherwise trim foreach bind if 标签当我们需要做一些判断的时候，可以使用到if标签，如下： 1234567891011&lt;select id=\"findUsersByUsernamePassword\" resultType=\"user\" &gt; select * from tb_user &lt;where&gt; &lt;if test=\"username != null\"&gt; username = #{username} &lt;/if&gt; &lt;if test=\"password != null\"&gt; and password = #{password} &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 所对应的Mapper接口方法： 12/*根据username和password查询*/List&lt;User&gt; findUsersByUsernamePassword(User user); 我们可以直接使用对象中的属性来取值。如果此时我们加了@Param(&quot;user&quot;) 12/*根据username和password查询*/List&lt;User&gt; findUsersByUsernamePassword(@Param(\"user\") User user); 对应的取值xml： 1234567891011&lt;select id=\"findUsersByUsernamePassword\" resultType=\"user\" &gt; select * from tb_user &lt;where&gt; &lt;if test=\"user.username != null\"&gt; username = #{user.username} &lt;/if&gt; &lt;if test=\"user.password != null\"&gt; and password = #{user.password} &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 解释：上述示例中，sql拼接结果如下： username 为null，password 不为null 1select * from tb_user where password = ? username 不为null，password为null 1select * from tb_user where username = ? username 不为null，password不为null 1select * from tb_user where username = ? and password = ? username 为null，password为null 1select * from tb_user 注意： 123&lt;if test=\"id != null and userId != '' and username =='2'\"&gt; refusalreason=#{remark,jdbcType=VARCHAR}&lt;/if&gt; mybatis是用OGNL表达式来解析的，在OGNL的表达式中，’2’会被解析成字符，java是强类型的，char 和一个string 会导致不等，所以if标签中的sql不会被解析。 if标签里，判断相等或不相等 1单个字符需要加.toString()，如：auditidentified =='2'.toString() if标签里，判断相等或不相等 1多个字符不需要加toString()，如：auditidentified !='2155' choose 标签​ 有时我们不希望用到所有的条件，比如用户有记录有id，user_id, username这几个属性，但是查询的时候希望有优先级，比如id存在的时候，只按id查询，如果id不存在，但是user_id存在，则按照user_id查询，如果前面两者都不存在，则按照username查询。 语句模板： 12345&lt;choose&gt; &lt;when test = \"a\"&gt;A&lt;/when&gt; &lt;when test = \"b\"&gt;B&lt;/when&gt; &lt;otherwise&gt;C&lt;/otherwise&gt;&lt;/choose&gt; 语句解释： 123456789解释：（只会执行一个条件,也必定会有一个条件执行） 这个语句相当Java中的 switch...case...default switch ==&gt; choose:定义语句范围 case ==&gt; when :满足当前条件 test 时执行 default ==&gt; otherwise :当前面的所有when都不满足的时候，使用otherwise的语句即：当表达式a计算结果为true时，则执行语句A, choose结束 当表达式b计算结果为true时，则执行语句B, choose结束 当前面的when都不满足时，执行C。choose结束。 示例语句如下： 12345678910111213141516&lt;select id=\"findUsersByIdOrUserIdOrUsername\" resultType=\"user\"&gt; select * from tb_user &lt;where&gt; &lt;choose&gt; &lt;when test=\"id != null\"&gt; id = #{id} &lt;/when&gt; &lt;when test=\"userId != null\"&gt; user_id = #{userId} &lt;/when&gt; &lt;otherwise&gt; username = #{username} &lt;/otherwise&gt; &lt;/choose&gt; &lt;/where&gt;&lt;/select&gt; 对应的Mapper接口方法： 12345/*查询，如果有id不为空，则直接按id查询，如果id为空，则按userId查询，否则按username查询*/List&lt;User&gt; findUsersByIdOrUserIdOrUsername( @Param(\"id\") Integer id, @Param(\"userId\") String userId, @Param(\"username\") String username); ​ 注意的同学可以发现，这里与之前的传参方法不同。后面将会有一篇专门介绍参数传递问题。这里先不细说。 trim 标签与trim相关的标签还有set和where标签，这是用来我们解决sql拼接的问题，之前自己手动凭借SQL的时候，需要非常注意 and，or和逗号问题，对应and|or，我们会在sql之前使用where 1 = 1,如下： 1select * from tb_user where 1 = 1 and ... 我们看一下下面这个sql: 123456789&lt;select id=\"findUsersByUsernamePassword\" resultType=\"user\" &gt; select * from tb_user where &lt;if test=\"username != null\"&gt; username = #{username} &lt;/if&gt; &lt;if test=\"password != null\"&gt; and password = #{password} &lt;/if&gt;&lt;/select&gt; 当我username为空，password不为空时，处理之后就会生成如下sql： 1select * from tb_user where and password = ? 上面这个sql就是一个错误的sql，但是mybatis中的动态sql帮我们提供了方法，下面我们看一下trim标签： 1234567&lt;trim prefix=\"\" prefixOverrides=\"\" suffix=\"\" suffixOverrides=\"\"&gt;&lt;/trim&gt;&lt;!-- 解释：prefix: 前缀,即在当前使用trim标签的最开头处添加指定元素。suffix: 后缀,即在当前使用trim标签的最结束处添加指定元素。prefixOverrides: 在最前面将元素指定的数据移除掉。suffixOverrides: 在最后面将元素指定的数据移除掉。--&gt; 所以我们使用trim标签来解决上面标签产生的问题，如下： 1234567891011&lt;select id=\"findUsersByUsernamePassword\" resultType=\"user\" &gt; select * from tb_user &lt;trim prefix=\"where\" prefixOverrides=\"and |or\"&gt; &lt;if test=\"username != null\"&gt; username = #{username} &lt;/if&gt; &lt;if test=\"password != null\"&gt; and password = #{password} &lt;/if&gt; &lt;/trim&gt;&lt;/select&gt; 注意：and后面的空格是必要添加的(官网介绍)。但是我测试的空格没有影响，为了规避问题，建议加上空格。 mybatis鉴于上述使用环境非常常见，将其封装为where标签，以及set标签，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;select id=\"findUsersByUsernamePassword\" resultType=\"user\" &gt; select * from tb_user &lt;where&gt; &lt;if test=\"username != null\"&gt; username = #{username} &lt;/if&gt; &lt;if test=\"password != null\"&gt; and password = #{password} &lt;/if&gt; &lt;/where&gt;&lt;/select&gt;&lt;update id=\"updateUserByUser\" &gt; update tb_user &lt;set&gt; &lt;if test=\"userId != null\"&gt; user_id = #{userId}, &lt;/if&gt; &lt;if test=\"username != null\"&gt; username = #{username}, &lt;/if&gt; &lt;if test=\"password != null\"&gt; password = #{password}, &lt;/if&gt; &lt;if test=\"email != null\"&gt; email = #{email}, &lt;/if&gt; &lt;if test=\"phone != null\"&gt; phone = #{phone}, &lt;/if&gt; &lt;if test=\"gender != null\"&gt; gender = #{gender}, &lt;/if&gt; &lt;if test=\"birthday != null\"&gt; birthday = #{birthday}, &lt;/if&gt; &lt;if test=\"status != null\"&gt; status = #{status}, &lt;/if&gt; &lt;if test=\"createTime != null\"&gt; create_time = #{createTime}, &lt;/if&gt; &lt;if test=\"createUser != null\"&gt; create_user = #{createUser}, &lt;/if&gt; &lt;if test=\"modifyUser != null\"&gt; modify_user = #{modifyUser}, &lt;/if&gt; &lt;if test=\"modifyTime != null\"&gt; modify_time = #{modifyTime}, &lt;/if&gt; &lt;/set&gt; where id = #{id}&lt;/update&gt; foreach标签​ 这个标签对我们来说从名字上，其实就知道是用来干啥的了。对，foreach标签就是用来循环迭代一些可迭代的元素，如，list，set，map，数组等。 试想以下，当我们需要根据多个id批量查询的时候，我们使用java代码需要如何操作： 1234567891011121314151617181920public void test() { String sql = \" select * from tb_user where id in \"; List&lt;Integer&gt; ids = new ArrayList&lt;&gt;(); ids.add(1); ids.add(2); ids.add(3); ids.add(4); String idSql = \"(\"; for (int i = 0; i &lt; ids.size(); i++) { if (i == ids.size() - 1) { idSql += ids.get(i) +\")\"; }else{ idSql += ids.get(i) + \",\"; } } sql += idSql; System.out.println(sql);}//select * from tb_user where id in (1,2,3,4); 可以看出，拼接这个sql非常繁琐，但是Mybatis提供的foreach可以很简单的实现,在此之前，我们看一下foreach标签： 1&lt;foreach collection=\"\" index=\"\" item=\"\" open=\"\" separator=\"\" close=\"\" &gt;&lt;/foreach&gt; 注意： 你可以将任何可迭代对象 如 List、Map 对象或者数组对象传递给 foreach 作为集合参数。当使用可迭代对象或者数组时。 collection 属性的书写方式，List -&gt; list/collection,Set-&gt;collection,[]数组 -&gt; array,Map -&gt; map. index 是当前迭代的次数，item 的值是本次迭代获取的元素。 当使用 Map 对象（或者 Map.Entry 对象的集合）时，index 是键，item 是值。 open表示拼接最前的元素 close表示拼接在最后的元素 separator表示遍历的各个元素之间的分隔符。 使用foreach实现： 123456789&lt;select id=\"findUsersByIds\" resultType=\"user\"&gt; select * from tb_user &lt;where&gt; id in &lt;foreach collection=\"list\" item=\"ite\" open=\"(\" separator=\",\" close=\")\"&gt; #{ite} &lt;/foreach&gt; &lt;/where&gt;&lt;/select&gt; 对应的mapper接口的方法： 1List&lt;User&gt; findUsersByIds(List&lt;Integer&gt; id); bind 标签bind 元素可以从 OGNL 表达式中创建一个变量并将其绑定到上下文： 1234567891011121314151617181920&lt;select id=\"findUserById\" resultType=\"user\"&gt; &lt;bind name=\"id\" value=\" id + 1\"/&gt; select * from tb_user where id = #{id}&lt;/select&gt;&lt;!-- ==&gt; Preparing: select * from tb_user where username like ? ==&gt; Parameters: %xxx%(String)--&gt;&lt;select id=\"findUsersByLikeUsername\" resultType=\"user\"&gt; &lt;bind name=\"name\" value=\" '%' +username+ '%' \"/&gt; select * from tb_user where username like #{name}&lt;/select&gt;&lt;!-- 模糊查询还可以这样 --&gt;&lt;select id=\"findUserByQueryVo\" parameterType=\"QueryVo\" resultType=\"User\"&gt; select * from tb_user where username like concat('%',#{user.username},'%')&lt;/select&gt; bind 标签比较简单，如上所示，可以将字符串进行拼接，也可以对传递进来的参数进行处理。 源码地址： https://gitee.com/ooyhao/JavaRepo_Public/tree/master/Mybatis","link":"/2020/01/18/SSM/mybatis/4Mybatis%E5%8A%A8%E6%80%81SQL/"},{"title":"五、Mybatis参数传递","text":"Mybatis参数传递 概述​ 参数传递在Mybatis中也是非常重要的。存在诸多情况，如下所介绍的单个参数，多个参数，对象，集合和数组等。 1234567891011121314151.单个的参数Mybatis不会做特殊处理 #{这里随便写什么都可以} 它都能把这里面的值取到2.传入对象POJO(普通的java类).. #{对象的属性名称}3.多个参数。Mybatis会做特殊处理。会把传入的参数自动封装成Map类型 Map 的key值就是从param1...paramN .. map.put(\"param1\",name) map.put(\"param2,id\") @param(\"name\") 可以使用这个注解 来自定义Map封装数据的key值。4.直接传入Map5.Collection(集合)类型(List,Set) ,数组。 Mybatis也会做特殊处理。。 如果是List或者Set 封装到map中 如果是数组 map.put(\"array\",你传入的数组) 单个参数Mapper接口的方法： 1List&lt;User&gt; findUsersByUsername(String username); Mapper.xml文件： 12345678&lt;select id=\"findUsersByUsername\" resultType=\"user\"&gt; select &lt;include refid=\"Base_Column_List\"/&gt; from tb_user &lt;where&gt; username = #{value} &lt;/where&gt;&lt;/select&gt; 注意： ​ 其中方法名和id一致，#{}中的参数名与方法中的参数名k可以不一致， 映射结果的时候，select 后的字段列表要和bean中的属性名一致， 如果不一致的可以用 as 来补充，特殊的也可以再mybatis中启用驼峰，比如create_time 和 createTime; 多个参数方法1：使用方法参数下标Mapper接口的方法： 1List&lt;User&gt; findUsersByUsernamePassword1(String username, String password); 对应的Mapper.xml: 123456789&lt;!--方法1.1--&gt;&lt;select id=\"findUsersByUsernamePassword1\" resultType=\"user\" &gt; select * from tb_user where username = #{arg0} and password = #{arg1}&lt;/select&gt;&lt;!--方法1.2--&gt;&lt;select id=\"findUsersByUsernamePassword1\" resultType=\"user\" &gt; select * from tb_user where username = #{0} and password = #{1}&lt;/select&gt; 注意： 有 些版本在使用上有不同，我使用的是 org.mybatis:mybatis:3.5.2版本，需要使用方法1.1。 方法2：使用注解 @Param 别名Mapper接口的方法： 12List&lt;User&gt; findUsersByUsernamePassword2(@Param(\"username\") String username, @Param(\"password\") String password); 对应的Mapper.xml文件： 12&lt;select id=\"findUsersByUsernamePassword2\" resultType=\"user\"&gt; select * from tb_user where username = #{username} and password = #{password}&lt;/select&gt; 方法3：使用实体Mapper接口的方法： 12345678910111213List&lt;User&gt; findUsersByUsernamePassword3(User user);// 调用方式@Testpublic void testFindUsersByUsernamePassword3(){ UserMapper mapper = sqlSession.getMapper(UserMapper.class); User user = new User(); user.setUsername(\"admin\"); user.setPassword(\"admin\"); List&lt;User&gt; users = mapper.findUsersByUsernamePassword3(user); System.out.println(users); sqlSession.close();} Mapper.xml文件： 123&lt;select id=\"findUsersByUsernamePassword3\" resultType=\"user\" parameterType=\"user\"&gt; select * from tb_user where username = #{username} and password = #{password}&lt;/select&gt; 方法4：使用MapMapper接口的方法： 123456789101112131415161718/*根据username和password查询*/List&lt;User&gt; findUsersByUsernamePassword(Map map);//-----调用方式@Testpublic void testFindUsersByUsernamePassword() { UserMapper mapper = sqlSession.getMapper(UserMapper.class); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"username\", \"admin\"); map.put(\"password\", \"admin\"); List&lt;User&gt; users = mapper.findUsersByUsernamePassword(map); System.out.println(users); sqlSession.close();}/*其中Map是mybatis自己配置好的直接使用就行。map中key的名字就是在#{}使用的个，map如何封装就不用了管了*/ 对应Mapper.xml文件： 123&lt;select id=\"findUsersByUsernamePassword\" resultType=\"user\" &gt; select * from tb_user where username = #{username} and password = #{password}&lt;/select&gt; 注意： ​ 这里使用Map来读取参数，需要注意的是，使用Map可以像实体那样访问，这里的key就像实体的属性名。 方法5：使用实体和@ParamMapper接口的方法： 1List&lt;User&gt; findUsersByUsernamePassword4(@Param(\"user\") User user); 对应Mapper.xml文件： 1234&lt;select id=\"findUsersByUsernamePassword4\" resultType=\"user\"&gt; select * from tb_user where username = #{user.username} and password = #{user.password}&lt;/select&gt; 注意： ​ 如果使用注解结合实体的方式来传参数的话，那么就需要使用实体.属性名的方式来读取参数。 方法6：使用Map和@ParamMapper接口的方法： 1List&lt;User&gt; findUsersByUsernamePassword5(@Param(\"map\") Map map); 对应的Mapper.xml文件： 1234&lt;select id=\"findUsersByUsernamePassword5\" resultType=\"user\"&gt; select * from tb_user where username = #{map.username} and password = #{map.password}&lt;/select&gt; 使用方法和方法5类似，不再赘述。 可迭代对象传递List前面的动态SQL中使用到了传递List的情况，这小节主要把几种迭代对象都使用一遍。 Mapper接口方法： 1List&lt;User&gt; findUsersByIds(List&lt;Integer&gt; id); 对应的Mapper.xml文件： 12345678910&lt;!--select * from tb_user WHERE id in ( ? , ? , ? ) --&gt;&lt;select id=\"findUsersByIds\" resultType=\"user\"&gt; select * from tb_user &lt;where&gt; id in &lt;foreach collection=\"list\" item=\"ite\" open=\"(\" separator=\",\" close=\")\"&gt; #{ite} &lt;/foreach&gt; &lt;/where&gt;&lt;/select&gt; 注意：List集合可以使用list，也可以使用collection。 使用SetMapper接口的方法： 1List&lt;User&gt; findUsersByIds1(Set&lt;Integer&gt; ids); 对应的Mapper.xml文件 123456&lt;select id=\"findUsersByIds2\" resultType=\"user\"&gt; select * from tb_user where id in &lt;foreach collection=\"collection\" item=\"item\" open=\"(\" separator=\",\" close=\")\"&gt; #{item} &lt;/foreach&gt;&lt;/select&gt; 注意：Set集合没有像List那样，Set只能使用collection。 传递数组Mapper接口的方法： 1List&lt;User&gt; findUsersByIds2(Integer[] ids); 对应的Mapper.xml文件 1234567&lt;select id=\"findUsersByIds1\" resultType=\"user\"&gt; select * from tb_user where id in &lt;foreach collection=\"array\" item=\"item\" open=\"(\" separator=\",\" close=\")\"&gt; #{item} &lt;/foreach&gt;&lt;/select&gt; 传递Map使用Map来做保存操作: 1void saveUserByMap1(Map&lt;String,Object&gt; map); 对应的Mapper.xml文件： 1234&lt;select id=\"saveUserByMap1\"&gt; insert into tb_user (user_id,username,password) values (#{user_id},#{username},#{password});&lt;/select&gt; 单元测试： 12345678910@Testpublic void testSaveUserByMap1(){UserMapper mapper = sqlSession.getMapper(UserMapper.class);Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put(\"user_id\",\"root\"); map.put(\"username\",\"root\"); map.put(\"password\",\"root\"); mapper.saveUserByMap1(map); sqlSession.close(); } 传递List-Map这里使用List和Map结合使用实现批量操作 Mapper接口文件的方法： 1void saveUserByMap(List&lt;Map&lt;String,Object&gt;&gt; listMap); 对应的Mapper.xml文件： 1234567&lt;!--insert into tb_user (user_id,username,password)values (?,?,?) , (?,?,?) --&gt;&lt;select id=\"saveUserByMap\"&gt; insert into tb_user (user_id,username,password)values &lt;foreach collection=\"collection\" item=\"item\" separator=\",\"&gt; (#{item.userId},#{item.username},#{item.password}) &lt;/foreach&gt;&lt;/select&gt; 单元测试： 123456789101112131415161718@Testpublic void testSaveUserByMap(){ UserMapper mapper = sqlSession.getMapper(UserMapper.class); List&lt;Map&lt;String,Object&gt;&gt; list = new ArrayList&lt;&gt;(); Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put(\"userId\",\"mybatis1\"); map.put(\"username\",\"mybatis1\"); map.put(\"password\",\"mybatis1\"); Map&lt;String,Object&gt; map1 = new HashMap&lt;&gt;(); map1.put(\"userId\",\"mybatis2\"); map1.put(\"username\",\"mybatis2\"); map1.put(\"password\",\"mybatis2\"); list.add(map); list.add(map1); mapper.saveUserByMap(list); sqlSession.close();} 源码地址： https://gitee.com/ooyhao/JavaRepo_Public/tree/master/Mybatis","link":"/2020/01/18/SSM/mybatis/5Mybatis%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/"},{"title":"六、一级缓存和二级缓存","text":"一级缓存和二级缓存 本文参考了下文： https://www.cnblogs.com/happyflyingpig/p/7739749.html\\ 一级缓存​ Mybatis 对缓存提供了支持，在没有配置的情况下，Mybatis默认只开启一级缓存，一级缓存其实就是依托于SqlSession，即使用同一个SqlSession操作下，如果Sql语句和参数都没有变化，SqlSession第一次会发送SQL，再缓存没有失效的情况下，后面的查询，就会直接去二级缓存中查找，不再像数据库发送SQL查询。 图片来源于上述链接博文： 为什么要使用一级缓存，不用多说也知道个大概。但是还有几个问题我们要注意一下。 1、一级缓存的生命周期有多长？ ​ a、MyBatis在开启一个数据库会话时，会创建一个新的SqlSession对象，SqlSession对象中会有一个新的Executor对象。Executor对象中持有一个新的PerpetualCache对象；当会话结束时，SqlSession对象及其内部的Executor对象还有PerpetualCache对象也一并释放掉。 b、如果SqlSession调用了close()方法，会释放掉一级缓存PerpetualCache对象，一级缓存将不可用。 c、如果SqlSession调用了clearCache()，会清空PerpetualCache对象中的数据，但是该对象仍可使用。 d、SqlSession中执行了任何一个update操作(update()、delete()、insert()) ，都会清空PerpetualCache对象的数据，但是该对象可以继续使用 2、怎么判断某两次查询是完全相同的查询？ mybatis认为，对于两次查询，如果以下条件都完全一样，那么就认为它们是完全相同的两次查询。 2.1 传入的statementId 2.2 查询时要求的结果集中的结果范围 2.3 这次查询所产生的最终要传递给JDBC java.sql.Preparedstatement的Sql语句字符串（boundSql.getSql() ） 2.4 传递给java.sql.Statement要设置的参数值 一级缓存验证我们依托于前面的示例， Role: 12345678910111213141516@NoArgsConstructor@AllArgsConstructor@Getter@Setter@ToStringpublic class Role{ private Integer id; private String roleName; private String description; private Integer status; private Date createTime; private String createUser; private Date modifyTime; private String modifyUser;} RoleMapper: 123public interface RoleMapper { Role findById(Integer id);} 下面是测试一级缓存的方法： 123456789101112131415161718192021public class AppTest { SqlSession sqlSession = null; @Before public void init(){ String resource = \"mybatis.configuration.xml\"; InputStream inputStream = AppTest.class.getClassLoader().getResourceAsStream(resource); sqlSession = new SqlSessionFactoryBuilder().build(inputStream).openSession(true); } @Test public void testFindRoleById(){ RoleMapper mapper = sqlSession.getMapper(RoleMapper.class); Role role1 = mapper.findById(1); Role role2 = mapper.findById(1); System.out.println(role1); System.out.println(role2); sqlSession.close(); }} 测试结果： 二级缓存Mybatis的二级缓存是SqlSessionFactory层面的，一级缓存是SqlSession层面的。 默认情况下，只启用了本地的会话缓存，也就是一级缓存，基于SqlSession的 ，但是如果需要开启二级缓存的话，只需要在Mapper.xml文件中添加一行： 1&lt;cache/&gt; 基本上就是这样。这个简单语句的效果如下: 映射语句文件中的所有 select 语句的结果将会被缓存。 映射语句文件中的所有 insert、update 和 delete 语句会刷新缓存。 缓存会使用最近最少使用算法（LRU, Least Recently Used）算法来清除不需要的缓存。 缓存不会定时进行刷新（也就是说，没有刷新间隔）。 缓存会保存列表或对象（无论查询方法返回哪种）的 1024 个引用。 缓存会被视为读/写缓存，这意味着获取到的对象并不是共享的，可以安全地被调用者修改，而不干扰其他调用者或线程所做的潜在修改。 二级缓存验证RoleMapper.xml： 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"com.ooyhao.mybatis4.mapper.RoleMapper\"&gt; &lt;!--开启二级缓存--&gt; &lt;cache /&gt; &lt;resultMap id=\"base_map_4\" type=\"role\"&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\" /&gt; &lt;result column=\"role_name\" jdbcType=\"VARCHAR\" property=\"roleName\"/&gt; &lt;result column=\"description\" jdbcType=\"VARCHAR\" property=\"description\"/&gt; &lt;result column=\"status\" jdbcType=\"INTEGER\" property=\"status\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"create_user\" jdbcType=\"VARCHAR\" property=\"createUser\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;result column=\"modify_user\" jdbcType=\"VARCHAR\" property=\"modifyUser\"/&gt; &lt;/resultMap&gt; &lt;select id=\"findById\" resultMap=\"base_map_4\"&gt; select * from tb_role where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 如xml文件所述，我们仅在RoleMapper文件下添加&lt;cache/&gt; 用于开启当前namespace 的缓存。 单元测试方法： (需要注意，我们需要将自动提交关闭，即openSession()的参数设置为false，或不填，否则无法进行缓存) 12345678910111213141516171819202122232425@Testpublic void testFindRoleByIdWithCache(){ //二级缓存是在SqlSessionFactory层面的。 String resource = \"mybatis.configuration.xml\"; InputStream stream = AppTest.class.getClassLoader().getResourceAsStream(resource); SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder(); //创建SqlSessionFactory SqlSessionFactory build = builder.build(stream); SqlSession sqlSession1 = build.openSession(); RoleMapper mapper = sqlSession1.getMapper(RoleMapper.class); Role role1 = mapper.findById(1); System.out.println(role1); RoleMapper mapper1 = sqlSession1.getMapper(RoleMapper.class); Role role = mapper1.findById(1); System.out.println(role); sqlSession1.commit(); SqlSession sqlSession2 = build.openSession();//创建了一个新的session。 RoleMapper roleMapper = sqlSession2.getMapper(RoleMapper.class); Role role2 = roleMapper.findById(1); System.out.println(role2); sqlSession2.commit();} 此时测试结果为：(报未序列化异常) 所以，我们需要为Role对象加上Serializable接口。 如果我们标注为缓存是只读的话，那么不序列化也不会保错： 1&lt;cache readOnly=\"true\" /&gt; 测试结果： 这是启用二级缓存之后的执行结果，可以发现查询了3次，但是实际仅仅只发送了一次SQL，我们可以看第二次的Cache Hit Ratio 是0.3333，即三分之一，我们总共查询了三次，在二级缓存中的命中的次数是一次，所以是0.333. 我们像下面这样，增加一次查询： 12345678910111213141516171819202122232425262728293031323334public class AppTest { @Test public void testFindRoleByIdWithCache(){ //二级缓存是在SqlSessionFactory层面的。 String resource = \"mybatis.configuration.xml\"; InputStream stream = AppTest.class.getClassLoader().getResourceAsStream(resource); SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder(); //创建SqlSessionFactory SqlSessionFactory build = builder.build(stream); SqlSession sqlSession1 = build.openSession(); RoleMapper mapper = sqlSession1.getMapper(RoleMapper.class); Role role1 = mapper.findById(1); System.out.println(role1); RoleMapper mapper1 = sqlSession1.getMapper(RoleMapper.class); Role role = mapper1.findById(1); System.out.println(role); sqlSession1.commit(); SqlSession sqlSession2 = build.openSession(); RoleMapper roleMapper = sqlSession2.getMapper(RoleMapper.class); Role role2 = roleMapper.findById(1); System.out.println(role2); sqlSession2.commit(); SqlSession sqlSession3 = build.openSession(); RoleMapper roleMapper3 = sqlSession3.getMapper(RoleMapper.class); Role role3 = roleMapper3.findById(1); System.out.println(role3); sqlSession3.commit(); }} 执行结果如下： 二级缓存详述我们知道了如何操作二级缓存，下面我们对二级缓存进行更加详细的了解。 1&lt;cache/&gt; 这个简单语句的效果如下: 映射语句文件中的所有 select 语句的结果将会被缓存。 映射语句文件中的所有 insert、update 和 delete 语句会刷新缓存。 缓存会使用最近最少使用算法（LRU, Least Recently Used）算法来清除不需要的缓存。 缓存不会定时进行刷新（也就是说，没有刷新间隔）。 缓存会保存列表或对象（无论查询方法返回哪种）的 1024 个引用。 缓存会被视为读/写缓存，这意味着获取到的对象并不是共享的，可以安全地被调用者修改，而不干扰其他调用者或线程所做的潜在修改。 这些属性可以通过 cache 元素的属性来修改。比如： 12345678910111213141516171819202122&lt;!--开启二级缓存--&gt;&lt;!--开启本mapper的namespace下的二级缓存--&gt;&lt;cache eviction=\"FIFO\" flushInterval=\"60000\" readOnly=\"true\" size=\"512\" /&gt;&lt;resultMap id=\"base_map_4\" type=\"role\"&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\" /&gt; &lt;result column=\"role_name\" jdbcType=\"VARCHAR\" property=\"roleName\"/&gt; &lt;result column=\"description\" jdbcType=\"VARCHAR\" property=\"description\"/&gt; &lt;result column=\"status\" jdbcType=\"INTEGER\" property=\"status\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"create_user\" jdbcType=\"VARCHAR\" property=\"createUser\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;result column=\"modify_user\" jdbcType=\"VARCHAR\" property=\"modifyUser\"/&gt;&lt;/resultMap&gt;&lt;!--可以通过设置useCache来规定这个sql是否开启缓存，ture是开启，false是关闭--&gt;&lt;select id=\"findById\" resultMap=\"base_map_4\" useCache=\"true\" &gt; select * from tb_role where id = #{id}&lt;/select&gt; ​ 这个更高级的配置创建了一个FIFO(first in first out) 缓存，每隔60秒刷新，最多可以存储结果对象或列表的512个引用，而且返回的对象被认为是只读的，因此对他们进行修改可能会在不同线程中的调用者产生冲突。 可用的清楚策略有： LRU -最近最少使用：移除最长时间不被使用的对象。（默认） FIFO -先进先出：按对象进入缓存的顺序来移除它们。 SOFT - 软引用：基于垃圾回收器状态和软引用规则移除对象。 WEAK - 弱引用：更积极地基于垃圾收集器状态和弱引用规则移除对象。 flushInterval（刷新间隔）属性可以被设置为任意的正整数，设置的值应该是一个以毫秒为单位的合理时间量。 默认情况是不设置，也就是没有刷新间隔，缓存仅仅会在调用语句时刷新。 size（引用数目）属性可以被设置为任意正整数，要注意欲缓存对象的大小和运行环境中可用的内存资源。默认值是 1024。 readOnly（只读）属性可以被设置为 true 或 false。只读的缓存会给所有调用者返回缓存对象的相同实例。 因此这些对象不能被修改。这就提供了可观的性能提升。而可读写的缓存会（通过序列化）返回缓存对象的拷贝。 速度上会慢一些，但是更安全，因此默认值是 false。 提示： 二级缓存是事务性的。这意味着，当 SqlSession 完成并提交时，或是完成并回滚，但没有执行 flushCache=true 的 insert/delete/update 语句时，缓存会获得更新。 总结： ​ 至此，我们学习了Mybatis的基础知识了，当然，如果我们需要深入理解Mybatis，我们还有很多要学习，所以，学习Mybatis，我们才刚刚开始。后面，我们学习一下如何和Spring整合操作。 源码地址： https://gitee.com/ooyhao/JavaRepo_Public/tree/master/Mybatis","link":"/2020/01/18/SSM/mybatis/6Mybatis%E7%9A%84%E4%B8%80%E7%BA%A7%E7%BC%93%E5%AD%98%E5%92%8C%E4%BA%8C%E7%BA%A7%E7%BC%93%E5%AD%98/"},{"title":"八、Mybatis整合Spring操作DB","text":"Mybatis整合Spring操作DB：​ 这一节我们主要看一下如何使用Spring整合Mybatis操作，同时也是基于操作方面的，对于其Spring如何操作Mybatis的，还需要后续的学习。虽然之前的Spring in action 4 中涉及到了SSM整合，但是在学习spring之后，再次整合Spring加Mybatis，会体会到不一样的感觉。 项目结构图 项目的POM依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;spring-mybatis&lt;/artifactId&gt; &lt;groupId&gt;com.ooyhao.mybatis&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;spring-mybatis-01&lt;/artifactId&gt; &lt;name&gt;spring-mybatis-01&lt;/name&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.1.9.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;5.1.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis依赖包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis整合spring--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.1.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;5.1.9.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;5.1.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--日志--&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.8.0-beta0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt; &lt;version&gt;1.8.0-beta0&lt;/version&gt; &lt;/dependency&gt; &lt;!--lombok--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.8&lt;/version&gt; &lt;/dependency&gt; &lt;!--jackson--&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.10.0.pr3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.10.0.pr3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.10.0.pr3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;5.1.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; ​ POM依赖也需要注意，所以我把完整的POM依赖贴出来，有的时候项目没问题，可能就是依赖搞错了导致项目运行不了、 Mybatis的全局配置1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!--属性配置文件--&gt; &lt;!--&lt;properties resource=\"application.properties\"/&gt;--&gt; &lt;!--设置--&gt; &lt;settings&gt; &lt;!--&lt;setting name=\"cacheEnabled\" value=\"true\"/&gt;--&gt; &lt;setting name=\"mapUnderscoreToCamelCase\" value=\"true\"/&gt; &lt;!--&lt;setting name=\"logImpl\" value=\"STDOUT_LOGGING\"/&gt;--&gt; &lt;/settings&gt; &lt;!--别名--&gt; &lt;!--&lt;typeAliases&gt; &lt;package name=\"com.ooyhao.mybatis.bean\"/&gt; &lt;/typeAliases&gt;--&gt; &lt;!--Spring中配置--&gt; &lt;!--&lt;environments default=\"dev\"&gt; &lt;environment id=\"dev\"&gt; &lt;transactionManager type=\"JDBC\"&gt;&lt;/transactionManager&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"${jdbc.driver}\"/&gt; &lt;property name=\"url\" value=\"${jdbc.url}\"/&gt; &lt;property name=\"username\" value=\"${jdbc.username}\"/&gt; &lt;property name=\"password\" value=\"${jdbc.password}\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt;--&gt; &lt;!--Mapper xml文件--&gt; &lt;!--&lt;mappers&gt; &lt;mapper resource=\"mapper/RoleMapper.xml\"/&gt; &lt;/mappers&gt;--&gt;&lt;/configuration&gt; ​ 可以看出，这里只是配置了一下开启驼峰命名，因为这一项在配置类中配置无效（测试结果），所以在配置文件中保留了这一项，其他的均可以通过配置类来配置。 properties文件1234567891011# 配合数据源jdbc.driver= com.mysql.jdbc.Driverjdbc.url = jdbc:mysql://120.79.167.88:3306/mybatis?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true&amp;autoReconnect=true&amp;useSSL=falsejdbc.username = rootjdbc.password = root#配置Mybatis参数mybatis.configuration = mybatis-configuration.xmlmybatis.mapperLocations = mapper/*.xmlmybatis.typeAliasesPackage = com.ooyhao.mybatis.bean Spring配置类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103package com.ooyhao.mybatis.config;import com.alibaba.druid.pool.DruidDataSource;import org.apache.ibatis.logging.stdout.StdOutImpl;import org.mybatis.spring.SqlSessionFactoryBean;import org.mybatis.spring.annotation.MapperScan;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;import org.springframework.core.io.ClassPathResource;import org.springframework.core.io.Resource;import org.springframework.core.io.support.PathMatchingResourcePatternResolver;import org.springframework.jdbc.datasource.DataSourceTransactionManager;import org.springframework.transaction.annotation.EnableTransactionManagement;import javax.sql.DataSource;/** * 描述: * 类【AppConfig】 * * @author ouYangHao * @create 2019-09-20 16:58 */@Configuration //标注为一个配置类@PropertySource(value = \"classpath:application.properties\") //加载属性文件@ComponentScan(basePackages = \"com.ooyhao.mybatis\") //组件扫描@MapperScan(basePackages = {\"com.ooyhao.mybatis.mapper\"}) //mapper文件的扫描@EnableTransactionManagement //开启事务管理public class AppConfig { @Value(\"${jdbc.url}\") private String url; @Value(\"${jdbc.driver}\") private String driverClassName; @Value(\"${jdbc.username}\") private String username; @Value(\"${jdbc.password}\") private String password; @Value(\"${mybatis.configuration}\") private String mybatisConfiguration; @Value(\"${mybatis.mapperLocations}\") private String mybatisMapperLocations; @Value(\"${mybatis.typeAliasesPackage}\") private String mybatisTypeAliasesPackage; /*配置数据源*/ @Bean public DataSource dataSource(){ DruidDataSource druidDataSource = new DruidDataSource(); druidDataSource.setUrl(url); druidDataSource.setDriverClassName(driverClassName); druidDataSource.setUsername(username); druidDataSource.setPassword(password); return druidDataSource; } /*Mybatis的全局配置*/ @Bean public SqlSessionFactoryBean sqlSessionFactoryBean(DataSource dataSource) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); /*配置Mybatis的全局配置文件*/ ClassPathResource resource = new ClassPathResource(mybatisConfiguration); sqlSessionFactoryBean.setConfigLocation(resource); /*配置Mapper.xml文件的路径*/ PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); Resource[] resources = resolver.getResources(mybatisMapperLocations); sqlSessionFactoryBean.setMapperLocations(resources); /*配置别名包*/ sqlSessionFactoryBean.setTypeAliasesPackage(mybatisTypeAliasesPackage); /*设置数据源，位置有要求，需要在下面几项之前*/ sqlSessionFactoryBean.setDataSource(dataSource); /*配置驼峰命名*/ sqlSessionFactoryBean.getObject().getConfiguration() .setMapUnderscoreToCamelCase(true); /*配置日志类*/ sqlSessionFactoryBean.getObject().getConfiguration() .setLogImpl(StdOutImpl.class); /*设置开启缓存*/ sqlSessionFactoryBean.getObject().getConfiguration().setCacheEnabled(true); return sqlSessionFactoryBean; } /*配置数据源事务管理器，需要将数据源注入*/ @Bean public DataSourceTransactionManager transactionManager(DataSource dataSource){ DataSourceTransactionManager transactionManager = new DataSourceTransactionManager(); transactionManager.setDataSource(dataSource); return transactionManager; }} 提示：配置说明如注释； RoleMapper 文件1234public interface RoleMapper { Role findById(Integer id); void deleteById(Integer id);} RoleMapper XML123456789101112131415161718192021222324252627282930313233&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"com.ooyhao.mybatis.mapper.RoleMapper\"&gt; &lt;!--开启二级缓存--&gt; &lt;!--开启本mapper的namespace下的二级缓存--&gt; &lt;cache eviction=\"FIFO\" flushInterval=\"60000\" readOnly=\"true\" size=\"512\" /&gt; &lt;resultMap id=\"base_map\" type=\"role\"&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\" /&gt; &lt;result column=\"role_name\" jdbcType=\"VARCHAR\" property=\"roleName\"/&gt; &lt;result column=\"description\" jdbcType=\"VARCHAR\" property=\"description\"/&gt; &lt;result column=\"status\" jdbcType=\"INTEGER\" property=\"status\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"create_user\" jdbcType=\"VARCHAR\" property=\"createUser\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;result column=\"modify_user\" jdbcType=\"VARCHAR\" property=\"modifyUser\"/&gt; &lt;/resultMap&gt; &lt;!--可以通过设置useCache来规定这个sql是否开启缓存，ture是开启，false是关闭--&gt; &lt;select id=\"findById\" resultMap=\"base_map\" useCache=\"true\" &gt; select * from tb_role where id = #{id} &lt;/select&gt; &lt;delete id=\"deleteById\"&gt; delete from tb_role where id = #{id} &lt;/delete&gt;&lt;/mapper&gt; RoleService12345678910111213141516171819@Servicepublic class RoleService { @Autowired private RoleMapper roleMapper;// @Transactional public Role findById(Integer id){ roleMapper.findById(id); return roleMapper.findById(id); } @Transactional public void deleteById(Integer id){ roleMapper.deleteById(id); int i = 1/0; }} 单元测试类123456789101112131415161718192021222324public class AppTest { AnnotationConfigApplicationContext context = null; @Before public void init(){ context = new AnnotationConfigApplicationContext(AppConfig.class); } @Test public void testFindById() { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class); RoleService bean = context.getBean(RoleService.class); Role role = bean.findById(1); System.out.println(role); } @Test public void testDeleteById(){ RoleService service = context.getBean(RoleService.class); service.deleteById(7); }} 这里顺便测试一下Mapper的一级缓存和二级缓存： 当我们在查询Service上不使用事务注解的时候： 测试结果如下： 可以看出，这种情况下我们走的是二级缓存，即，在此情况下，一级缓存是没有生效的。 当我们在查询Service上加上事务时： 测试结果如下： ​ 可以看出此时走的是一级缓存，因为二级缓存的击中率都是0，但是查询了两次，只发送一次SQL，所以此时可以看出是查询的一级缓存。 总结： ​ 至此，Spring的基础和Mybatis的基础就完整的过了一遍了，将Mybatis的各种基础用法，动态SQL，结果映射都使用了一遍，同时前面的Spring中也将Spring的基础再次熟悉了一遍，比如自动装配，AOP，同时知道了如何不使用Web.xml和其他配置文件的情况下，搭建起一个web项目。 源码地址： https://gitee.com/ooyhao/JavaRepo_Public/tree/master/Mybatis","link":"/2020/01/18/SSM/mybatis/8Mybatis%E6%95%B4%E5%90%88Spring/"},{"title":"一、Windows上安装单机版Nacos","text":"Windows上安装单机版Nacos Nacos官网：https://nacos.io/zh-cn/ 下载Nacos到github (https://github.com/alibaba/nacos)下载安装程序,点击releases，选择需要下载的版本。zip包。 解压安装包下载并解压，文件目录如下： 部署Nacos我们可以参考官网：https://nacos.io/zh-cn/docs/deployment.html 创建数据库1CREATE DATABASE nacos_devtest; 初始化数据库初始化Sql位于conf目录下的 nacos-mysql.sql 文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194/******************************************//* 数据库全名 = nacos_config *//* 表名称 = config_info *//******************************************/CREATE TABLE `config_info` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` varchar(255) NOT NULL COMMENT 'data_id', `group_id` varchar(255) DEFAULT NULL, `content` longtext NOT NULL COMMENT 'content', `md5` varchar(32) DEFAULT NULL COMMENT 'md5', `gmt_create` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', `src_user` text COMMENT 'source user', `src_ip` varchar(20) DEFAULT NULL COMMENT 'source ip', `app_name` varchar(128) DEFAULT NULL, `tenant_id` varchar(128) DEFAULT '' COMMENT '租户字段', `c_desc` varchar(256) DEFAULT NULL, `c_use` varchar(64) DEFAULT NULL, `effect` varchar(64) DEFAULT NULL, `type` varchar(64) DEFAULT NULL, `c_schema` text, PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfo_datagrouptenant` (`data_id`,`group_id`,`tenant_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = config_info_aggr *//******************************************/CREATE TABLE `config_info_aggr` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` varchar(255) NOT NULL COMMENT 'data_id', `group_id` varchar(255) NOT NULL COMMENT 'group_id', `datum_id` varchar(255) NOT NULL COMMENT 'datum_id', `content` longtext NOT NULL COMMENT '内容', `gmt_modified` datetime NOT NULL COMMENT '修改时间', `app_name` varchar(128) DEFAULT NULL, `tenant_id` varchar(128) DEFAULT '' COMMENT '租户字段', PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfoaggr_datagrouptenantdatum` (`data_id`,`group_id`,`tenant_id`,`datum_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='增加租户字段';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = config_info_beta *//******************************************/CREATE TABLE `config_info_beta` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` varchar(255) NOT NULL COMMENT 'data_id', `group_id` varchar(128) NOT NULL COMMENT 'group_id', `app_name` varchar(128) DEFAULT NULL COMMENT 'app_name', `content` longtext NOT NULL COMMENT 'content', `beta_ips` varchar(1024) DEFAULT NULL COMMENT 'betaIps', `md5` varchar(32) DEFAULT NULL COMMENT 'md5', `gmt_create` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', `src_user` text COMMENT 'source user', `src_ip` varchar(20) DEFAULT NULL COMMENT 'source ip', `tenant_id` varchar(128) DEFAULT '' COMMENT '租户字段', PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfobeta_datagrouptenant` (`data_id`,`group_id`,`tenant_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info_beta';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = config_info_tag *//******************************************/CREATE TABLE `config_info_tag` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` varchar(255) NOT NULL COMMENT 'data_id', `group_id` varchar(128) NOT NULL COMMENT 'group_id', `tenant_id` varchar(128) DEFAULT '' COMMENT 'tenant_id', `tag_id` varchar(128) NOT NULL COMMENT 'tag_id', `app_name` varchar(128) DEFAULT NULL COMMENT 'app_name', `content` longtext NOT NULL COMMENT 'content', `md5` varchar(32) DEFAULT NULL COMMENT 'md5', `gmt_create` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', `src_user` text COMMENT 'source user', `src_ip` varchar(20) DEFAULT NULL COMMENT 'source ip', PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfotag_datagrouptenanttag` (`data_id`,`group_id`,`tenant_id`,`tag_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info_tag';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = config_tags_relation *//******************************************/CREATE TABLE `config_tags_relation` ( `id` bigint(20) NOT NULL COMMENT 'id', `tag_name` varchar(128) NOT NULL COMMENT 'tag_name', `tag_type` varchar(64) DEFAULT NULL COMMENT 'tag_type', `data_id` varchar(255) NOT NULL COMMENT 'data_id', `group_id` varchar(128) NOT NULL COMMENT 'group_id', `tenant_id` varchar(128) DEFAULT '' COMMENT 'tenant_id', `nid` bigint(20) NOT NULL AUTO_INCREMENT, PRIMARY KEY (`nid`), UNIQUE KEY `uk_configtagrelation_configidtag` (`id`,`tag_name`,`tag_type`), KEY `idx_tenant_id` (`tenant_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_tag_relation';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = group_capacity *//******************************************/CREATE TABLE `group_capacity` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键ID', `group_id` varchar(128) NOT NULL DEFAULT '' COMMENT 'Group ID，空字符表示整个集群', `quota` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '配额，0表示使用默认值', `usage` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '使用量', `max_size` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个配置大小上限，单位为字节，0表示使用默认值', `max_aggr_count` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '聚合子配置最大个数，，0表示使用默认值', `max_aggr_size` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值', `max_history_count` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '最大变更历史数量', `gmt_create` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', PRIMARY KEY (`id`), UNIQUE KEY `uk_group_id` (`group_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='集群、各Group容量信息表';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = his_config_info *//******************************************/CREATE TABLE `his_config_info` ( `id` bigint(64) unsigned NOT NULL, `nid` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `data_id` varchar(255) NOT NULL, `group_id` varchar(128) NOT NULL, `app_name` varchar(128) DEFAULT NULL COMMENT 'app_name', `content` longtext NOT NULL, `md5` varchar(32) DEFAULT NULL, `gmt_create` datetime NOT NULL DEFAULT '2010-05-05 00:00:00', `gmt_modified` datetime NOT NULL DEFAULT '2010-05-05 00:00:00', `src_user` text, `src_ip` varchar(20) DEFAULT NULL, `op_type` char(10) DEFAULT NULL, `tenant_id` varchar(128) DEFAULT '' COMMENT '租户字段', PRIMARY KEY (`nid`), KEY `idx_gmt_create` (`gmt_create`), KEY `idx_gmt_modified` (`gmt_modified`), KEY `idx_did` (`data_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='多租户改造';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = tenant_capacity *//******************************************/CREATE TABLE `tenant_capacity` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键ID', `tenant_id` varchar(128) NOT NULL DEFAULT '' COMMENT 'Tenant ID', `quota` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '配额，0表示使用默认值', `usage` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '使用量', `max_size` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个配置大小上限，单位为字节，0表示使用默认值', `max_aggr_count` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '聚合子配置最大个数', `max_aggr_size` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值', `max_history_count` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '最大变更历史数量', `gmt_create` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', PRIMARY KEY (`id`), UNIQUE KEY `uk_tenant_id` (`tenant_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='租户容量信息表';CREATE TABLE `tenant_info` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `kp` varchar(128) NOT NULL COMMENT 'kp', `tenant_id` varchar(128) default '' COMMENT 'tenant_id', `tenant_name` varchar(128) default '' COMMENT 'tenant_name', `tenant_desc` varchar(256) DEFAULT NULL COMMENT 'tenant_desc', `create_source` varchar(32) DEFAULT NULL COMMENT 'create_source', `gmt_create` bigint(20) NOT NULL COMMENT '创建时间', `gmt_modified` bigint(20) NOT NULL COMMENT '修改时间', PRIMARY KEY (`id`), UNIQUE KEY `uk_tenant_info_kptenantid` (`kp`,`tenant_id`), KEY `idx_tenant_id` (`tenant_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='tenant_info';CREATE TABLE users ( username varchar(50) NOT NULL PRIMARY KEY, password varchar(500) NOT NULL, enabled boolean NOT NULL);CREATE TABLE roles ( username varchar(50) NOT NULL, role varchar(50) NOT NULL);INSERT INTO users (username, password, enabled) VALUES ('nacos', '$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu', TRUE);INSERT INTO roles (username, role) VALUES ('nacos', 'ROLE_ADMIN'); 此时，我们数据库已经初始化准备好了。 修改数据库配置打开conf目录下的application.properties文件，添加下面内容： 123456spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://127.0.0.1:3306/nacos_devtest? characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=rootdb.password=root 启动Nacos进入 bin目录中，双击startup.sh，启动Nacos。 访问Nacos服务登录此时我们访问：localhost:8848/nacos.会出现登录界面：使用nacos/nacos，进行登录。 服务列表如图所示，我们可以看到服务列表，但是由于我们没有注册任何的服务生产者和服务消费者，所以此时的列表是空的。 至此，在Windows上安装单机版Nacos就完成了。So Easy！","link":"/2020/01/18/SSM/springcloudalibaba/0.1.Windows%E5%AE%89%E8%A3%85%E5%8D%95%E6%9C%BA%E7%89%88Nacos/"},{"title":"十九、Sentinel规则之熔断降级规则","text":"除了流量控制以外，对调用链路中不稳定的资源进行熔断降级也是保障高可用的重要措施之一。由于调用关系的复杂性，如果调用链路中的某个资源不稳定，最终会导致请求发生堆积。Sentinel 熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或异常比例升高），对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联错误。当资源被降级后，在接下来的降级时间窗口之内，对该资源的调用都自动熔断（默认行为是抛出 DegradeException）。 降级策略我们通常用以下几种方式来衡量资源是否处于稳定的状态： 平均响应时间 (DEGRADE_GRADE_RT)：当 1s 内持续进入 5 个请求，对应时刻的平均响应时间（秒级）均超过阈值（count，以 ms 为单位），那么在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方法的调用都会自动地熔断（抛出 DegradeException）。注意 Sentinel 默认统计的 RT 上限是 4900 ms，超出此阈值的都会算作 4900 ms，若需要变更此上限可以通过启动配置项 -Dcsp.sentinel.statistic.max.rt=xxx 来配置。 异常比例 (DEGRADE_GRADE_EXCEPTION_RATIO)：当资源的每秒请求量 &gt;= 5，并且每秒异常总数占通过量的比值超过阈值（DegradeRule 中的 count）之后，资源进入降级状态，即在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方法的调用都会自动地返回。异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。 异常数 (DEGRADE_GRADE_EXCEPTION_COUNT)：当资源近 1 分钟的异常数目超过阈值之后会进行熔断。注意由于统计时间窗口是分钟级别的，若 timeWindow 小于 60s，则结束熔断状态后仍可能再进入熔断状态。 注意：异常降级仅针对业务异常，对 Sentinel 限流降级本身的异常（BlockException）不生效。为了统计异常比例或异常数，需要通过 Tracer.trace(ex) 记录业务异常。示例： 降级演示平均响应时间RT初始化降级规则： 12345678910111213141516171819public static void main(String[] args) { SpringApplication.run(SentinelDegradeRuleApplication.class, args); initDegradeRuleForRT();}public static void initDegradeRuleForRT(){ List&lt;DegradeRule&gt; rules = new ArrayList&lt;&gt; (); DegradeRule rule = new DegradeRule(); //设置资源名 rule.setResource(\"echo\"); //设置40毫秒 rule.setCount(40); //阈值类型为平均响应时间 rule.setGrade(RuleConstant.DEGRADE_GRADE_RT); //时间窗口设置为5秒 rule.setTimeWindow(5); rules.add(rule); DegradeRuleManager.loadRules(rules);} 程序： 12345678910111213141516171819202122232425262728293031323334353637383940414243@RestControllerpublic class EchoController { @Autowired private EchoService echoService; @GetMapping(\"/echo/{str}\") public String echo(@PathVariable String str){ SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss:SSS\"); for (int i = 1; i &lt;= 10; i++) { try { String echo = echoService.echo(str); System.out.println(\"第\"+i+\"次： echo:\"+echo+\" | 时间:\"+dateFormat.format(new Date())); TimeUnit.MILLISECONDS.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } } return \"访问成功\"; }}//Servicepublic interface EchoService { String echo(String str);}//ServiceImpl@Servicepublic class EchoServiceImpl implements EchoService { @Override @SentinelResource(value = \"echo\",blockHandler = \"handleBlockException\") public String echo(String str) { try { TimeUnit.MILLISECONDS.sleep(50); } catch (InterruptedException e) { e.printStackTrace(); } return \"返回值:\"+str; } public String handleBlockException(String str, BlockException ex){ return \" 服务降级处理：\"+str+\" 异常为：\"+ex.getClass().getSimpleName(); }} 访问： 12345678910第1次： echo:返回值:123 | 时间:2019-10-23 14:13:02:809第2次： echo:返回值:123 | 时间:2019-10-23 14:13:02:859第3次： echo:返回值:123 | 时间:2019-10-23 14:13:02:910第4次： echo:返回值:123 | 时间:2019-10-23 14:13:02:960第5次： echo:返回值:123 | 时间:2019-10-23 14:13:03:010第6次： echo: 服务降级处理：123 异常为：DegradeException | 时间:2019-10-23 14:13:03:049第7次： echo: 服务降级处理：123 异常为：DegradeException | 时间:2019-10-23 14:13:03:049第8次： echo: 服务降级处理：123 异常为：DegradeException | 时间:2019-10-23 14:13:03:050第9次： echo: 服务降级处理：123 异常为：DegradeException | 时间:2019-10-23 14:13:03:050第10次： echo: 服务降级处理：123 异常为：DegradeException | 时间:2019-10-23 14:13:03:050 通过程序可以看出，平均响应时间(RT)是先计算前5次的请求的平均处理时间，如果超过了预定的阈值时间(count)，那么在接下来的时间范围/窗口(timeWindow)后直接进行服务降级，抛出DegradeException. 等待timeWindow过后，又会重新计算RT。 我们看一下实时监控： 异常比例初始化规则： 1234567891011121314public static void initDegradeRuleForExceptionRatio(){ List&lt;DegradeRule&gt; rules = new ArrayList&lt;&gt;(); DegradeRule rule = new DegradeRule(); //资源名 rule.setResource(\"echo\"); //阈值类型：异常比例 rule.setGrade(RuleConstant.DEGRADE_GRADE_EXCEPTION_RATIO); //阈值 rule.setCount(0.5); //时间窗口为5秒 rule.setTimeWindow(5); rules.add(rule); DegradeRuleManager.loadRules(rules);} 测试程序: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859//controller@RestControllerpublic class EchoController { @Autowired private EchoService echoService; @GetMapping(\"/echo/{str}\") public String echo(@PathVariable String str) { SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss:SSS\"); for (int i = 1; i &lt;= 10; i++) { String echo = echoService.echo(str, i); System.out.println(\"第\" + i + \"次： echo:\" + echo + \" | 时间:\" + dateFormat.format(new Date())); } try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { e.printStackTrace(); } return \"访问成功\"; }}// servicepublic interface EchoService { String echo(String str, int i);}//serviceImpl/** * @author hao.ouYang * @create 2019-10-22 11:05 */@Servicepublic class EchoServiceImpl implements EchoService { @Override @SentinelResource(value = \"echo\",blockHandler = \"handleBlockException\",fallback = \"fallbackFun\") public String echo(String str,int i) { try { TimeUnit.MILLISECONDS.sleep(150); } catch (InterruptedException e) { e.printStackTrace(); } if ( i % 2 == 1){ throw new IRuleException(); } return \"返回值:\"+str; } public String handleBlockException(String str,int i, BlockException ex){ return \" 服务降级处理：\"+str+\" 参数i:\"+i+\" 异常为：\"+ex.getClass().getSimpleName(); } public String fallbackFun(String str,int i, Throwable throwable){ return \" 服务降级处理：\"+str+\" 参数i:\"+i+\" 异常为：\"+throwable.getClass().getSimpleName(); }} 测试结果： 总结：一秒内要保证访问数量超过5次，否则不会出发异常比例的服务熔断降级。比例超过预定的0.5之后就会触发降级 异常数异常数是统计1分钟时间的内，所以当时间窗口包含在统计时间内，可能一分钟之后又会立即进入统计时间范围中 。 1234567891011121314public static void initDegradeRuleForExceptionCount(){ List&lt;DegradeRule&gt; rules = new ArrayList&lt;&gt;(); DegradeRule degradeRule = new DegradeRule(); //设置异常数阈值 degradeRule.setCount(5); //阈值类型：异常数 degradeRule.setGrade(RuleConstant.DEGRADE_GRADE_EXCEPTION_COUNT); //资源名称 degradeRule.setResource(\"echo\"); //时间窗口 degradeRule.setTimeWindow(10); rules.add(degradeRule); DegradeRuleManager.loadRules(rules);}","link":"/2020/01/18/SSM/springcloudalibaba/16.sentinel%E8%A7%84%E5%88%99%E4%B9%8B%E7%86%94%E6%96%AD%E9%99%8D%E7%BA%A7%E8%A7%84%E5%88%99/"},{"title":"五、Ribbon实现负载均衡","text":"Ribbon实现负载均衡 官方文档：https://cloud.spring.io/spring-cloud-static/spring-cloud-netflix/2.2.0.M3/reference/html/#spring-cloud-ribbon 概述下面是截取官方文档的两段话，我们可以大概看一下： Ribbon是什么：Ribbon是一个客户端负载均衡器。提供了大量的Http和Tcp客户端行为。Feign已经使用了Ribbon，所以，如果使用@FeignClient ，这一部分也被采用。Feign后面也会介绍到。 这一部分使用到了Nacos服务注册中心，所以需要先准备好注册中心，前面有介绍。 项目结构 父级依赖12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.9.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;groupId&gt;com.ooyhao&lt;/groupId&gt; &lt;artifactId&gt;nacos-feign-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;modules&gt; &lt;module&gt;nacos-feign-service-provider-1&lt;/module&gt; &lt;module&gt;nacos-feign-service-provider-2&lt;/module&gt; &lt;module&gt;nacos-feign-service-provider-3&lt;/module&gt; &lt;module&gt;nacos-feign-service-consumer&lt;/module&gt; &lt;/modules&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;0.9.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 负载均衡是面向同一服务的集群使用的，所以我们一般都是将同一服务部署到不同的主机上，即拥有不同Ip、相同或不同端口，本地测试，用端口来标识不同的服务。 服务提供者依赖123456789101112131415161718192021222324252627&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.ooyhao&lt;/groupId&gt; &lt;artifactId&gt;nacos-feign-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;groupId&gt;com.ooyhao&lt;/groupId&gt; &lt;artifactId&gt;nacos-feign-service-provider-1&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 配置文件下面是三个服务的不同的配置文件： 配置文件一 123456789101112server:# 服务端口 port: 8071spring:# 项目/服务 名 application: name: feign-service-provider cloud: nacos: discovery:# 注册中心地址：端口 server-addr: 127.0.0.1:8848 配置文件二 123456789101112server:# 服务端口 port: 8072spring:# 项目/服务 名 application: name: feign-service-provider cloud: nacos: discovery:# 注册中心地址：端口 server-addr: 127.0.0.1:8848 配置文件三 123456789101112server:# 服务端口 port: 8073spring:# 项目/服务 名 application: name: feign-service-provider cloud: nacos: discovery:# 注册中心地址：端口 server-addr: 127.0.0.1:8848 其实就是指定相同的服务名，不同的端口，并且配置到注册中心，即可。 User1234567891011121314package com.ooyhao.nacosfeignserviceprovider.pojo;import lombok.AllArgsConstructor;import lombok.Data;import java.io.Serializable;@Data@AllArgsConstructorpublic class User implements Serializable { private Integer id; private String username; private String password; private Integer age;} 主程序1234567@SpringBootApplication@EnableDiscoveryClientpublic class NacosFeignServiceProvider1Application { public static void main(String[] args) { SpringApplication.run(NacosFeignServiceProvider1Application.class, args); }} 说明：这里会发现一个问题，如果没有写@enableDiscoveryClient 注解，也是可以将自身注册到注册中心去的，在网上看到，从Spring Cloud Edgware开始，@EnableDiscoveryClient 或@EnableEurekaClient 可省略，测试结果也是如此，于是我翻阅了一下Spring官方文档，看到了下面这段话，即：@EnableDiscoveryClient 不再是必须的了，你可以将DiscoveryClient的实现类置于SpringBoot项目的ClassPath中就可以注册服务。也就是说，我们只需要在POM文件中添加相关依赖，在配置文件中配置相应的配置，就可以自动实现服务注册于发现了。 https://cloud.spring.io/spring-cloud-static/spring-cloud-commons/2.2.0.M3/reference/html/#enablediscoveryclient Controller123456789101112131415161718@RestControllerpublic class IndexController { private static Map&lt;Integer,User&gt; users = new HashMap&lt;&gt;(); static { users.put(1,new User(1,\"张三\",\"provider-1\",18)); users.put(2,new User(2,\"李四\",\"provider-1\",19)); users.put(3,new User(3,\"王五\",\"provider-1\",20)); } @GetMapping(\"/user/{id}\") public User user(@PathVariable(\"id\") Integer id){ System.out.println(\"provider 1 rec\"); return users.get(id); }} 这里需要修改下不同的服务的password，用于后续观察负载均衡的效果。 服务消费者依赖123456789101112131415server: port: 8080spring: application: name: feign-service-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848# 配置负载均衡策略#feign-service-provider:# ribbon:# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule UserUser对象就不再赘述了。将服务提供方的User对象复制过来即可。这里测试发现，服务提供方的User类和服务消费方的User类可以不需要放在相同的包下，这点与RabbitMQ的自动序列化和反序列化要求不同 。 Controller12345678910111213141516171819202122/** * 描述: * 类【IndexController】 * * @author ouYangHao * @create 2019-10-15 9:57 */@RestControllerpublic class IndexController { @Autowired private RestTemplate restTemplate; @GetMapping(\"/user/{id}\") public User user(@PathVariable(\"id\") Integer id){ User user = restTemplate.getForObject(\"http://feign-service-provider/user/\" + id, User.class); System.out.println(user); return user; }} 这里可以发现，使用RestTemplate进行Http接口调用的时候，使用的是服务名feign-service-provider ,而不是IP加端口的形式，这样就把IP地址与服务名的映射关系的任务交给注册中心去维护了。我们只需要知道服务名就可以，至于服务在世界何处不用关心。 主程序123456789101112131415161718192021@SpringBootApplication@EnableDiscoveryClientpublic class NacosFeignServiceConsumerApplication { @Bean public IRule iRule(){ return new RandomRule();//随机策略// return new RoundRobinRule();//轮询策略 } @Bean @LoadBalanced public RestTemplate restTemplate(){ return new RestTemplate(); } public static void main(String[] args) { SpringApplication.run(NacosFeignServiceConsumerApplication.class, args); }} 测试随机策略这里我们先试用随机策略来测试：连续多次刷新访问下面路径： http://localhost:8080/user/1 可以看出，当前测试结果符合预定随机策略结果。 轮询策略我们将iRule方法换成轮询方式，重新启动： 1234@Beanpublic IRule iRule(){ return new RoundRobinRule();//随机策略} 测试结果： 测试结果符合轮询规则！","link":"/2020/01/18/SSM/springcloudalibaba/2.Ribbon%E5%92%8CRestTemplate%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"title":"二十三、SpringCloud Gateway 的初体验","text":"Gateway的路由谓词工厂 相关概念(术语) 路由 (Route)： 路由是网关的基础构建模块，它是有ID，目标URI，谓词集合和过滤器集合定义。如果聚合谓词为true，则匹配路由。 谓词 (Predicate)： 这是Java8的函数谓词，输入类型是Spring Framework ServerWebExchange, 这使得开发者可以匹配HTTP请求中的所有内容，例如 header 和 参数。 过滤器 (Filter)： 这些是使用特定工厂构建的SpringFramework GatewayFilter 实例。在此，可以在发送下游请求之前或之后修改请求和响应。 路由谓词工厂SpringCloudGateway 将路由作为 Spring WebFlux HandlerMapping 基础架构的一部分进行匹配。SpringCloudGateway 包括许多内置的Route Predicate factory。所有这些谓词都与HTTP请求的不同属性匹配。多个Route Predicate工厂可以合并，也可以通过逻辑合并 and 。 1. After 路由谓词After Route Predicate Factory 采用一个参数，即日期时间。该谓词匹配在当前日期时间之后发生的请求。 2. Before 路由谓词Before Route Predicate Factory 采用一个参数，即日期时间。该谓词匹配在当前日期时间之前发生的请求。 3. Between 路由谓词Between Route Predicate Factory 采用两个参数，都是日期时间类型的，该谓词匹配在两个日期之间发生的请求。 下面是统一的配置： 12345678910spring: cloud: gateway: routes: - id: gateway-service uri: https://www.163.com predicates: # - Before= 2019-10-25T00:00:00+08:00[Asia/Shanghai] # - After= 2019-10-25T00:00:00+08:00[Asia/Shanghai] - Between= 2019-10-25T00:00:00+08:00[Asia/Shanghai],2019-10-25T18:05:00+08:00[Asia/Shanghai] 说明： 如果是时间之前的，使用Before关键字。如果是时间之后的，使用After关键字，如果要指明在两个日期之间，则使用Between 关键字，两个日期使用逗号隔开。[Asia/Shanghai] 表示使用的是以上海为基准的时间。 4. Cookie 路由谓词Cookie路由谓词工厂采用的是两个参数，一个是Cookie的名字，另外一个是合法的正则表达式。这个谓词用于匹配具有给定名称的Cookie，并且值匹配一个合法的正则表达式。 12345678spring: cloud: gateway: routes: - id: gateway-service uri: http://www.163.com predicates: - Cookie= username,kee.e 说明：这里是采用验证cookie的方式，当我们请求中携带了对应的正确的cookie信息，就可以访问成功到http://www.163.com ， 否则就会报 Not Found . 下面是使用Postman测试的结果： 错误的cookie信息： 正确的cookie信息： 如果使用gateway时， 需要取出 cookie信息，可以使用下面的方法： 1234@GetMapping(\"/resp\")public String test(@CookieValue(\"username\") String username) { return \"SUCCESS\";} 5. Header 路由谓词Header 路由谓词工厂接受两个参数：header的name和其对应的合法的正则表达式值。只有在Header部分存在name并且其value也匹配的情况下，才能通过。 12345678spring: cloud: gateway: routes: - id: gateway-service uri: http://www.163.com predicates: - Header=password,123456 测试结果如下： 如果使用Gateway，需要从Header中取出信息，可以使用下面的方法： 1234@GetMapping(value = \"/testHeader\")public String testHeader(@RequestHeader(value = \"username\") String username){ return \"username:\"+username;} 6. Host 路由谓词Host（主机）路由谓词工厂，采用一个参数：主机名模式列表。该模式带有. 作为分隔符的Ant样式的模式，谓词与Host 匹配模式的Header部分。 12345678spring: cloud: gateway: routes: - id: gateway-service uri: http://localhost:8888 predicates: - Host= localhost:9999 这里为了更好的测试，我们单创建并启动一个服务，端口为8888的，大概代码如下： 12345678910111213141516171819202122232425262728293031/** * @author hao.ouYang * @create 2019-10-25 18:08 */@RestControllerpublic class UserController { @Autowired private UserService userService; @RequestMapping(\"/user\") public User findUser(){ return userService.findUser(); }}@Servicepublic class UserService { public User findUser(){ User user = new User(1,\"admin\",\"admin\"); return user; }}@Data@NoArgsConstructor@AllArgsConstructorpublic class User implements Serializable { private Integer id; private String username; private String password;} 测试结果如下： 上面其实是将http://localhost:9999/user 映射到了 http://localhost:8888/user 上了。 注意：当然除了我们除了上面的写法，还有一些多样化的定制。同时也支持URI模板变量 123- Host= www.ouyang.**, **.ouyang.**,**.ouyang.org# 上面的例子可以匹配 www.ouyang.club, www.ouyang.com, www.ouyangorg等。- Host= {sub}.ouyang.club 7. Method 路由谓词方法路由谓词工厂采用一个参数：用来匹配HTTP请求的类型。(GET,POST等). 12345678spring: cloud: gateway: routes: - id: gateway-service uri: http://localhost:8888 predicates: - Method= POST 以上需要匹配为POST 类型的请求才可以转发到 http://localhost:8888 上面，测试如下： 更改为POST 类型的请求： 8. Path 路由谓词PathRoutePredicateFactory 需要PathMatcher 模式路径列表和一个可选的标志位参数matchOptionalTrailingSeparator. 这是最常用的一个路由谓词。 12345678spring: cloud: gateway: routes: - id: gateway-service uri: http://localhost:8888 predicates: - Path= /path 这种使用路径来映射的方式。以上可以将http://localhost:9999/path 映射到http://localhost:8888/path 路径上，前一节也见过这个谓词，所以说这个谓词是最常用。还可以通过下面这个方式在请求路径上携带参数：（如果通过这种形式配置，在匹配命中进行路由的同时，会提取路径中对应的内容并且将键值对放在ServerWebExchange.getAttributes()集合中，Key为ServerWebExchangeUtils.URI_TEMPLATE_VARIABLES_ATTRIBUTE, 这些提取出来的属性可以供GatewayFilter Factories 使用）。 12345678spring: cloud: gateway: routes: - id: gateway-service uri: http://localhost:8888 predicates: - Path= /testPath/{stri} 另一个服务的接收： 123456789@GetMapping(value = \"/path\")public String path(){ return \"path\";}@GetMapping(value = \"/testPath/{str}\")public String testPath(@PathVariable(\"str\") String str){ return \"return:\"+str;} 9. Query 路由谓词请求查询参数路由工厂QueryRoutePredicateFactory 需要一个必须的请求查询参数(Param的name)以及一个可选的正则表达式(regexp). 12345678910spring: application: name: spring-cloud-gateway cloud: gateway: routes: - id: gateway-service uri: http://localhost:8888 predicates: - Query= username 通过上述配置，我们的请求中只需要包含username参数即可匹配路由。 1curl localhost:9999/testQuery?username=1 上面的测试可以通过，但是如果把username 删除或是改成别的，就无法匹配了。 还可以将Query参数以键值对的形式来配置，这样的请求过来的时候，不仅需要匹配名字，同时参数值需要与正则表达式匹配才能走路径。 12345678910spring: application: name: spring-cloud-gateway cloud: gateway: routes: - id: gateway-service uri: http://localhost:8888 predicates: - Query= username,ad. 以上匹配需要请求满足既有username 参数，并且值需要以ad 开头的长度为3的字符串才能匹配和路由。 测试如下： 12345curl http://localhost:9999/testQuery?username=adv{\"param\":\"adv\"}curl http://localhost:9999/testQuery?username=addv{\"timestamp\":\"2019-10-27T09:15:45.580+0000\",\"path\":\"/testQuery\",\"status\":404,\"error\":\"Not Found\",\"message\":null} 8888端口服务的controller方法为： 123456@GetMapping(value = \"/testQuery\")public Map&lt;String,String&gt; testQuery(@RequestParam(\"username\") String username){ Map&lt;String,String&gt; map = new HashMap&lt;&gt;(); map.put(\"param\",username); return map;} 10. RemoteAddr 路由谓词 RemoteAddrRoutePredicateFactory匹配规则采用CIDR符号（IPv4或IPv6）字符串的列表（最小值为1），例如192.168.0.1/16（其中192.168.0.1是远程IP地址并且16是子网掩码）。 123456789101112spring: application: name: spring-cloud-gateway cloud: gateway: routes: - id: gateway-service uri: http://localhost:8888 predicates: - RemoteAddr= 127.0.0.1server: port: 9999 8888端口服务的处理方法： 1234@GetMapping(value = \"/remote\")public String testRemote(){ return \"Remote\";} 测试结果： 123curl http://127.0.0.1:9999/remote# 响应结果Remote 11. Weight 路由谓词权重路由谓词工厂采用两个参数，分别为组(group)和权重(weight). 权重按组进行计算。 12345678910111213141516spring: application: name: spring-cloud-gateway cloud: gateway: routes: - id: gateway-weight-high uri: http://localhost:8888 predicates: - Weight= Group1, 8 - id: gateway-weight-low uri: http://localhost:7777 predicates: - Weight= Group1, 2server: port: 9999 接受7777和8888请求的方法： 12345678910111213141516//============port:7777 ============@GetMapping(value = \"/weight\")public Map weight() { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"port\", \"7777\"); return map;}//============port:8888 ============@GetMapping(value = \"/weight\")public Map weight() { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"port\", \"8888\"); System.out.println(map); return map;} 测试结果如下： 参考了： https://www.cnblogs.com/throwable/p/10807704.html","link":"/2020/01/18/SSM/springcloudalibaba/21.gateway%E8%B7%AF%E7%94%B1%E8%B0%93%E8%AF%8D/"},{"title":"六、Feign服务调用","text":"Feign服务调用 ​ 前一节有说到，Feign使用了Ribbon，即具有了Ribbon的负载均衡的功能。这一节主要是基于上一节的程序上，使用Feign这个伪Http客户端来进行服务调用。 Feign是一个声明式web服务客户端，它让我们写web服务客户端更加简单。使用Feign只需要创建一个接口并标相应的注解。 Feign is a declarative web service client. It makes writing web service clients easier. To use Feign create an interface and annotate it. It has pluggable annotation support including Feign annotations and JAX-RS annotations. Feign also supports pluggable encoders and decoders. Spring Cloud adds support for Spring MVC annotations and for using the same HttpMessageConverters used by default in Spring Web. Spring Cloud integrates Ribbon and Eureka to provide a load balanced http client when using Feign. 官方文档：https://cloud.spring.io/spring-cloud-static/spring-cloud-openfeign/2.2.0.M3/reference/html/ 程序基于上一节，即Ribbon和RestTemplate实现服务负载均衡。 服务提供方Controller12345678910111213141516171819202122232425262728293031323334353637@RestControllerpublic class IndexController { private static Map&lt;Integer,User&gt; users = new HashMap&lt;&gt;(); static { users.put(1,new User(1,\"张三\",\"provider-1\",18)); users.put(2,new User(2,\"李四\",\"provider-1\",19)); users.put(3,new User(3,\"王五\",\"provider-1\",20)); } @GetMapping(\"/echo/{str}\") public String echo(@PathVariable(\"str\") String str){ return \"provider-1 echo : \"+str; } @GetMapping(\"/user/{id}\") public User user(@PathVariable(\"id\") Integer id){ System.out.println(\"provider 1 rec\"); return users.get(id); } @GetMapping(\"/exist\") public boolean exist(User user){ System.out.println(\"provider 1 rec\"); boolean isExist = false; for (Map.Entry&lt;Integer,User&gt; userEntry : users.entrySet()){ if (userEntry.getValue().getUsername().equals(user.getUsername()) &amp;&amp; userEntry.getValue().getPassword().equals(user.getPassword())){ isExist = true; break; } } return isExist; }} 服务消费方依赖使用Feign，我们需要先导入Feign的依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 主程序1234567891011121314151617181920@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class NacosFeignServiceConsumerApplication { @Bean public IRule iRule(){ return new RoundRobinRule();//轮询策略 } @Bean @LoadBalanced public RestTemplate restTemplate(){ return new RestTemplate(); } public static void main(String[] args) { SpringApplication.run(NacosFeignServiceConsumerApplication.class, args); }} 注意：这里我们使用@EnableFeignClients 注解，来启用Feign客户端功能。重点是我们如何来使用feign调用服务。如下： Feign服务接口123456789@FeignClient(value = \"feign-service-provider\")public interface FeignService { @GetMapping(\"/echo/{str}\") String echo(@PathVariable(\"str\") String str); @GetMapping(\"/exist\") boolean exist(@SpringQueryMap User user);} 我们可以发现，这里与服务提供方的controller方法很类似，首先，声明一个接口，使用@FeignClient 注解来标注此接口为Feign客户端接口，使用value 属性来标注是哪一个服务，value指定服务名。细心的可能已经发现这里出现了一个新的注解@StringQueryMap 注解，后面会介绍到。 Controller使用Feign服务：首先将服务接口注入，其他就与普通的方法调用一样。 12345678910111213141516171819202122232425262728293031@RestControllerpublic class IndexController { @Autowired private FeignService feignService; @Autowired private RestTemplate restTemplate; @GetMapping(\"/echo/{str}\") public HashMap echo(@PathVariable(\"str\") String str) { HashMap map = new HashMap(); String echo = feignService.echo(str); System.out.println(\"message:\" + echo); map.put(\"message\", echo); return map; } //使用RestTemplate调用 @GetMapping(\"/user/{id}\") public User user(@PathVariable(\"id\") Integer id) { User user = restTemplate.getForObject(\"http://feign-service-provider/user/\" + id, User.class); System.out.println(user); return user; } @GetMapping(\"/exist\") public boolean exist(User user) { return feignService.exist(user); }} 效果图 @StringQueryMap https://cloud.spring.io/spring-cloud-static/spring-cloud-openfeign/2.2.0.M3/reference/html/#feign-querymap-support The OpenFeign @QueryMap annotation provides support for POJOs to be used as GET parameter maps. Unfortunately, the default OpenFeign QueryMap annotation is incompatible with Spring because it lacks a value property. Spring Cloud OpenFeign provides an equivalent @SpringQueryMap annotation, which is used to annotate a POJO or Map parameter as a query parameter map. OpenFeign的 @QueryMap 注解提供了Get请求的POJOS的参数支持，遗憾的是，这个OpenFeign的默认QueryMap注解由于缺少value属性而不太适用。 12345@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.PARAMETER})public @interface QueryMap { boolean encoded() default false;} SpringCloudOpenFeign提供了一个相同功能的注解：@SpringQueryMap ,它可以标注PoJo或Map用来作为请求参数。 123456789@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.PARAMETER})public @interface SpringQueryMap { @AliasFor(\"encoded\") boolean value() default false; @AliasFor(\"value\") boolean encoded() default false;} 我们再回来看看Feign这个接口： 123456789@FeignClient(value = \"feign-service-provider\")public interface FeignService { @GetMapping(\"/echo/{str}\") String echo(@PathVariable(\"str\") String str); @GetMapping(\"/exist\") boolean exist(@SpringQueryMap User user);} 当我们不使用@SpringQueryMap 注解是，会抛出如下异常： 正常测试结果： Feign 日志 https://cloud.spring.io/spring-cloud-static/spring-cloud-openfeign/2.2.0.M3/reference/html/#feign-logging 配置文件123logging: level: com.ooyhao.nacosfeignserviceconsumer.feignserver: debug The Logger.Level object that you may configure per client, tells Feign how much to log. Choices are: NONE, No logging (DEFAULT). BASIC, Log only the request method and URL and the response status code and execution time. HEADERS, Log the basic information along with request and response headers. FULL, Log the headers, body, and metadata for both requests and responses. Feign的日志级别有以上几种方式： NONE：没有日志，默认（性能高）。 BASIC：记录请求方法和请求路径，响应状态码和执行时间。 HEADERS：记录基本的请求和响应头信息。 FULL：记录请求/响应头，体和元数据。 123456class FooConfig{ @Bean Logger.Level level(){ return Logger.Level.FULL; }} 效果图下面是调用效果： Feign继承 https://cloud.spring.io/spring-cloud-static/spring-cloud-openfeign/2.2.0.M3/reference/html/#spring-cloud-feign-inheritance 上面是从SpringCloud OpenFeign官方文档截图的，说：这显示是不明智的在Feign服务端和客户端共享一个接口，这样会提高耦合度，所以这里就做演示了。","link":"/2020/01/18/SSM/springcloudalibaba/3.Feign%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8/"},{"title":"十一、Nacos多配置加载和共享配置","text":"Nacos多配置加载和共享配置 中文文档：https://github.com/alibaba/spring-cloud-alibaba/wiki/Nacos-config 通过前两小节，我们已经掌握了Nacos作为分布式配置中心的基本功能，比如：配置读取，自动刷新，加载原则，多环境管理等。但是，在实际项目中，配置文件一般会安装实际业务进行拆分，所以会存在多个配置文件需要加载。当然，对于多个服务之间，可能会存在一些共享的配置，所以这一节我们了解一下多配置文件加载和配置共享。 多配置文件加载我们知道，配置文件的加载规则是由相面几个属性组合而成的： 12345spring.cloud.nacos.config.namespace= 默认:\"\"//空，此处填的是namespaceId,而不是名字publicspring.cloud.nacos.config.group= 默认：DEFAULT_GROUP# ${spring.cloud.nacos.config.prefix} &gt; ${spring.cloud.nacos.config.name} &gt; ${spring.application.name}spring.cloud.nacos.config.prefix= spring.cloud.nacos.config.file-extension= 默认 .properties 控制页面添加配置 具体配置如下： nacos-multi-config.yaml 12server: port: 8888 nacos-multi-config-discovery.yaml 12discovery: host: 127.0.0.1:8848 nacos-multi-config-log.yaml 12log: level: Info nacos-multi-config-db.yaml 1234567spring: datasource: username: root password: 123server: port: 7777 nacos-multi-config-redis.yaml 1234567redis: host: 127.0.0.1 username: amdin password: adminserver: port: 9999 bootstrap.properties123456789101112131415161718192021222324# 基础配置spring.application.name=nacos-multi-configspring.cloud.nacos.config.file-extension=yamlspring.cloud.nacos.config.server-addr=127.0.0.1:8848# spring.cloud.nacos.config.group=ouYangGroupspring.cloud.nacos.config.namespace=28dacdf7-263f-40af-9d31-592529746f6e# 多配置加载# 使用默认的 DEFAULT_GROUP,如果上面配置了，则按照上面配置的加载# 默认自动刷新spring.cloud.nacos.config.ext-config[0].data-id=nacos-multi-config-discovery.yaml# 不再默认的组，不会自动刷新spring.cloud.nacos.config.ext-config[1].data-id=nacos-multi-config-log.yamlspring.cloud.nacos.config.ext-config[1].group=ouYangGroup# 不再默认的组，手动启动自动刷新spring.cloud.nacos.config.ext-config[2].data-id=nacos-multi-config-db.yamlspring.cloud.nacos.config.ext-config[2].group=ouYangGroupspring.cloud.nacos.config.ext-config[2].refresh=true# 测试加载顺序spring.cloud.nacos.config.ext-config[3].data-id=nacos-multi-config-redis.yamlspring.cloud.nacos.config.ext-config[3].group=ouYangGroup 注意： 通过spring.cloud.nacos.config.ext-config[n].data-id的配置来配置多个DataId 的配置。 通过spring.cloud.nacos.config.ext-config[n].group 的配置来指定dataId所在的组，不明确指定的话使用默认的DEFAULT_GROUP 通过spring.cloud.nacos.config.ext-config[n].refresh 的配置来控制该dataId属性变更时，是否动态刷新加载，默认如果不在DEFAULT_GROUP，自动刷新是关闭的，可以通过置为true来手动开启。 测试结果 注意1: 多个DataId同时配置时，它的优先级关系是 spring.cloud.nacos.config.ext-config[n].data-id 的值越大，优先级越高，即先加载，所以可以通过结果看到server.port=8888.是因为先加载server.port=9999.再7777覆盖了9999，再8888覆盖了7777，所以最后的结果就是server.port=8888 . 注意2： spring.cloud.nacos.config.ext-config[n].data-id= 必须带上扩展名，即文件格式，支持properties，也支持yaml/yml. 此时spring.cloud.nacos.config.file-extension 的配置对自定义扩展的配置的data-id是无效的。 共享配置通过上述自定义扩展dataId，已经解决了多个应用之间配置贡献的问题，同时也支持一个应用有多个配置文件。 下面我可以通过这种简单方式来配置共享配置： 123# 共享配置spring.cloud.nacos.config.shared-dataids=common-log.yaml,common-redis.yamlspring.cloud.nacos.config.refreshable-dataids=common-log.yaml Nacos控制台 nacos-config-share.yaml 12server: port: 9999 common-log.yaml 12log: level: DEBUG common-redis.yaml 12345redis: host: 127.0.0.1 port: 6379log: level: Info 主程序测试主程序： 12345678910111213141516@SpringBootApplicationpublic class NacosConfigShareApplication { public static void main(String[] args) { ConfigurableApplicationContext applicationContext = SpringApplication.run(NacosConfigShareApplication.class, args); ConfigurableEnvironment environment = applicationContext.getEnvironment(); String port = environment.getProperty(\"server.port\"); String level = environment.getProperty(\"log.level\"); String redisHost = environment.getProperty(\"redis.host\"); String redisPort = environment.getProperty(\"redis.port\"); System.out.println(\"server.port:\"+port); System.out.println(\"log.level:\"+level); System.out.println(\"redis.host:\"+redisHost+\" | redis.port:\"+redisPort); }} 结果： 12server.port:9999log.level:Info 可以看出： 通过spring.cloud.nacos.config.share-dataids 来支持多个共享dataId的配置，多个配置文件之间用逗号隔开。 通过spring.cloud.nacos.config.refreshable-dataids 来支持哪些共享配置的Data Id在变化时，应用中是否动态刷新，能感知到最新的值，多个DataId之间用逗号隔开。如果没有明确指定的配置，默认情况下所共享的配置是不支持动态刷新。 注意： spring.cloud.nacos.config.share-dataids 的配置加载顺序是按照从左到右的，所以如果出现相同的配置时，后面的会覆盖前面的，如上述的log.level 使用spring.cloud.nacos.config.share-dataids 来配置共享配置时，需要加上后缀名，即properties,yaml/yml.此时的spring.cloud.nacos.config.file-extension 的配置对此项无效。 通过使用spring.cloud.nacos.config.refreshable-dataids 来指定哪些共享配置是需要支持自动刷新的。默认未指定的配置是不支持自动刷新的。同时也需要加上配置的后缀名 配置的优先级我们用下面的实例来测试优先级： spring cloud alibaba nacos config 目前提供了三种配置能力从Nacos拉取相关的配置。 A : 通过spring.cloud.nacos.config.shared-datadis 支持多个共享data id的配置。 B : 通过spring.cloud.nacos.config.ext-config[n].data-id 的方式支持多个扩展Data Id的配置。 C : 通过内部相关规则（应用名、应用名+profile）自动生成的DataId配置。 优先级：A &lt; B &lt; C 即，先读取C,再读取B，最后读取A。 nacos-config.yaml 12log: level: warning nacos-config-share.yaml 12log: level: error common.log.yaml 12log: level: DEBUG boostrap.properties文件 case one: 1234spring.cloud.nacos.config.file-extension=yamlspring.cloud.nacos.config.server-addr=127.0.0.1:8848spring.cloud.nacos.config.shared-dataids=common-log.yamlspring.cloud.nacos.config.refreshable-dataids=common-log.yaml result: 1log.level:DEBUG case two: 123456spring.cloud.nacos.config.file-extension=yamlspring.cloud.nacos.config.server-addr=127.0.0.1:8848spring.cloud.nacos.config.ext-config[0].data-id=nacos-config.yamlspring.cloud.nacos.config.ext-config[0].refresh=truespring.cloud.nacos.config.shared-dataids=common-log.yamlspring.cloud.nacos.config.refreshable-dataids=common-log.yaml result: 1log.level:warning case three: 12345678spring.application.name=nacos-share-configspring.cloud.nacos.config.prefix=nacos-config-sharespring.cloud.nacos.config.file-extension=yamlspring.cloud.nacos.config.server-addr=127.0.0.1:8848spring.cloud.nacos.config.ext-config[0].data-id=nacos-config.yamlspring.cloud.nacos.config.ext-config[0].refresh=truespring.cloud.nacos.config.shared-dataids=common-log.yamlspring.cloud.nacos.config.refreshable-dataids=common-log.yaml result: 1log.level:error 完全关闭配置通过设置spring.cloud.nacos.config.enabled =false 来完全关闭Spring Cloud Nacos Config 配置功能。 完整配置参考 https://spring-cloud-alibaba-group.github.io/github-pages/greenwich/spring-cloud-alibaba.html#_more_information_about_nacos_config_starter_configurations","link":"/2020/01/18/SSM/springcloudalibaba/8.Nacos%E5%A4%9A%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD%E5%92%8C%E5%85%B1%E4%BA%AB%E9%85%8D%E7%BD%AE/"},{"title":"十、Nacos的自动刷新和多环境管理","text":"Nacos的自动刷新和多环境管理 自动刷新所谓自动刷新，通俗说就是指当我们在Nacos配置中心管理界面修改之后，相应服务会自动读取到修改后的配置。 自动刷新的功能是默认开启的，测试如下： 修改主程序123456789101112131415@SpringBootApplicationpublic class NacosConfigSimpleApplication { public static void main(String[] args) throws InterruptedException { ConfigurableApplicationContext applicationContext = SpringApplication.run(NacosConfigSimpleApplication.class, args); //取到Spring的配置环境 while(true){ ConfigurableEnvironment environment = applicationContext.getEnvironment(); String username = environment.getProperty(\"user.name\"); String age = environment.getProperty(\"user.age\"); System.out.println(\"username:\"+username+\" | age:\"+age); TimeUnit.SECONDS.sleep(1); } }} 测试结果然后我们修改相应的配置文件的age字段的数据，可以看到Idea的控制输出信息： 关闭自动刷新12spring.cloud.nacos.config.refresh.enabled = false # 关闭动态刷新 可以通过上述配置来关闭配置自动刷新。 我们可以看看源码：[默认为true]。 1234567891011121314@Componentpublic class NacosRefreshProperties { @Value(\"${spring.cloud.nacos.config.refresh.enabled:true}\") private boolean enabled = true; public boolean isEnabled() { return enabled; } public void setEnabled(boolean enabled) { this.enabled = enabled; }} Nacos的配置类：NacosConfigProperties 1234567891011121314151617181920212223242526272829303132333435@ConfigurationProperties(NacosConfigProperties.PREFIX)public class NacosConfigProperties { public static final String PREFIX = \"spring.cloud.nacos.config\"; private String serverAddr; private String encode; private String group = \"DEFAULT_GROUP\"; private String prefix; private String fileExtension = \"properties\"; private int timeout = 3000; private String endpoint; private String namespace; private String accessKey; private String secretKey; private String contextPath; private String clusterName; private String name; private String sharedDataids; private String refreshableDataids; private List&lt;Config&gt; extConfig; private ConfigService configService; //getter &amp; setter public static class Config { private String dataId; private String group = \"DEFAULT_GROUP\"; private boolean refresh = false; //getter &amp; setter } //toString public ConfigService configServiceInstance() {...}} NacosConfig 自动配置：NacosConfigAutoConfiguration 1234@Configuration@ConditionalOnProperty(name = \"spring.cloud.nacos.config.enabled\", matchIfMissing = true)public class NacosConfigAutoConfiguration {}//即如果没有在配置文件中配置spring.cloud.nacos.config.enabled，则默认为条件满足。所以不配置，我们依旧启用了配置功能。 多环境profile管理profile粒度控制首先我们在Nocos控制页面配置两个不同环境的配置，如下： nacos-config-develop.yaml: 1current.env: develop-env nacos-config-product.yaml: 1current.env: product-env 修改主程序，增加读取环境类型的属性： 123456789101112public static void main(String[] args) throws InterruptedException { ConfigurableApplicationContext applicationContext = SpringApplication.run(NacosConfigSimpleApplication.class, args); //取到Spring的配置环境// while(true){ ConfigurableEnvironment environment = applicationContext.getEnvironment(); String username = environment.getProperty(\"user.name\"); String age = environment.getProperty(\"user.age\"); String env = environment.getProperty(\"current.env\"); System.out.println(\"username:\"+username+\" | age:\"+age +\" | env:\"+env); TimeUnit.SECONDS.sleep(1);// }} 然后在配置bootstrap.properties配置文件指定激活环境： 几种激活方式可以查看：https://blog.csdn.net/ooyhao/article/details/100939089#Profile_176 123456789spring.application.name=nacos-config# 配置文件的格式spring.cloud.nacos.config.file-extension=yaml# 禁用配置自动刷新功能#spring.cloud.nacos.config.refresh.enabled = false# 配置中心的地址:端口spring.cloud.nacos.config.server-addr=127.0.0.1:8848# 激活环境 *spring.profiles.active=develop 注意：${spring.profiles.active}当通过配置文件来指定的时候，必须放在bootstrap.properties文件中。 通过结果可以看出，读取到的配置有nacos-config.yaml和nacos-config-develop.yaml。 注意：此示例中我们通过spring.profile.active= &lt;profilename&gt; 的方式写死在配置文件中，而在真正的项目实施过程中，这个变量的值需要不同环境而有不同的值。这个时候通常的做法是通过 -Dspring.profiles.active=&lt;profile&gt; 参数指定其配置来达到环境间灵活的切换。 具体可以参考上述链接内容 总结：文件匹配规则如下（dataId），${spring.cloud.nacos.config.prefix}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} 我们可以看看源码： 加载配置源码分析NacosConfigProperties类 123456789101112131415161718192021@ConfigurationProperties(NacosConfigProperties.PREFIX)public class NacosConfigProperties { public static final String PREFIX = \"spring.cloud.nacos.config\"; private String serverAddr; private String encode; private String group = \"DEFAULT_GROUP\"; private String prefix; private String fileExtension = \"properties\"; private int timeout = 3000; private String endpoint; private String namespace; private String accessKey; private String secretKey; private String contextPath; private String clusterName; private String name; private String sharedDataids; private String refreshableDataids;} 上述删除了部分代码，但是我们可以看到，fileExtension的默认值是properties.所以，在前一节中，我们使用properties格式的配置文件时，是没有配置文件扩展类型的。 注意：上面的配置类中有prefix，并且按上述的文件匹配规则来看，我们应该加载不到nacos-config.yaml文件的，但是测试结果是加载到了这个文件，而我们并没有配置前缀，所以可以推断出，模式是使用spring.application 属性。 我们查看源码可以看到原因： NacosPropertySourceLocator类：我们粗略的看一下（源码恐怖，后续深入研究） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@Order(0)public class NacosPropertySourceLocator implements PropertySourceLocator { private static final String NACOS_PROPERTY_SOURCE_NAME = \"NACOS\"; private static final String SEP1 = \"-\"; private static final String DOT = \".\"; private static final String SHARED_CONFIG_SEPARATOR_CHAR = \"[,]\"; //配置文件类型 private static final List&lt;String&gt; SUPPORT_FILE_EXTENSION = Arrays.asList(\"properties\",\"yaml\", \"yml\"); @Override public PropertySource&lt;?&gt; locate(Environment env) { //删除了部分无关内容 //spring.cloud.nacos.config.name String name = nacosConfigProperties.getName(); //spring.cloud.nacos.config.prefix String dataIdPrefix = nacosConfigProperties.getPrefix(); //如果没有配置prefix，则使用name属性作为prefix if (StringUtils.isEmpty(dataIdPrefix)) { dataIdPrefix = name; } //如果没有配置prefix,并且也没有配置name属性，则使用spring.application.name属性 //作为prefix的值 if (StringUtils.isEmpty(dataIdPrefix)) { dataIdPrefix = env.getProperty(\"spring.application.name\"); } CompositePropertySource composite = new CompositePropertySource( NACOS_PROPERTY_SOURCE_NAME); loadSharedConfiguration(composite); loadExtConfiguration(composite); //我们再看一下这个方法，如下 loadApplicationConfiguration(composite, dataIdPrefix, nacosConfigProperties, env); return composite; } private void loadApplicationConfiguration( CompositePropertySource compositePropertySource, String dataIdPrefix, NacosConfigProperties properties, Environment environment) { //spring.cloud.nacos.config.prefix String fileExtension = properties.getFileExtension(); //spring.cloud.nacos.config.group 默认DEFAULT_GROUP String nacosGroup = properties.getGroup(); //dataId=${prefix}-${profile}.${file-extension} // 上面的例子中的nacos-config.yaml loadNacosDataIfPresent(compositePropertySource, dataIdPrefix + DOT + fileExtension, nacosGroup, fileExtension, true); //加载激活了的profile的配置文件 // 上例中的nacos-config-develop.yaml for (String profile : environment.getActiveProfiles()) { String dataId = dataIdPrefix + SEP1 + profile + DOT + fileExtension; loadNacosDataIfPresent(compositePropertySource, dataId, nacosGroup, fileExtension, true); } }} 注意：通过上述代码分析，就知道为什么加载了nacos-config.yaml 和 nacos-config-develop.yaml. 多环境Group管理在没有自定义${spring.cloud.nacos.config.group} 配置的情况下，默认使用的是DEFAULT_GROUP, 如果需要自定义，可以通过下面的配置来实现： 1spring.cloud.nacos.config.group=DEVELOP_GROUP 注意：该配置必须放在bootstrap.properties文件中，并且在添加配置时的值一定要和spring.cloud.nacos.config.group 的属性值一致。 默认配置 Develop配置 测试结果123//: Loading nacos data, dataId: 'nacos-config.yaml', group: 'DEVELOP_GROUP'//: Loading nacos data, dataId: 'nacos-config-develop.yaml', group: 'DEVELOP_GROUP'username:欧阳 | age:23 | env:DEV 多环境namespace管理概述我们看一下官方时如何介绍namespace的： 用户进行租户粒度的配置隔离。不同的命名空间下，可以存在相同的Group或Data ID的配置。Namespace的常用场景之一是不同环境的配置的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等。 在配置文件中没有自定义namespace的时候，模式使用的是Nacos上Public作为namespace，如果我们希望自定义，可以通过${spring.cloud.nacos.config.namespace} 来配置。 默认命名空间我们先看之前的默认namespace。 自定义命名空间1spring.cloud.nacos.config.namespace= dc7fb953-fab6-4f98-95b9-e777d02cd683 注意：这个配置必须放在bootstrap.properties文件中。并且spring.cloud.nacos.config.namespace 配置的是namespace Id。而不是命名空间名称。并且这个命名空间id是不用自己生成的，只要在Nacos新建一个命名空间，管理页面就会自动产生一个字符串。在配置文件中配置时要注意选择相应的namespace，否则会读不到正确的配置。 这里为了保证配置的干净，我新建一个项目来测试。 完整配置12345678# DataIdspring.application.name=nacos-config-namespace# groupspring.cloud.nacos.config.group=ouYangGroup# namespacespring.cloud.nacos.config.namespace=dc7fb953-fab6-4f98-95b9-e777d02cd683spring.cloud.nacos.config.file-extension=yamlspring.cloud.nacos.config.server-addr=192.168.1.104:8848 Nacos配置 测试结果主程序： 12345678910111213@SpringBootApplicationpublic class NacosConfigNamespaceApplication { public static void main(String[] args) { ConfigurableApplicationContext applicationContext = SpringApplication.run(NacosConfigNamespaceApplication.class, args); //环境 ConfigurableEnvironment environment = applicationContext.getEnvironment(); String username = environment.getProperty(\"user.username\"); String password = environment.getProperty(\"user.password\"); System.out.println(\"username:\"+username+\" | password:\"+password); }} 测试结果： 1username:admin | password:123456","link":"/2020/01/18/SSM/springcloudalibaba/7.Nacos%E7%9A%84%E8%87%AA%E5%8A%A8%E5%88%B7%E6%96%B0%E5%92%8C%E5%A4%9A%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86/"},{"title":"一、初见Mybatis","text":"在技术进步的过程中，往往是因为新的技术比老的使用操作更方便，或是性能更优。而现在要接触的Mybatis无疑比传统的JDBC和hibernate等框架有更优的地方，才会有其存在的理由。下面我们通过JDBC与Mybatis的简单操作进行对比，来认识Mybatis的好。 简介来自官网： ​ MyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生类型、接口和 Java 的 POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。 说一下：Mybatis官网对于英语不好的工程师来说很友好，因为它是为数不多的有中文文档的技术官网。 JDBC VS Mybatis使用JDBC操作数据库DBUtils: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899/** * 描述: * 类【DBUtils】 * * @author ouYangHao * @create 2019-09-17 14:55 */public class DBUtils { /*用户名*/ private static final String username = \"root\"; /*密码*/ private static final String password = \"root\"; /*驱动名*/ private static final String driverClassName = \"com.mysql.jdbc.Driver\"; /*数据库连接地址*/ private static final String dbUrl = \"jdbc:mysql://120.79.167.xxx:3306/mybatis ?useUnicode=true &amp;characterEncoding=UTF-8 &amp;allowMultiQueries=true &amp;autoReconnect=true &amp;useSSL=false\"; public static List&lt;User&gt; findUsersByUsername(String name){ List&lt;User&gt; users = new ArrayList&lt;&gt;(); /*连接*/ Connection connection = null; /*预编译statement*/ PreparedStatement statement = null; /*结果集*/ ResultSet resultSet = null; try { /*加载数据库驱动*/ Class.forName(driverClassName); /*获取数据库连接*/ connection = DriverManager.getConnection(dbUrl, username, password); /*定义SQL*/ String sql = \" select * from tb_user where username = ? \"; /*创建预编译处理的statement*/ statement = connection.prepareStatement(sql); /*设置参数*/ statement.setString(1,name); /*执行SQL*/ resultSet = statement.executeQuery(); /*遍历结果集，封装对象*/ while (resultSet.next()){ User user = new User(); user.setId(resultSet.getInt(\"id\")); user.setUserId(resultSet.getString(\"user_id\")); user.setUsername(resultSet.getString(\"username\")); user.setPassword(resultSet.getString(\"password\")); user.setEmail(resultSet.getString(\"email\")); user.setPhone(resultSet.getString(\"phone\")); user.setGender(resultSet.getInt(\"gender\")); user.setBirthday(resultSet.getTime(\"birthday\")); user.setStatus(resultSet.getInt(\"status\")); user.setCreateTime(resultSet.getTimestamp(\"create_time\")); user.setCreateUser(resultSet.getString(\"create_user\")); user.setModifyTime(resultSet.getTimestamp(\"modify_time\")); user.setModifyUser(resultSet.getString(\"modify_user\")); users.add(user); } } catch (ClassNotFoundException | SQLException e) { e.printStackTrace(); } finally { try { if (connection != null){ connection.close(); } } catch (SQLException e) { e.printStackTrace(); } try { if (statement != null){ statement.close(); } } catch (SQLException e) { e.printStackTrace(); } try { if (resultSet != null){ resultSet.close(); } } catch (SQLException e) { e.printStackTrace(); } } return users; } public static void main(String[] args) { List&lt;User&gt; users = DBUtils.findUsersByUsername(\"admin\"); System.out.println(users); }} 使用Mybatis操作数据库Mapper接口的方法： 1List&lt;User&gt; findUsersByUsername(String username); Mapper.xml文件的SQL： 1234567891011121314&lt;sql id=\"Base_Column_List\"&gt; id, user_id, username, password, email, phone, gender, birthday, status, create_time, create_user, modify_time, modify_user&lt;/sql&gt;&lt;!--查询--&gt;&lt;select id=\"findUsersByUsername\" resultType=\"user\"&gt; select &lt;include refid=\"Base_Column_List\"/&gt; from tb_user &lt;where&gt; username = #{username} &lt;/where&gt;&lt;/select&gt; 以上代码除去Mybatis的配置文件外，上面仅仅几行就可以实现JDBC几十行代码可以实现的效果。 Mybatis的配置文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!-- 通过源码我们可以分析读取优先级： 1、在 properties 内部自定义的属性值第一个被读取 2、然后读取 resource 路径表示文件中的属性，如果有它会覆盖已经读取的属性； 如果 resource 路径不存在，那么读取 url 表示路径文件中的属性，如果有它会覆盖第一步读取的属性值 3、最后读取 parameterType 传递的属性值，它会覆盖已读取的同名的属性 --&gt; &lt;!--引入properties的属性文件--&gt; &lt;properties resource=\"mybatis.properties\"&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;/properties&gt; &lt;!--设置使用驼峰命名--&gt; &lt;settings&gt; &lt;setting name=\"mapUnderscoreToCamelCase\" value=\"true\"/&gt; &lt;setting name=\"logPrefix\" value=\"##Mybatis##\"/&gt; &lt;setting name=\"logImpl\" value=\"STDOUT_LOGGING\"/&gt; &lt;/settings&gt; &lt;!--设置别名--&gt; &lt;!-- mybatis自动扫描包中的po类，自动定义别名，别名是类名(首字母大写或小写都可以,一般用小写) --&gt; &lt;typeAliases&gt; &lt;package name=\"com.ooyhao.mybatis.bean\"/&gt; &lt;/typeAliases&gt; &lt;!--配置环境--&gt; &lt;environments default=\"development\"&gt; &lt;!--可以用来配置不同环境的参数，例如：开发，测试，生产--&gt; &lt;environment id=\"development\"&gt; &lt;!--事务管理--&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;!--数据源--&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"${jdbc.driver}\"/&gt; &lt;property name=\"url\" value=\"${jdbc.url}\"/&gt; &lt;property name=\"username\" value=\"${jdbc.username}\"/&gt; &lt;property name=\"password\" value=\"${jdbc.password}\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!--mapper xml文件--&gt; &lt;mappers&gt; &lt;mapper resource=\"mapper/UserMapper.xml\"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; mybatis.properties: 12345jdbc.driver= com.mysql.jdbc.Driverjdbc.url = jdbc:mysql://120.79.167.88:3306/mybatis ?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true&amp;autoReconnect=true&amp;useSSL=falsejdbc.username = rootjdbc.password = root 测试： 1234567891011121314151617181920public TestDemo{ SqlSession sqlSession = null; @Before public void init(){ String resource = \"mybatis-configuration.xml\"; InputStream inputStream = RoleTest.class.getClassLoader().getResourceAsStream(resource); SqlSessionFactory build = new SqlSessionFactoryBuilder().build(inputStream); sqlSession = build.openSession(true); } @Test public void testFindUsersByUsername() { //使用Mapper文件形式 String username = \"admin\"; UserMapper mapper = sqlSession.getMapper(UserMapper.class); List&lt;User&gt; userList = mapper.findUsersByUsername(username); System.out.println(userList); sqlSession.close(); }} 我们可以看一下测试类：我们通过SqlSessionFactoryBuilder的build方法，结合Mybatis的全局配置文件创建出SqlSessionFactory,再利用SqlSessionFactory通过openSession方法创建一个SqlSession。然后通过SqlSession来操作SQL。 看一下项目结构： SqlSession执行SQL操作步骤 需要在对应的mapper文件中添加相关的sql配置。 获得配置文件的路径并通过Resources的getResourceAsStream/AsReader方法获取流 InputStream getResourceAsStream(String resource) 返回值为字节流 Reader getResourceAsReader(String resource) 返回值为字符流 通过SqlSessionFactoryBuilder创建对象 使用SqlSessionFactoryBuilder对象的build(Stream/Reader)方法创建SqlSessionFactory对象。 通过SQLSessionFactory对象的openSession方法创建一个SqlSession对象 通过SQLSession对象的相关方法进行对数据库的crud操作。 增删改时需要提交事务。 上面已经进行了数据库操作，我们再回头看一下是不是这样的步骤： 12345678910111213141516171819202122@Testpublic void testFindUsersByUsername() { //1.mybatis的全局配置文件。 String resource = \"mybatis-configuration.xml\"; //2.获取文件并将其读取成流。 InputStream inputStream = RoleTest.class.getClassLoader().getResourceAsStream(resource); //3.通过SqlSessionFactoryBuilder创建对象。 //4.通过build创建SQLSessionFactory。 SqlSessionFactory build = new SqlSessionFactoryBuilder().build(inputStream); //5.创建一个SqlSession对象 sqlSession = build.openSession(true); //使用Mapper接口形式 String username = \"admin\"; UserMapper mapper = sqlSession.getMapper(UserMapper.class); //6.进行数据库操作 List&lt;User&gt; userList = mapper.findUsersByUsername(username); System.out.println(userList); //7.前面设置了自动提交，所以不同提交事务，这里关闭资源。 sqlSession.close();} 我们通过SqlSession指定Sql的有下列几种方式： 方式1使用SqlSession直接通过namespace.id的形式操作xml： 12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.ooyhao.mybatis1.mybatis.mapper.UserMapper\"&gt; &lt;!--查询--&gt; &lt;select id=\"findUsersByUsername\" resultType=\"user\"&gt; select &lt;include refid=\"Base_Column_List\"/&gt; from tb_user &lt;where&gt; username = #{username} &lt;/where&gt; &lt;/select&gt;&lt;/mapper&gt; 测试方法： 123456789@Testpublic void testMybatisFindUsersByUsernameXML() { /*使用XML形式文件*/ String username = \"admin\"; List&lt;User&gt; list = sqlSession.selectList (\"com.ooyhao.mybatis1.mybatis.mapper.UserMapper.findUsersByUsername\", username); System.out.println(list); sqlSession.close();} 提示：com.ooyhao.mybatis1.mybatis.mapper.UserMapper是xml配置文件的namespace。findUsersByUsername是sql的id。 方式2使用Mapper接口结合注解的方式来执行SQL： 12@Select(\" select * from tb_user where username = #{value} \")List&lt;User&gt; findUsersByUsername(String username); 测试方法： 123456789@Testpublic void testFindUsersByUsername() { //使用Mapper文件形式 String username = \"admin\"; UserMapper mapper = sqlSession.getMapper(UserMapper.class); List&lt;User&gt; userList = mapper.findUsersByUsername(username); System.out.println(userList); sqlSession.close();} 提示：这种方式通过在接口方法上使用注解，来替代在xml文件中的SQL，简单sql可以使用注解。 方式3使用Mapper接口和XML文件关联来查询SQL并执行： Mapper接口： 1List&lt;User&gt; findUsersByUsername(String username); Xml文件： 12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.ooyhao.mybatis1.mybatis.mapper.UserMapper\"&gt; &lt;!--查询--&gt; &lt;select id=\"findUsersByUsername\" resultType=\"user\"&gt; select &lt;include refid=\"Base_Column_List\"/&gt; from tb_user &lt;where&gt; username = #{username} &lt;/where&gt; &lt;/select&gt;&lt;/mapper&gt; 单元测试方法： 123456789@Testpublic void testFindUsersByUsername() { //使用Mapper文件形式 String username = \"admin\"; UserMapper mapper = sqlSession.getMapper(UserMapper.class); List&lt;User&gt; userList = mapper.findUsersByUsername(username); System.out.println(userList); sqlSession.close();} 这种情况后面使用最多，但是有一些需要遵循的规则： 1234567891011//遵循四个原则1、Mapper.xml文件中的namespace与mapper接口的类路径相同。2、Mapper接口方法名和Mapper.xml中定义的每个statement的id相同 3、Mapper接口方法的输入参数类型和mapper.xml中定义的每个sql 的parameterType的类型相同4、Mapper接口方法的输出参数类型和mapper.xml中定义的每个sql的resultType的类型相同mapper动态代理 Mapper接口开发方法只需要程序员编写Mapper接口（相当于Dao接口），由Mybatis框架根据接口定义创建接口的动态代理对象，代理对象的方法体同上边Dao接口实现类方法。 mybatis官方推荐使用mapper代理方法开发mapper接口，程序员不用编写mapper接口实现类，使用mapper代理方法时，输入参数可以使用pojo包装对象或map对象，保证dao的通用性。 完整的Mybatis案例完整的配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!-- 通过源码我们可以分析读取优先级： 1、在 properties 内部自定义的属性值第一个被读取 2、然后读取 resource 路径表示文件中的属性，如果有它会覆盖已经读取的属性； 如果 resource 路径不存在，那么读取 url 表示路径文件中的属性， 如果有它会覆盖第一步读取的属性值 3、最后读取 parameterType 传递的属性值，它会覆盖已读取的同名的属性 --&gt; &lt;!--引入properties的属性文件,数据库配置--&gt; &lt;properties resource=\"mybatis.properties\"&gt; &lt;/properties&gt; &lt;!--设置使用驼峰命名--&gt; &lt;settings&gt; &lt;setting name=\"mapUnderscoreToCamelCase\" value=\"true\"/&gt; &lt;setting name=\"logPrefix\" value=\"##Mybatis##\"/&gt; &lt;setting name=\"logImpl\" value=\"STDOUT_LOGGING\"/&gt; &lt;/settings&gt; &lt;!--设置别名--&gt; &lt;!-- mybatis自动扫描包中的po类，自动定义别名，别名是类名(首字母大写或小写都可以,一般用小写) --&gt; &lt;typeAliases&gt; &lt;package name=\"com.ooyhao.mybatis3.bean\"/&gt; &lt;/typeAliases&gt; &lt;!--配置环境--&gt; &lt;environments default=\"development\"&gt; &lt;!--可以用来配置不同环境的参数，例如：开发，测试，生产--&gt; &lt;environment id=\"development\"&gt; &lt;!--事务管理--&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;!--数据源--&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"${jdbc.driver}\"/&gt; &lt;property name=\"url\" value=\"${jdbc.url}\"/&gt; &lt;property name=\"username\" value=\"${jdbc.username}\"/&gt; &lt;property name=\"password\" value=\"${jdbc.password}\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!--mapper xml文件--&gt; &lt;mappers&gt; &lt;!--&lt;package name=\"mapper\"/&gt;--&gt; &lt;mapper resource=\"mapper/UserMapper.xml\"/&gt; &lt;mapper resource=\"mapper/RoleMapper.xml\"/&gt; &lt;mapper resource=\"mapper/VehicleMapper.xml\"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 配置文件解析【通过properties 的resource属性引入properties文件】 12&lt;!--引入properties的属性文件,数据库配置--&gt;&lt;properties resource=\"mybatis.properties\"&gt;&lt;/properties&gt; 【延迟加载技术】 12345678910&lt;settings&gt; &lt;!--开启驼峰命名--&gt; &lt;setting name=\"mapUnderscoreToCamelCase\" value=\"true\"/&gt; &lt;!--日志输出--&gt; &lt;setting name=\"logImpl\" value=\"STDOUT_LOGGING\"/&gt; &lt;!--开启延迟加载--&gt; &lt;setting name=\"lazyLoadingEnabled\" value=\"true\"/&gt; &lt;!--关闭强制延迟加载技术--&gt; &lt;setting name=\"aggressiveLazyLoading\" value=\"false\"/&gt;&lt;/settings&gt; 【包别名】 1234567&lt;!--设置别名--&gt;&lt;!-- mybatis自动扫描包中的po类，自动定义别名，别名是类名(首字母大写或小写都可以,一般用小写) --&gt;&lt;typeAliases&gt; &lt;package name=\"com.ooyhao.mybatis3.bean\"/&gt;&lt;/typeAliases&gt; 【配置数据库信息】（要根据自己的环境来设置） 123456789101112131415&lt;!--配置环境--&gt;&lt;environments default=\"development\"&gt; &lt;!--可以用来配置不同环境的参数，例如：开发，测试，生产--&gt; &lt;environment id=\"development\"&gt; &lt;!--事务管理--&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;!--数据源--&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"${jdbc.driver}\"/&gt; &lt;property name=\"url\" value=\"${jdbc.url}\"/&gt; &lt;property name=\"username\" value=\"${jdbc.username}\"/&gt; &lt;property name=\"password\" value=\"${jdbc.password}\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt;&lt;/environments&gt; 【通过在mapper标签中引入mapper文件】 （一定要注意每新创建一个mapper文件需要在配置文件中配置） 1234567&lt;!--mapper xml文件--&gt;&lt;mappers&gt; &lt;!--&lt;package name=\"mapper\"/&gt;--&gt; &lt;mapper resource=\"mapper/UserMapper.xml\"/&gt; &lt;mapper resource=\"mapper/RoleMapper.xml\"/&gt; &lt;mapper resource=\"mapper/VehicleMapper.xml\"/&gt;&lt;/mappers&gt; properties属性文件123456jdbc.driver= com.mysql.jdbc.Driverjdbc.url = jdbc:mysql://120.79.167.xxx:3306/mybatis ?useUnicode=true&amp;characterEncoding=UTF-8 &amp;allowMultiQueries=true&amp;autoReconnect=true&amp;useSSL=falsejdbc.username = rootjdbc.password = root UserMapper接口文件123public interface UserMapper { User findUserWithRolesByUserId(Integer id);} UserMapper.xml接口文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.ooyhao.mybatis3.mapper.UserMapper\"&gt; &lt;resultMap id=\"BaseResultWithRole\" type=\"com.ooyhao.mybatis3.bean.User\"&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;result column=\"user_id\" jdbcType=\"VARCHAR\" property=\"userId\"/&gt; &lt;result column=\"username\" jdbcType=\"VARCHAR\" property=\"username\"/&gt; &lt;result column=\"password\" jdbcType=\"VARCHAR\" property=\"password\"/&gt; &lt;result column=\"email\" jdbcType=\"VARCHAR\" property=\"email\"/&gt; &lt;result column=\"phone\" jdbcType=\"VARCHAR\" property=\"phone\"/&gt; &lt;result column=\"gender\" jdbcType=\"INTEGER\" property=\"gender\"/&gt; &lt;result column=\"birthday\" jdbcType=\"DATE\" property=\"birthday\"/&gt; &lt;result column=\"status\" jdbcType=\"INTEGER\" property=\"status\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"create_user\" jdbcType=\"VARCHAR\" property=\"createUser\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;result column=\"modify_user\" jdbcType=\"VARCHAR\" property=\"modifyUser\"/&gt; &lt;collection property=\"roles\" ofType=\"role\" column=\"id\" select=\"selectRole\" /&gt; &lt;/resultMap&gt; &lt;resultMap id=\"selectRole\" type=\"role\"&gt; &lt;id column=\"cid\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;result column=\"role_name\" jdbcType=\"VARCHAR\" property=\"roleName\"/&gt; &lt;result column=\"description\" jdbcType=\"VARCHAR\" property=\"description\"/&gt; &lt;result column=\"status\" jdbcType=\"INTEGER\" property=\"status\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"create_user\" jdbcType=\"VARCHAR\" property=\"createUser\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;result column=\"modify_user\" jdbcType=\"VARCHAR\" property=\"modifyUser\"/&gt; &lt;/resultMap&gt; &lt;select id=\"findUserWithRolesByUserId\" resultMap=\"BaseResultWithRole\"&gt; select a.id,a.user_id,a.username,a.password,a.email,a.phone,a.gender, a.birthday,a.status,a.create_time,a.create_user,a.modify_time,a.create_user from tb_user a where a.id = #{id} &lt;/select&gt; &lt;select id=\"selectRole\" resultType=\"role\" &gt; select b.* from tb_user_role a left join tb_role b on a.role_id = b.id where a.user_id = #{id} &lt;/select&gt;&lt;/mapper&gt; 单元测试123456789101112131415161718192021public class UserTest { SqlSession sqlSession = null; @Before public void init(){ String resource = \"mybatis-configuration.xml\"; InputStream inputStream = UserTest.class.getClassLoader().getResourceAsStream(resource); sqlSession = new SqlSessionFactoryBuilder().build(inputStream).openSession(true); } @Test public void findUserWithRolesByUserId(){ UserMapper mapper = sqlSession.getMapper(UserMapper.class); User user = mapper.findUserWithRolesByUserId(1); System.out.println(JSONObject.toJSONString(user)); sqlSession.close(); }} 测试结果 总结​ 这一节仅仅通过JDBC和Mybatis的操作比较，来引出Mybatis，初一看，可能会觉得Mybatis配置文件很繁琐，但是当我们书写多个SQL之后，就会觉得Mybatis仅仅是在第一次配置有些繁琐，后面书写SQL会很方便，而使用JDBC方式，每次写sql都会连带着5，60%的与业务无关的代码 ，而且每次都写的是一样的，比如获取Connection，获取Statement，关闭资源。 源码地址： https://gitee.com/ooyhao/JavaRepo_Public/tree/master/Mybatis","link":"/2020/01/18/SSM/mybatis/1Mybatis%E7%9A%84%E5%88%9D%E6%AC%A1%E9%81%87%E8%A7%81/"},{"title":"九、整合PageHelper实现分页","text":"由于为了后续使用SpringBoot，本人还是推荐使用Java配置类来操作，但是这里还是提一下XML配置。（本文项目基于第六节Mybatis集成Spring操作） XML配置方式使用XML文件来配置Mybatis的PageHelper分页插件： mybatis-configuration:(mybatis的全局配置文件) 1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!--配置开启自动匹配驼峰--&gt; &lt;settings&gt; &lt;setting name=\"mapUnderscoreToCamelCase\" value=\"true\"/&gt; &lt;/settings&gt; &lt;!--配置PageHelper分页插件拦截器--&gt; &lt;plugins&gt; &lt;plugin interceptor=\"com.github.pagehelper.PageInterceptor\"&gt; &lt;property name=\"offsetAsPageNum\" value=\"true\"/&gt; &lt;property name=\"helperDialect\" value=\"mysql\"/&gt; &lt;property name=\"rowBoundsWithCount\" value=\"true\"/&gt; &lt;property name=\"reasonable\" value=\"true\"/&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; Java配置类方式完整的配置类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495@Configuration //标注为一个配置类@PropertySource(value = \"classpath:application.properties\") //加载属性文件@ComponentScan(basePackages = \"com.ooyhao.mybatis\") //组件扫描@MapperScan(basePackages = {\"com.ooyhao.mybatis.mapper\"}) //mapper文件的扫描@EnableTransactionManagement //开启事务管理public class AppConfig { @Value(\"${jdbc.url}\") private String url; @Value(\"${jdbc.driver}\") private String driverClassName; @Value(\"${jdbc.username}\") private String username; @Value(\"${jdbc.password}\") private String password; @Value(\"${mybatis.configuration}\") private String mybatisConfiguration; @Value(\"${mybatis.mapperLocations}\") private String mybatisMapperLocations; @Value(\"${mybatis.typeAliasesPackage}\") private String mybatisTypeAliasesPackage; /*配置数据源*/ @Bean public DataSource dataSource(){ DruidDataSource druidDataSource = new DruidDataSource(); druidDataSource.setUrl(url); druidDataSource.setDriverClassName(driverClassName); druidDataSource.setUsername(username); druidDataSource.setPassword(password); return druidDataSource; } @Bean public PageInterceptor pageInterceptor(){ PageInterceptor pageInterceptor = new PageInterceptor(); Properties properties = new Properties(); /*4.0.0版本之后可以不用配置*/ properties.setProperty(\"helperDialect\",\"mysql\"); /*默认为false，会将RowBounds第一个参数offset当成pageNum页面使用 * 和startPage中的pageNum效果一样*/ properties.setProperty(\"offsetAsPageNum\",\"true\"); /*RowBounds方式是否做count查询 默认false*/ properties.setProperty(\"rowBoundsWithCount\",\"true\"); /*分页合理化，true开启，如果分页参数不合理会自动修正。默认false不启用*/ properties.setProperty(\"reasonable\",\"true\"); /*是否允许接口方法参数来传递分页参数 默认false*/ properties.setProperty(\"supportMethodsArguments\",\"true\"); pageInterceptor.setProperties(properties); /*当设置为true的时候，如果pageSize设置为0（或RowBounds的limit=0），就不执行分页*/ properties.setProperty(\"pageSizeZero\",\"true\"); return pageInterceptor; } /*Mybatis的全局配置*/ @Bean public SqlSessionFactoryBean sqlSessionFactoryBean(DataSource dataSource) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); /*配置Mybatis的全局配置文件*/ ClassPathResource resource = new ClassPathResource(mybatisConfiguration); sqlSessionFactoryBean.setConfigLocation(resource); /*配置Mapper.xml文件的路径*/ PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); Resource[] resources = resolver.getResources(mybatisMapperLocations); sqlSessionFactoryBean.setMapperLocations(resources); /*配置别名包*/ sqlSessionFactoryBean.setTypeAliasesPackage(mybatisTypeAliasesPackage); /*设置数据源，位置有要求，需要在下面几项之前*/ sqlSessionFactoryBean.setDataSource(dataSource); /*将PageHelper分页插件以拦截器的形式配置*/ sqlSessionFactoryBean.setPlugins(new Interceptor[]{pageInterceptor()}); /*配置驼峰命名*/ sqlSessionFactoryBean.getObject().getConfiguration().setMapUnderscoreToCamelCase(true); /*配置日志类*/ sqlSessionFactoryBean.getObject().getConfiguration().setLogImpl(StdOutImpl.class); /*设置开启缓存*/ sqlSessionFactoryBean.getObject().getConfiguration().setCacheEnabled(true); return sqlSessionFactoryBean; } /*配置数据源事务管理器，需要将数据源注入*/ @Bean public DataSourceTransactionManager transactionManager(DataSource dataSource){ DataSourceTransactionManager transactionManager = new DataSourceTransactionManager(); transactionManager.setDataSource(dataSource); return transactionManager; }} 提示： 添加了PageInterceptor 组件 通过 sqlSessionFactoryBean.setPlugins(new Interceptor[]{pageInterceptor()});设置到SqlSessionFactoryBean中 开启了这个properties.setProperty(&quot;supportMethodsArguments&quot;,&quot;true&quot;);则表示可以通过Mapper来进行参数传递，实现分页，如下： 1List&lt;Role&gt; findByPage(@Param(\"pageNum\") int pageNum,@Param(\"pageSize\") int pageSize); xml文件不需要修改，只需要在参数上添加形参即可。 PageHelper的PageInterceptor的参数说明：一下是PageParams类中的setProperties方法的源码： 12345678910111213141516171819202122232425public void setProperties(Properties properties) { //offset作为PageNum使用 String offsetAsPageNum = properties.getProperty(\"offsetAsPageNum\"); this.offsetAsPageNum = Boolean.parseBoolean(offsetAsPageNum); //RowBounds方式是否做count查询 String rowBoundsWithCount = properties.getProperty(\"rowBoundsWithCount\"); this.rowBoundsWithCount = Boolean.parseBoolean(rowBoundsWithCount); //当设置为true的时候，如果pagesize设置为0（或RowBounds的limit=0），就不执行分页 String pageSizeZero = properties.getProperty(\"pageSizeZero\"); this.pageSizeZero = Boolean.parseBoolean(pageSizeZero); //分页合理化，true开启，如果分页参数不合理会自动修正。默认false不启用 String reasonable = properties.getProperty(\"reasonable\"); this.reasonable = Boolean.parseBoolean(reasonable); //是否支持接口参数来传递分页参数，默认false String supportMethodsArguments = properties.getProperty(\"supportMethodsArguments\"); this.supportMethodsArguments = Boolean.parseBoolean(supportMethodsArguments); //默认count列 String countColumn = properties.getProperty(\"countColumn\"); if(StringUtil.isNotEmpty(countColumn)){ this.countColumn = countColumn; } //当offsetAsPageNum=false的时候，不能 //参数映射 PageObjectUtil.setParams(properties.getProperty(\"params\"));} 测试： 下面是测试结果，以及获取PageInfo中的各个参数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class AppTest { AnnotationConfigApplicationContext context = null; @Before public void init(){ context = new AnnotationConfigApplicationContext(AppConfig.class); } @Test public void testFindByPage(){ RoleService bean = context.getBean(RoleService.class); /*是否需要计算总条数*/ List&lt;Role&gt; page = bean.findByPage(2, 2, true); PageInfo&lt;Role&gt; pageInfo = new PageInfo&lt;&gt;(page); //返回的是Page对象，Page是ArrayList的子类。由于Page重写了toString方法 List&lt;Role&gt; list = pageInfo.getList(); System.out.println(JSONObject.toJSONString(list)); System.out.println(JSONObject.toJSON(list)); //SQL查询的数据总条数 System.out.println(\"total:\"+pageInfo.getTotal());//22 //总分页数 System.out.println(\"pages:\"+pageInfo.getPages());//8 //自动生成一个分页导航，大小为8（如果满足）[1, 2, 3, 4, 5, 6, 7, 8] System.out.println(\"navigatepageNums:\"+Arrays.toString(pageInfo.getNavigatepageNums())); //分页导航的第一页 System.out.println(\"navigateFirstPage:\"+pageInfo.getNavigateFirstPage());//1 //分页导航的最后一页 System.out.println(\"navigateLastPage:\"+pageInfo.getNavigateLastPage());//8 //分页导航的总页数 System.out.println(\"navigatePages:\"+pageInfo.getNavigatePages());//8 //当前页 System.out.println(\"pageNum:\"+pageInfo.getPageNum());//2 //当前页的上一页 System.out.println(\"prePage:\"+pageInfo.getPrePage());//1 //当前页的下一页 System.out.println(\"nextPage:\"+pageInfo.getNextPage());//3 //每页的数据条数 System.out.println(\"pageSize:\"+pageInfo.getPageSize());//3 //当前页的开始行号 System.out.println(\"startRow:\"+pageInfo.getStartRow());//4 //当前页的结束行号 System.out.println(\"endRow:\"+pageInfo.getEndRow());//6 }} 提示: List list = pageInfo.getList();我们通过打印这个list对象是无法正常打印出Role对象的数据，是因为Page对象继承自ArrayList，并且重写了toString方法。我们可以通过迭代循环打印出来。如下图: ​ 这里由于循环打印才能看到Role对象的真实面部，个人觉得麻烦，所以使用了fastJson格式化为Json，但是发现一个之前没有留意的问题： ​ 通过上面打印出的结果可以发现，list既然是Page对象，但是我们可以看到Page类中有诸多属性，为何通过JSON格式化工具之后，就没有了呢？通过查询fastJson的toJson源码就可以发现奥秘了，如下： 123456789101112131415public static Object toJSON(Object javaObject, SerializeConfig config) { ...... if (javaObject instanceof Collection) { Collection&lt;Object&gt; collection = (Collection&lt;Object&gt;) javaObject; JSONArray array = new JSONArray(collection.size()); for (Object item : collection) { Object jsonValue = toJSON(item, config); array.add(jsonValue); } return array; } ...... String text = JSON.toJSONString(javaObject); return JSON.parse(text);} ​ 里面有这样一个判断，如果对象是Collection或其子类，则强转为Collection，所以我们会发现，在使用JSONObject.toJson或是toJsonString的时候，不管是ArrayList还是Page中的属性都没有了，这是因为取的是Collection。对于数据存储，需要进一步研究Collection系列集合，暂不涉及。 Page对象源码下面我们看一下Page对象源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354public class Page&lt;E&gt; extends ArrayList&lt;E&gt; implements Closeable { private static final long serialVersionUID = 1L; /** * 页码，从1开始 */ private int pageNum; /** * 页面大小 */ private int pageSize; /** * 起始行 */ private int startRow; /** * 末行 */ private int endRow; /** * 总数 */ private long total; /** * 总页数 */ private int pages; /** * 包含count查询 */ private boolean count = true; /** * 分页合理化 */ private Boolean reasonable; /** * 当设置为true的时候，如果pagesize设置为0（或RowBounds的limit=0），就不执行分页，返回全部结果 */ private Boolean pageSizeZero; /** * 进行count查询的列名 */ private String countColumn; /** * 排序 */ private String orderBy; /** * 只增加排序 */ private boolean orderByOnly; public Page() { super(); } public Page(int pageNum, int pageSize) { this(pageNum, pageSize, true, null); } public Page(int pageNum, int pageSize, boolean count) { this(pageNum, pageSize, count, null); } private Page(int pageNum, int pageSize, boolean count, Boolean reasonable) { super(0); if (pageNum == 1 &amp;&amp; pageSize == Integer.MAX_VALUE) { pageSizeZero = true; pageSize = 0; } this.pageNum = pageNum; this.pageSize = pageSize; this.count = count; calculateStartAndEndRow(); setReasonable(reasonable); } /** * int[] rowBounds * 0 : offset * 1 : limit */ public Page(int[] rowBounds, boolean count) { super(0); if (rowBounds[0] == 0 &amp;&amp; rowBounds[1] == Integer.MAX_VALUE) { pageSizeZero = true; this.pageSize = 0; } else { this.pageSize = rowBounds[1]; this.pageNum = rowBounds[1] != 0 ? (int) (Math.ceil(((double) rowBounds[0] + rowBounds[1]) / rowBounds[1])) : 0; } this.startRow = rowBounds[0]; this.count = count; this.endRow = this.startRow + rowBounds[1]; } public List&lt;E&gt; getResult() { return this; } public int getPages() { return pages; } public Page&lt;E&gt; setPages(int pages) { this.pages = pages; return this; } public int getEndRow() { return endRow; } public Page&lt;E&gt; setEndRow(int endRow) { this.endRow = endRow; return this; } public int getPageNum() { return pageNum; } public Page&lt;E&gt; setPageNum(int pageNum) { //分页合理化，针对不合理的页码自动处理 this.pageNum = ((reasonable != null &amp;&amp; reasonable) &amp;&amp; pageNum &lt;= 0) ? 1 : pageNum; return this; } public int getPageSize() { return pageSize; } public Page&lt;E&gt; setPageSize(int pageSize) { this.pageSize = pageSize; return this; } public int getStartRow() { return startRow; } public Page&lt;E&gt; setStartRow(int startRow) { this.startRow = startRow; return this; } public long getTotal() { return total; } public void setTotal(long total) { this.total = total; if (total == -1) { pages = 1; return; } if (pageSize &gt; 0) { pages = (int) (total / pageSize + ((total % pageSize == 0) ? 0 : 1)); } else { pages = 0; } //分页合理化，针对不合理的页码自动处理 if ((reasonable != null &amp;&amp; reasonable) &amp;&amp; pageNum &gt; pages) { pageNum = pages; calculateStartAndEndRow(); } } public Boolean getReasonable() { return reasonable; } public Page&lt;E&gt; setReasonable(Boolean reasonable) { if (reasonable == null) { return this; } this.reasonable = reasonable; //分页合理化，针对不合理的页码自动处理 if (this.reasonable &amp;&amp; this.pageNum &lt;= 0) { this.pageNum = 1; calculateStartAndEndRow(); } return this; } public Boolean getPageSizeZero() { return pageSizeZero; } public Page&lt;E&gt; setPageSizeZero(Boolean pageSizeZero) { if (pageSizeZero != null) { this.pageSizeZero = pageSizeZero; } return this; } public String getOrderBy() { return orderBy; } public &lt;E&gt; Page&lt;E&gt; setOrderBy(String orderBy) { this.orderBy = orderBy; return (Page&lt;E&gt;) this; } public boolean isOrderByOnly() { return orderByOnly; } public void setOrderByOnly(boolean orderByOnly) { this.orderByOnly = orderByOnly; } /** * 计算起止行号 */ private void calculateStartAndEndRow() { this.startRow = this.pageNum &gt; 0 ? (this.pageNum - 1) * this.pageSize : 0; this.endRow = this.startRow + this.pageSize * (this.pageNum &gt; 0 ? 1 : 0); } public boolean isCount() { return this.count; } public Page&lt;E&gt; setCount(boolean count) { this.count = count; return this; } /** * 设置页码 * * @param pageNum * @return */ public Page&lt;E&gt; pageNum(int pageNum) { //分页合理化，针对不合理的页码自动处理 this.pageNum = ((reasonable != null &amp;&amp; reasonable) &amp;&amp; pageNum &lt;= 0) ? 1 : pageNum; return this; } /** * 设置页面大小 * * @param pageSize * @return */ public Page&lt;E&gt; pageSize(int pageSize) { this.pageSize = pageSize; calculateStartAndEndRow(); return this; } /** * 是否执行count查询 * * @param count * @return */ public Page&lt;E&gt; count(Boolean count) { this.count = count; return this; } /** * 设置合理化 * * @param reasonable * @return */ public Page&lt;E&gt; reasonable(Boolean reasonable) { setReasonable(reasonable); return this; } /** * 当设置为true的时候，如果pagesize设置为0（或RowBounds的limit=0），就不执行分页，返回全部结果 * * @param pageSizeZero * @return */ public Page&lt;E&gt; pageSizeZero(Boolean pageSizeZero) { setPageSizeZero(pageSizeZero); return this; } /** * 指定 count 查询列 * * @param columnName * @return */ public Page&lt;E&gt; countColumn(String columnName) { this.countColumn = columnName; return this; } /** * 转换为PageInfo * * @return */ public PageInfo&lt;E&gt; toPageInfo() { PageInfo&lt;E&gt; pageInfo = new PageInfo&lt;E&gt;(this); return pageInfo; } public &lt;E&gt; Page&lt;E&gt; doSelectPage(ISelect select) { select.doSelect(); return (Page&lt;E&gt;) this; } public &lt;E&gt; PageInfo&lt;E&gt; doSelectPageInfo(ISelect select) { select.doSelect(); return (PageInfo&lt;E&gt;) this.toPageInfo(); } public long doCount(ISelect select) { this.pageSizeZero = true; this.pageSize = 0; select.doSelect(); return this.total; } public String getCountColumn() { return countColumn; } public void setCountColumn(String countColumn) { this.countColumn = countColumn; } @Override public String toString() { return \"Page{\" + \"count=\" + count + \", pageNum=\" + pageNum + \", pageSize=\" + pageSize + \", startRow=\" + startRow + \", endRow=\" + endRow + \", total=\" + total + \", pages=\" + pages + \", reasonable=\" + reasonable + \", pageSizeZero=\" + pageSizeZero + '}'; } @Override public void close() { PageHelper.clearPage(); }}","link":"/2020/01/18/SSM/mybatis/9Mybatis%E6%95%B4%E5%90%88PageHelper/"},{"title":"十八、Sentinel规则之流量控制规则","text":"Sentinel规则之流量控制规则 概述流量控制(flow control), 其原理是监控应用的QPS或并发线程数等指标，当达到指定的阈值时对流量进行控制，以避免被瞬时的流量高峰冲垮，从而保障应用的高可用性。 文档：https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6 继承结构同一资源可以创建多条限流规则。我们先看一下继承结构： 下面是Rule接口代码： 123public interface Rule { boolean passCheck(Context context, DefaultNode node, int count, Object... args);} AbstractRule: 12345678910public abstract class AbstractRule implements Rule { /** * 资源名，资源名是限流规则的作用对象。 */ private String resource; /** * 流控针对的调用来源，default代表不区分调用来源 */ private String limitApp;} FlowRule： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class FlowRule extends AbstractRule { /** * 限流阈值类型 0：线程数 1：QPS queries per second */ private int grade = RuleConstant.FLOW_GRADE_QPS; /** * 数量。限流阈值 */ private double count; /** * 流控模式 * public static final int STRATEGY_DIRECT = 0; //direct 直接模式 * public static final int STRATEGY_RELATE = 1; //relate 关联 * public static final int STRATEGY_CHAIN = 2; //chain 链路 */ private int strategy = RuleConstant.STRATEGY_DIRECT; /** * Reference resource in flow control with relevant resource or context. */ private String refResource; /** * Rate limiter control behavior. * 流控控制效果（直接拒绝，Warm up，匀速排队） * 0. default(reject directly), 1. warm up, 2. rate limiter, 3. warm up + rate limiter */ private int controlBehavior = RuleConstant.CONTROL_BEHAVIOR_DEFAULT; private int warmUpPeriodSec = 10; /** * Max queueing time in rate limiter behavior. */ private int maxQueueingTimeMs = 500; private boolean clusterMode; /** * 集群模式 */ private ClusterFlowConfig clusterConfig; /** * The traffic shaping (throttling) controller. */ private TrafficShapingController controller; @Override public boolean passCheck(Context context, DefaultNode node, int acquireCount, Object... args) { return true; }} 单条限流规则主要由以下几个因素组成，我们可以组合这些元素实现不同的限流效果： resource : 资源名，即限流规则的作用对象 count : 限流阈值 grade : 限流阈值类型(QPS或是并发线程数) limitApp : 流控针对的调用来源，若为default 则不区分来源 strategy : 调用关系限流策略 controlBehavior ：流量控制效果(直接拒绝,Warm Up,均速排队) 基本代码12345678910111213141516171819202122232425262728293031// EchoController@RestControllerpublic class EchoController { @Autowired private EchoService echoService; @GetMapping(\"/echo/{str}\") public String echo(@PathVariable String str, HttpServletRequest request){ return echoService.echo(str); }}// EchoServicepublic interface EchoService { String echo(String str);}// EchoServiceImpl@Servicepublic class EchoServiceImpl implements EchoService { @Override @SentinelResource(value = \"echo\",blockHandler = \"handleBlockException\") public String echo(String str) { return \"echo str:\"+str; } public String handleBlockException(String str, BlockException ex){ return \"str:\"+str+\" | e:\"+ex; }} 基于QPS流量控制当QPS超过某个阈值的时候，则采用措施进行流量控制（基于并发线程数的没有这个控制）。流量控制的手段包括以下几种：直接拒绝，Warm Up，均速排队。对应FlowRule 中的controlBeHavior字段。 https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6#22-qps%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6 流量控制 直接拒绝:(RuleConstant.CONTROL_BEHAVIOR_DEFAULT)方式是默认的流量控制方式，当QPS超过任何规则的阈值后，新的请求就会立即拒绝，拒绝方式为抛出FlowException . 这种方式适用于对系统处理能力确切已知的情况下，比如通过压测确定了系统的准确水位时。 Warm Up:(RuleConstant.CONTROL_BEHAVIOR_WARM_UP)方式，即预热/冷启动方式。当系统长期处理低水平的情况下，当流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。通过”冷启动”，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值的上限，给系统一个预热的时间，避免冷系统被压垮。 通常冷启动的过程系统允许通过的 QPS 曲线如下图所示： ​ ​ 均速排队:(RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER)方式后严格控制请求通过的时间间隔，也即是让请求以均匀的速度通过，对应的是漏桶算法。 该方式的作用如下图所示： 这种方式主要用于处理间隔性突发的流量，例如消息队列。想象一下这样的场景，在某一秒有大量的请求到来，而接下来的几秒则处于空闲状态，我们希望系统能够在接下来的空闲期间逐渐处理这些请求，而不是在第一秒直接拒绝多余的请求。 代码测试初始化规则： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/*初始化规则*/public static void initRule(){ List&lt;FlowRule&gt; rules = new ArrayList&lt;&gt;(); //定义规则 FlowRule rule = new FlowRule(); //定义资源 rule.setResource(\"echo\"); //定义模式 rule.setGrade(RuleConstant.FLOW_GRADE_QPS); //定义阈值 rule.setCount(2); rules.add(rule); FlowRuleManager.loadRules(rules);}public static void testFlowRule(){ initRule(); Entry entry = null; for (int i = 0; i &lt; 10; i++) { try { entry = SphU.entry(\"echo\"); System.out.println(\"访问成功\"); } catch (BlockException e) { System.out.println(\"当前访问人数过多，请刷新后重新!\"); }finally { if (entry != null){ entry.exit(); } } }}// ============== 执行结果 =================/**访问成功访问成功当前访问人数过多，请刷新后重试!当前访问人数过多，请刷新后重试!当前访问人数过多，请刷新后重试!当前访问人数过多，请刷新后重试!当前访问人数过多，请刷新后重试!当前访问人数过多，请刷新后重试!当前访问人数过多，请刷新后重试!当前访问人数过多，请刷新后重试!*/ 通过上面的代码可以测试出：当我们使用QPS为阈值类型时，并设置阈值为2，定义资源，其他默认，则表示一秒内，只需要通过两次请求，其他的均失败。 initRule()方法相当于在页面这样设置： 基于并发线程数控制代码测试： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public static void initFlowRuleForThreadNum() { List&lt;FlowRule&gt; rules = new ArrayList&lt;&gt;(); FlowRule rule = new FlowRule(); //定义以线程数控制 rule.setGrade(RuleConstant.FLOW_GRADE_THREAD); //定义资源名 rule.setResource(\"echo\"); //定义并发线程数阈值 rule.setCount(2); rules.add(rule); FlowRuleManager.loadRules(rules);}public static void testFlowRuleForThreadNum() { initFlowRuleForThreadNum(); for (int i = 0; i &lt; 5; i++) { new Thread() { @Override public void run() { for (int j = 0; j &lt; 5; j++) { Entry entry = null; try { entry = SphU.entry(\"echo\"); System.out.println(\"操作成功！\"); } catch (BlockException ex) { System.out.println(\"当前访问人数过多，请刷新后重试!\"); } finally { if (entry != null) { entry.exit(); } } } } }.start(); }}// ========================测试结果==================/**操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！操作成功！当前访问人数过多，请刷新后重试!操作成功！*/ 上面的初始化规则，相当于： 基于调用关系的流量控制 https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6#%E5%9F%BA%E4%BA%8E%E8%B0%83%E7%94%A8%E5%85%B3%E7%B3%BB%E7%9A%84%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6 根据调用方限流ContextUtil.enter(resourceName, origin) 方法中的origin 参数标明了调用身份。这些信息会在ClusterBuilderSlot 中统计。 流量规则中的limitApp 字段用于根据调用来源进行流量控制。该字段的值有以下三种选择，分别对应不同的场景： default ：表示不区分调用者，来自任何调用者的请求都将进行限流统计。如果这个资源名的调用总和超过了这条规则定义的阈值，则出发限流。 {some_origin_name} : 表示针对特定的调用者，只有来自这个调用者的请求才会进行流量控制。例如NodeA 配置了一条针对调用者caller1 的规则，那么当且仅当来自caller1 对 NodeA 的请求才会触发流量控制。 other ：表示针对除{some_origin_name} 以外的其余调用方的流量进行流量控制。例如：资源NodeA 配置了一条针对调用者caller1 的限流规则，同时又配置了一条调用者为other 的规则，那么任意来自非caller1 对NodeA 的调用，都不能超过other这条规则定义的阈值。 同一资源名可以配置多条规则，规则生效的顺序为:{some_origin_name} &gt; other &gt; default. 代码测试： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/*定义根据调用者的流控规则*/public static void initFlowRuleForCaller(){ List&lt;FlowRule&gt; rules = new ArrayList&lt;&gt;(); FlowRule rule = new FlowRule(); //定义资源名 rule.setResource(\"echo\"); //定义阈值类型 rule.setGrade(RuleConstant.FLOW_GRADE_QPS); //定义阈值 rule.setCount(2); //定义限制调用者 rule.setLimitApp(\"caller\"); rules.add(rule); FlowRule rule1 = new FlowRule(); rule1.setResource(\"echo\"); rule1.setGrade(RuleConstant.FLOW_GRADE_QPS); rule1.setLimitApp(\"other\"); rule1.setCount(3); rules.add(rule1); FlowRuleManager.loadRules(rules);}public static void testFlowRuleForCaller(){ initFlowRuleForCaller(); for (int i = 0; i &lt; 5; i++) { ContextUtil.enter(\"c1\",\"caller\"); Entry entry = null; try { entry = SphU.entry(\"echo\"); System.out.println(\"访问成功\"); } catch (BlockException e) { System.out.println(\"网络异常，请刷新！\"); }finally { if (entry != null){ entry.exit(); } } }}// =========测试结果：=========/*访问成功访问成功网络异常，请刷新！网络异常，请刷新！网络异常，请刷新！*/// ===========将caller换成caller1测试，结果如下============/*访问成功访问成功访问成功网络异常，请刷新！网络异常，请刷新！*/ 控制页面流控规则列表： 前面都是自己手动使用ContextUtil自己去埋点定义，那么在web场景下如何识别origin呢？ 这一部分放到最后，：如何自定义origin ? 根据调用链路限流NodeSelectorSlot 中记录了资源之间的调用链路，这些资源通过调用关系，相互之间构成一棵调用树。这棵树的根节点是一个名字为 machine-root 的虚拟节点，调用链的入口都是这个虚节点的子节点。 一棵典型的调用树如下图所示： 1234567 machine-root / \\ / \\ Entrance1 Entrance2 / \\ / \\DefaultNode(nodeA) DefaultNode(nodeA) 上图中来自入口 Entrance1 和 Entrance2 的请求都调用到了资源 NodeA，Sentinel 允许只根据某个入口的统计信息对资源限流。比如我们可以设置 FlowRule.strategy 为 RuleConstant.CHAIN，同时设置 FlowRule.ref_identity 为 Entrance1 来表示只有从入口 Entrance1 的调用才会记录到 NodeA 的限流统计当中，而不关心经 Entrance2 到来的调用。 调用链的入口（上下文）是通过 API 方法 ContextUtil.enter(contextName) 定义的，其中 contextName 即对应调用链路入口名称。 代码测试： 规则定义 12345678910111213141516public static void initFlowRuleForLink(){ List&lt;FlowRule&gt; rules = new ArrayList&lt;&gt;(); FlowRule rule = new FlowRule(); //定义流控模式 rule.setStrategy(RuleConstant.STRATEGY_CHAIN); //定义资源名 rule.setResource(\"echo\"); //定义入口资源 rule.setRefResource(\"Entrance1\"); //定义阈值类型 rule.setGrade(RuleConstant.FLOW_GRADE_QPS); //定义阈值 rule.setCount(2); rules.add(rule); FlowRuleManager.loadRules(rules);} 页面显示 测试 1234567891011121314151617181920212223242526272829303132public static void testFlowRuleForLink(){ initFlowRuleForLink(); for (int i = 0; i &lt; 5; i++) { ContextUtil.enter(\"Entrance1\"); Entry entry = null; try { entry = SphU.entry(\"echo\"); System.out.println(\"访问成功\"); } catch (BlockException e) { System.out.println(\"网络异常，请刷新！\"); }finally { if (entry != null){ entry.exit(); } } }}//========测试结果======/*访问成功访问成功网络异常，请刷新！网络异常，请刷新！网络异常，请刷新！*///========ContextUtil.enter(\"Entrance1\");修改为ContextUtil.enter(\"Entrance2\");====/*访问成功访问成功访问成功访问成功访问成功*/ 根据测试结果可以看出，这里只对入口为Entrance1 进行流量控制，对Entrance2 不进行流量控制。 具有关系的资源流量控制：关联流量控制当两个资源之间具有资源争抢或者依赖关系的时候，这两个资源便具有了关联。比如对数据库同一个字段的读操作和写操作存在争抢，读的速度过高会影响写得速度，写的速度过高会影响读的速度。如果放任读写操作争抢资源，则争抢本身带来的开销会降低整体的吞吐量。可使用关联限流来避免具有关联关系的资源之间过度的争抢，举例来说，read_db 和 write_db 这两个资源分别代表数据库读写，我们可以给 read_db 设置限流规则来达到写优先的目的：设置 FlowRule.strategy 为 RuleConstant.RELATE 同时设置 FlowRule.ref_identity 为 write_db。这样当写库操作过于频繁时，读数据的请求会被限流。 自定义Originalibaba的github FAQ中有提到： https://github.com/alibaba/Sentinel/wiki/FAQ#q-%E6%80%8E%E4%B9%88%E9%92%88%E5%AF%B9%E7%89%B9%E5%AE%9A%E8%B0%83%E7%94%A8%E7%AB%AF%E9%99%90%E6%B5%81%E6%AF%94%E5%A6%82%E6%88%91%E6%83%B3%E9%92%88%E5%AF%B9%E6%9F%90%E4%B8%AA-ip-%E6%88%96%E8%80%85%E6%9D%A5%E6%BA%90%E5%BA%94%E7%94%A8%E8%BF%9B%E8%A1%8C%E9%99%90%E6%B5%81%E8%A7%84%E5%88%99%E9%87%8C%E9%9D%A2-limitapp%E6%B5%81%E6%8E%A7%E5%BA%94%E7%94%A8%E7%9A%84%E4%BD%9C%E7%94%A8 在web情况下，会有一个名为CommonFilter 的Filter对请求进行过滤：我们来看一下源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class CommonFilter implements Filter { private final static String HTTP_METHOD_SPECIFY = \"HTTP_METHOD_SPECIFY\"; private final static String COLON = \":\"; private boolean httpMethodSpecify = false; @Override public void init(FilterConfig filterConfig) { httpMethodSpecify = Boolean.parseBoolean(filterConfig.getInitParameter(HTTP_METHOD_SPECIFY)); } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest sRequest = (HttpServletRequest)request; Entry urlEntry = null; try { String target = FilterUtil.filterTarget(sRequest); UrlCleaner urlCleaner = WebCallbackManager.getUrlCleaner(); if (urlCleaner != null) { target = urlCleaner.clean(target); } if (!StringUtil.isEmpty(target)) { //******* 主要看这个方法，这是用来转化origin的。 String origin = parseOrigin(sRequest); ContextUtil.enter(WebServletConfig.WEB_SERVLET_CONTEXT_NAME, origin); if (httpMethodSpecify) { String pathWithHttpMethod = sRequest.getMethod().toUpperCase() + COLON + target; urlEntry = SphU.entry(pathWithHttpMethod, ResourceTypeConstants.COMMON_WEB, EntryType.IN); } else { urlEntry = SphU.entry(target, ResourceTypeConstants.COMMON_WEB, EntryType.IN); } } chain.doFilter(request, response); } catch (BlockException e) { HttpServletResponse sResponse = (HttpServletResponse)response; WebCallbackManager.getUrlBlockHandler().blocked(sRequest, sResponse, e); } catch (IOException | ServletException | RuntimeException e2) { Tracer.traceEntry(e2, urlEntry); throw e2; } finally { if (urlEntry != null) { urlEntry.exit(); } ContextUtil.exit(); } } private String parseOrigin(HttpServletRequest request) { RequestOriginParser originParser = WebCallbackManager.getRequestOriginParser(); String origin = EMPTY_ORIGIN; if (originParser != null) { origin = originParser.parseOrigin(request); if (StringUtil.isEmpty(origin)) { return EMPTY_ORIGIN; } } return origin; } @Override public void destroy() {} private static final String EMPTY_ORIGIN = \"\";} parseOrigin方法： 123456789101112private String parseOrigin(HttpServletRequest request) { //这个方法需要从WebCallbackManager中拿出一个RequestOriginParser. RequestOriginParser originParser = WebCallbackManager.getRequestOriginParser(); String origin = EMPTY_ORIGIN; if (originParser != null) { origin = originParser.parseOrigin(request); if (StringUtil.isEmpty(origin)) { return EMPTY_ORIGIN; } } return origin;} RequestOriginParser接口： 123public interface RequestOriginParser { String parseOrigin(HttpServletRequest request);} 在项目中这个接口是没有实现的，所以正常情况下origin = &quot;&quot;. 我们需要自己实现，并将其加入到spring容器中即可。 12345678910111213/** * @author hao.ouYang * @create 2019-10-22 18:25 */@Componentpublic class IOriginParser implements RequestOriginParser { @Override public String parseOrigin(HttpServletRequest request) { String id = request.getParameter(\"id\"); System.out.println(id); return id; }}","link":"/2020/01/18/SSM/springcloudalibaba/15.sentinel%E8%A7%84%E5%88%99%E4%B9%8B%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E8%A7%84%E5%88%99/"},{"title":"十七、Sentinel注解支持","text":"Sentinel注解支持 官方文档：https://github.com/alibaba/Sentinel/wiki/%E6%B3%A8%E8%A7%A3%E6%94%AF%E6%8C%81 这一节，我们首先做一个小的案例，然后把官方文档中的介绍过一遍，再把文档所述的特性在代码中找到。 案例依赖12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 属性文件12345678910spring: cloud: sentinel: transport: dashboard: 127.0.0.1:8080 port: 8719 application: name: sentinel-annotaionserver: port: 9999 说明： spring.application.name 定义应用名,如图所示的名称 server.port :应用端口 spring.cloud.sentinel.transport.dashboard :sentinel的IP:端口 spring.cloud.sentinel.transport.port :sentinel 与服务的通讯端口 切面如果使用的是Spring Boot/Cloud ，即没有导入前面的依赖，需要自己将切面纳入到Spring容器中去： 1234@Beanpublic SentinelResourceAspect sentinelResourceAspect() { return new SentinelResourceAspect();} 由于我们导入了springcloud的依赖，所以会自动配置好这个切面,源码如下： EchoService1234public interface EchoService { String echoMessage(String message); String hello();} EchoServiceImpl1234567891011121314151617181920@Servicepublic class EchoServiceImpl implements EchoService { @Override @SentinelResource(value = \"echo.message\",blockHandler = \"handleException\", blockHandlerClass = ExceptionUtil.class) public String echoMessage(String message) { return \"echo message:\"+message; } @Override @SentinelResource(value = \"hello\",blockHandler = \"handleHello\") public String hello() { return \"echo hello\"; } public String handleHello(BlockException ex){ return \"handle hello ; exception:\"+ex; }} ExceptionUtil12345public class ExceptionUtil { public static String handleException(String message, BlockException ex){ return \"exception handle \"+message + \" exception:\"+ex; }} EchoController12345678910111213141516@RestControllerpublic class EchoController { @Autowired private EchoService echoService; @GetMapping(\"/echo/message/{message}\") public String echoMessage(@PathVariable String message){ return echoService.echoMessage(message); } @GetMapping(\"/hello\") public String hello(){ return echoService.hello(); }} 页面控制流控流控限制如下，简单使用基于QPS的流控规则（规则后续会详细说到），阈值为2，流控效果选的是快速失败。 通过测试，当我们在页面快速刷新（达到一秒访问3次或3次以上）可以看到下面的效果。 @SentinelResource 注解@sentinelResource 注解用于定义资源，并提供可选的异常处理和fallback配置项，@sentinelResource 注解包含以下属性： 注解源码12345678910111213141516171819202122232425262728@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Inheritedpublic @interface SentinelResource { //资源名 String value() default \"\"; //entry 类型 EntryType entryType() default EntryType.OUT; //指定异常处理函数名 String blockHandler() default \"\"; //如果异常处理函数不与目标方法在同一个类，则需要指定类，并且异常处理函数需要声明为static Class&lt;?&gt;[] blockHandlerClass() default {}; //fallback函数名，默认为空 String fallback() default \"\"; //指定默认fallback函数 String defaultFallback() default \"\"; //同样，fallback函数需要和目标方法在同一个类，如果不再，则需要指定，并且对应的函数需要声明为static Class&lt;?&gt;[] fallbackClass() default {}; // Class&lt;? extends Throwable&gt;[] exceptionsToTrace() default {Throwable.class}; //指定排除的异常类型，不进入异常统计，也不会进入fallback函数处理，而是原样抛出。 Class&lt;? extends Throwable&gt;[] exceptionsToIgnore() default {};} 文档原文@SentinelResource 用于定义资源，并提供可选的异常处理和 fallback 配置项。 @SentinelResource 注解包含以下属性： value：资源名称，必需项（不能为空） entryType：entry 类型，可选项（默认为 EntryType.OUT） blockHandler / blockHandlerClass: blockHandler对应处理 BlockException 的函数名称，可选项。blockHandler 函数访问范围需要是 public，返回类型需要与原方法相匹配，参数类型需要和原方法相匹配并且最后加一个额外的参数，类型为 BlockException。blockHandler 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 blockHandlerClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 fallback：fallback 函数名称，可选项，用于在抛出异常的时候提供 fallback 处理逻辑。fallback 函数可以针对所有类型的异常（除了 exceptionsToIgnore 里面排除掉的异常类型）进行处理。fallback 函数签名和位置要求：返回值类型必须与原函数返回值类型一致；方法参数列表需要和原函数一致，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。fallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 defaultFallback（since 1.6.0）：默认的 fallback 函数名称，可选项，通常用于通用的 fallback 逻辑（即可以用于很多服务或方法）。默认 fallback 函数可以针对所有类型的异常（除了 exceptionsToIgnore 里面排除掉的异常类型）进行处理。若同时配置了 fallback 和 defaultFallback，则只有 fallback 会生效。defaultFallback 函数签名要求：返回值类型必须与原函数返回值类型一致；方法参数列表需要为空，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。defaultFallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 exceptionsToIgnore（since 1.6.0）：用于指定哪些异常被排除掉，不会计入异常统计中，也不会进入 fallback 逻辑中，而是会原样抛出。 注：1.6.0 之前的版本 fallback 函数只针对降级异常（DegradeException）进行处理，不能针对业务异常进行处理。 特别地，若 blockHandler 和 fallback 都进行了配置，则被限流降级而抛出 BlockException 时只会进入 blockHandler 处理逻辑。若未配置 blockHandler、fallback 和 defaultFallback，则被限流降级时会将 BlockException 直接抛出 @SentinelResource逻辑分析源码分析1234567891011121314151617181920212223242526272829303132333435363738394041424344@Around(\"sentinelResourceAnnotationPointcut()\")public Object invokeResourceWithSentinel(ProceedingJoinPoint pjp) throws Throwable { //标有注解(@SentinelResource)的目标原始方法 Method originMethod = resolveMethod(pjp); //获取注解对象(@SentinelResource) SentinelResource annotation = originMethod.getAnnotation(SentinelResource.class); if (annotation == null) { throw new IllegalStateException(\"Wrong state for SentinelResource annotation\"); } //资源名称 String resourceName = getResourceName(annotation.value(), originMethod); EntryType entryType = annotation.entryType(); Entry entry = null; try { //sentinel 逻辑代码 entry = SphU.entry(resourceName, entryType, 1, pjp.getArgs()); //执行目标方法 Object result = pjp.proceed(); return result; } catch (BlockException ex) { // 处理BlockException return handleBlockException(pjp, annotation, ex); } catch (Throwable ex) { // 处理非BlockException // 获取忽略处理的异常 Class&lt;? extends Throwable&gt;[] exceptionsToIgnore = annotation.exceptionsToIgnore(); //判断当前异常是否在 忽略异常列表中，如果存在，则直接抛出 if (exceptionsToIgnore.length &gt; 0 &amp;&amp; exceptionBelongsTo(ex, exceptionsToIgnore)) { throw ex; } //如果当前异常在exceptionsToTrace属性中定义了，就进行处理 if (exceptionBelongsTo(ex, annotation.exceptionsToTrace())) { traceException(ex); return handleFallback(pjp, annotation, ex); } //前面的条件都不符合，则直接抛出异常 throw ex; } finally { if (entry != null) { entry.exit(1, pjp.getArgs()); } }} 我们主要看 catch 中的handleBlockException() 方法。 第一步：执行 blockHandler所配置的方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118protected Object handleBlockException(ProceedingJoinPoint pjp, SentinelResource annotation, BlockException ex) throws Throwable { //第一步：处理blockHandler方法。 // 如果配置了blockHandler 处理函数，则进行执行处理，获取blockHandler处理方法 Method blockHandlerMethod = extractBlockHandlerMethod(pjp, annotation.blockHandler(), annotation.blockHandlerClass()); //存在blockHandlerMethod的方法 if (blockHandlerMethod != null) { //获取目标方法的参数 Object[] originArgs = pjp.getArgs(); // 构建参数 Object[] args = Arrays.copyOf(originArgs, originArgs.length + 1); args[args.length - 1] = ex; try { //静态方法 if (isStatic(blockHandlerMethod)) { //反射调用方法，静态方法不需要传入obj return blockHandlerMethod.invoke(null, args); } //非静态方法。 return blockHandlerMethod.invoke(pjp.getTarget(), args); } catch (InvocationTargetException e) { // throw the actual exception throw e.getTargetException(); } } //如果没有配置blockHandler 异常处理函数。则执行fallback //第二步执行fallback 处理函数 return handleFallback(pjp, annotation, ex);}//========================进入extractBlockHandlerMethod方法======================== /** * name:异常处理函数名，locationClass：异常处理函数所在类，如果没有配置，则说明不是静态方法 */ //注意：这里可以看到，如果使用blockHandler函数，则先处理普通的，其次在去处理静态的。 private Method extractBlockHandlerMethod(ProceedingJoinPoint pjp, String name, Class&lt;?&gt;[] locationClass) { if (StringUtil.isBlank(name)) { return null; } // locationClass 如果配置了类，说明异常处理方法是静态方法。 boolean mustStatic = locationClass != null &amp;&amp; locationClass.length &gt;= 1; Class&lt;?&gt; clazz; //是不是配置了方法所在的类 if (mustStatic) { //如果传入了blockHandlerClass，则取第一个class clazz = locationClass[0]; } else { // 如果为空，就取当前类 clazz = pjp.getTarget().getClass(); } //从缓存中取MethodWrapper MethodWrapper m = ResourceMetadataRegistry.lookupBlockHandler(clazz, name); //缓存中没有 if (m == null) { // name是异常处理方法的名称，clazz是方法所在的类，mustStatic 是 是否为静态方法 // 获取 异常处理方法在当前类(及所有父类)的异常处理方法 Method method = resolveBlockHandlerInternal(pjp, name, clazz, mustStatic); //缓存当前方法的MethodWrapper实例 ResourceMetadataRegistry.updateBlockHandlerFor(clazz, name, method); return method; } if (!m.isPresent()) { return null; } //从缓存中取 return m.getMethod();} //===============进入resolveBlockHandlerInternal()方法================================//name: 异常处理方法；class：异常处理方法所在的类，mustStatic是否为静态方法//注意：通过这个方法可以看到：blockHandler异常处理函数的参数列表是在原方法的基础上，在末尾添加一个// BlockException类型的形参private Method resolveBlockHandlerInternal(ProceedingJoinPoint pjp, /*@NonNull*/ String name, Class&lt;?&gt; clazz,boolean mustStatic) { //获取目标方法的Method对象 Method originMethod = resolveMethod(pjp); //获取方法参数数组 Class&lt;?&gt;[] originList = originMethod.getParameterTypes(); //获取异常处理方法的参数列表 Class&lt;?&gt;[] parameterTypes = Arrays.copyOf(originList, originList.length + 1); //添加了一个新的参数，所以，我们定义降级的方法时，在末尾需要添加一个BlockException。 parameterTypes[parameterTypes.length - 1] = BlockException.class; //查找处理异常方法的Method对象（handleException） return findMethod(mustStatic, clazz, name, originMethod.getReturnType(), parameterTypes);}//=================进入findMethod()方法==========================//注意：这里可以发现，如果使用的是非静态的方法的处理方式，如果本类没有对应的异常处理函数，会递归追溯到父类，// 父类的父类....../*递归查询方法对象*/private Method findMethod(boolean mustStatic, Class&lt;?&gt; clazz, String name, Class&lt;?&gt; returnType, Class&lt;?&gt;... parameterTypes) { //获取当前类对象的所有方法对象 Method[] methods = clazz.getDeclaredMethods(); for (Method method : methods) { if (name.equals(method.getName()) &amp;&amp; checkStatic(mustStatic, method) &amp;&amp; returnType.isAssignableFrom(method.getReturnType()) &amp;&amp; Arrays.equals(parameterTypes, method.getParameterTypes())) { RecordLog.info(\"Resolved method [{0}] in class [{1}]\", name, clazz.getCanonicalName()); return method; } } // 本类没有，则向它的父类查找 Class&lt;?&gt; superClass = clazz.getSuperclass(); if (superClass != null &amp;&amp; !Object.class.equals(superClass)) { return findMethod(mustStatic, superClass, name, returnType, parameterTypes); } else { String methodType = mustStatic ? \" static\" : \"\"; RecordLog.warn(\"Cannot find{0} method [{1}] in class [{2}] with parameters {3}\", methodType, name, clazz.getCanonicalName(), Arrays.toString(parameterTypes)); return null; }} 第二步：执行fallback所配置的方法，进入handleFallback()方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293protected Object handleFallback(ProceedingJoinPoint pjp, SentinelResource annotation, Throwable ex) throws Throwable { return handleFallback(pjp, annotation.fallback(), annotation.defaultFallback(), annotation.fallbackClass(), ex);}protected Object handleFallback(ProceedingJoinPoint pjp, String fallback, String defaultFallback, Class&lt;?&gt;[] fallbackClass, Throwable ex) throws Throwable { //目标方法的参数数组 Object[] originArgs = pjp.getArgs(); // 如果配置了fallback处理函数，则执行 Method fallbackMethod = extractFallbackMethod(pjp, fallback, fallbackClass); if (fallbackMethod != null) { // 构造参数列表 int paramCount = fallbackMethod.getParameterTypes().length; Object[] args; if (paramCount == originArgs.length) { args = originArgs; } else { args = Arrays.copyOf(originArgs, originArgs.length + 1); args[args.length - 1] = ex; } try { if (isStatic(fallbackMethod)) { //静态方法调用 return fallbackMethod.invoke(null, args); } //普通方法调用 return fallbackMethod.invoke(pjp.getTarget(), args); } catch (InvocationTargetException e) { // throw the actual exception throw e.getTargetException(); } } // If fallback is absent, we'll try the defaultFallback if provided. // 如果fallback 方法没有，则执行默认的fallback方法 //第三步处理默认的fallback配置的函数 return handleDefaultFallback(pjp, defaultFallback, fallbackClass, ex);}//==================进入extractFallbackMethod()方法==================private Method extractFallbackMethod(ProceedingJoinPoint pjp, String fallbackName, Class&lt;?&gt;[] locationClass) { if (StringUtil.isBlank(fallbackName)) { return null; } //判断配置为静态方法 boolean mustStatic = locationClass != null &amp;&amp; locationClass.length &gt;= 1; //同样，如果是配置为静态的，直接取，如果不是，则使用目标方法所在类 Class&lt;?&gt; clazz = mustStatic ? locationClass[0] : pjp.getTarget().getClass(); //从缓存中取 MethodWrapper m = ResourceMetadataRegistry.lookupFallback(clazz, fallbackName); if (m == null) { // 获取fallback方法的Method对象 Method method = resolveFallbackInternal(pjp, fallbackName, clazz, mustStatic); // 加入到缓存中 ResourceMetadataRegistry.updateFallbackFor(clazz, fallbackName, method); return method; } if (!m.isPresent()) { return null; } return m.getMethod();}//===========进入resolveFallbackInternal()方法中=================private Method resolveFallbackInternal(ProceedingJoinPoint pjp, /*@NonNull*/ String name, Class&lt;?&gt; clazz,boolean mustStatic) { //获取原方法（目标增强方法） Method originMethod = resolveMethod(pjp); // Fallback function allows two kinds of parameter list. // Fallback函数是支持两种类型的参数列表的，这里不像BlockHandler函数 // 第一种：与原参数列表一直；第二种：在原参数列表的最后添加一个Throwable类型 Class&lt;?&gt;[] defaultParamTypes = originMethod.getParameterTypes(); Class&lt;?&gt;[] paramTypesWithException = Arrays.copyOf(defaultParamTypes, defaultParamTypes.length + 1); paramTypesWithException[paramTypesWithException.length - 1] = Throwable.class; // We first find the fallback matching the signature of origin method. // 先查找第一个参数列表的方法 Method method = findMethod(mustStatic, clazz, name, originMethod.getReturnType(), defaultParamTypes); // If fallback matching the origin method is absent, we then try to find the other one. if (method == null) { // 如果第一种没有找到，则查询第二个加了异常类型的方法列表的方法 method = findMethod(mustStatic, clazz, name, originMethod.getReturnType(), paramTypesWithException); } return method;} 第三步：执行defaultFallback属性配置的函数,进入handleDefaultFallback()方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465protected Object handleDefaultFallback(ProceedingJoinPoint pjp, String defaultFallback, Class&lt;?&gt;[] fallbackClass, Throwable ex) throws Throwable { // 如果配置了默认的fallback方法，如果配置了的话 Method fallbackMethod = extractDefaultFallbackMethod(pjp, defaultFallback, fallbackClass); if (fallbackMethod != null) { // 构造参数 Object[] args = fallbackMethod.getParameterTypes().length == 0 ? new Object[0] : new Object[] {ex}; try { if (isStatic(fallbackMethod)) { //静态方法调用 return fallbackMethod.invoke(null, args); } //普通方法调用 return fallbackMethod.invoke(pjp.getTarget(), args); } catch (InvocationTargetException e) { // 抛出实际异常 throw e.getTargetException(); } } // 如果没有配置任何的fallback函数（fallback函数和默认的fallback函数，则直接抛出异常 BlockException） throw ex;}//====================进入extractDefaultFallbackMethod()方法====================private Method extractDefaultFallbackMethod(ProceedingJoinPoint pjp, String defaultFallback, Class&lt;?&gt;[] locationClass) { if (StringUtil.isBlank(defaultFallback)) { return null; } //判断配置的是否是其他类的静态方法 boolean mustStatic = locationClass != null &amp;&amp; locationClass.length &gt;= 1; //获取方法所在的类名 Class&lt;?&gt; clazz = mustStatic ? locationClass[0] : pjp.getTarget().getClass(); //查询缓存 MethodWrapper m = ResourceMetadataRegistry.lookupDefaultFallback(clazz, defaultFallback); if (m == null) { Class&lt;?&gt; originReturnType = resolveMethod(pjp).getReturnType(); // Default fallback allows two kinds of parameter list. // 默认的fallback方法支持两种参数列表 // One is empty parameter list. // 第一种是空参数 Class&lt;?&gt;[] defaultParamTypes = new Class&lt;?&gt;[0]; // The other is a single parameter {@link Throwable} to get relevant exception info. // 第二种是只有一个Throwable类型的参数 Class&lt;?&gt;[] paramTypeWithException = new Class&lt;?&gt;[] {Throwable.class}; // We first find the default fallback with empty parameter list. // 先查找空参数 Method method = findMethod(mustStatic, clazz, defaultFallback, originReturnType, defaultParamTypes); // If default fallback with empty params is absent, we then try to find the other one. if (method == null) { // 再查询有参数的方法 method = findMethod(mustStatic, clazz, defaultFallback, originReturnType, paramTypeWithException); } // 缓存方法 ResourceMetadataRegistry.updateDefaultFallbackFor(clazz, defaultFallback, method); return method; } if (!m.isPresent()) { return null; } return m.getMethod();} 如果把上面的代码过一遍的话，前面文档中总结的要点基本都理解了。 执行方法顺序: blockHandler –&gt; fallback –&gt; defaultFallback 处理BlockException属性方法形参： blockHandler:在原方法的形参列表基础上，需要在最后添加一个BlockException 类型的参数。 123456//获取方法参数数组Class&lt;?&gt;[] originList = originMethod.getParameterTypes();//获取异常处理方法的参数列表Class&lt;?&gt;[] parameterTypes = Arrays.copyOf(originList, originList.length + 1);//添加了一个新的参数，所以，我们定义降级的方法时，在末尾需要添加一个BlockException。parameterTypes[parameterTypes.length - 1] = BlockException.class; fallback:有两种：1:方法参数列表与原方法参数列表一致，2：在原方法列表后添加一个Throwable 类型的参数 123456// Fallback函数是支持两种类型的参数列表的，这里不像BlockHandler函数// 第一种：与原参数列表一致；第二种：在原参数列表的最后添加一个Throwable类型Class&lt;?&gt;[] defaultParamTypes = originMethod.getParameterTypes();Class&lt;?&gt;[] paramTypesWithException = Arrays.copyOf(defaultParamTypes, defaultParamTypes.length + 1);paramTypesWithException[paramTypesWithException.length - 1] = Throwable.class; defaultFallback:有两种，1：方法参数列表为空，2：仅有一个Thowable的参数列表 12345678// Default fallback allows two kinds of parameter list.// 默认的fallback方法支持两种参数列表// One is empty parameter list.// 第一种是空参数Class&lt;?&gt;[] defaultParamTypes = new Class&lt;?&gt;[0];// The other is a single parameter {@link Throwable} to get relevant exception info.// 第二种是只有一个Throwable类型的参数Class&lt;?&gt;[] paramTypeWithException = new Class&lt;?&gt;[] {Throwable.class}; 处理非BlockException如果配置了在忽略异常列表中，则直接抛出原始异常，否则使用exceptionToTrace 配置进行处理，如果没有配置，则直接抛出原始异常。 1234567891011121314// 处理非BlockException// 获取忽略处理的异常Class&lt;? extends Throwable&gt;[] exceptionsToIgnore = annotation.exceptionsToIgnore();//判断当前异常是否在 忽略异常列表中，如果存在，则直接抛出if (exceptionsToIgnore.length &gt; 0 &amp;&amp; exceptionBelongsTo(ex, exceptionsToIgnore)) { throw ex;}//如果当前异常在exceptionsToTrace属性中定义了，就进行fallback和defaultFallback处理if (exceptionBelongsTo(ex, annotation.exceptionsToTrace())) { traceException(ex); return handleFallback(pjp, annotation, ex);}//前面的条件都不符合，则直接抛出异常throw ex; annotation.exceptionsToTrace() 默认是Throwable.class类型的,所以，理论上fallback是可以处理任何异常，排序在忽略异常列表中的异常。 这一节通过阅读源码的方式来学习sentinel的注解支持，后面我们看一下sentinel的几种控制规则。","link":"/2020/01/18/SSM/springcloudalibaba/14.sentinel%E6%B3%A8%E8%A7%A3%E6%94%AF%E6%8C%81%E8%AF%A6%E8%BF%B0/"},{"title":"二十四、GatewayFilter 工厂","text":"路由过滤器GatewayFilter允许修改进来的HTTP请求内容或者返回的HTTP响应内容。路由过滤器的作用域是一个具体的路由配置。 Spring Cloud Gateway提供了丰富的内建的GatewayFilter工厂，可以按需选用 。 图 from： https://blog.csdn.net/forezp/article/details/85057268 过滤器的声明周期： Gateway Filters 注意：接收端默认9999的服务中。 1. AddRequestHeaderAddRequestHeader GatewayFilter 工厂采用 name 和 value 参数。 12345678910spring: cloud: gateway: routes: - id: gateway-filter uri: http://localhost:9999 predicates: - Path=/addRequestHeader filters: - AddRequestHeader= X-Request-username,admin 9999端口接收端： 12345@GetMapping(value = \"/addRequestHeader\")public String addRequestHeader(@RequestHeader(\"X-Request-username\") String username){ System.out.println(\"X-Request-username:\"+username); return \"addRequestHeader SUCCESS\";} 说明：使用@RequestHeader注解读取HTTP Header中的数据。 当然，我们也可以使用路径变量的形式来动态传递参数。 12345678910spring: cloud: gateway: routes: - id: add_request_header_route uri: http://localhost:9999 predicates: - Path=/addRequestHeader/{username} filters: - AddRequestHeader= X-Request-username,u-{username} 接收端： 12345@GetMapping(value = \"/addRequestHeader/{str}\")public String addRequestHeader(@RequestHeader(\"X-Request-username\") String username){ System.out.println(\"X-Request-username:\"+username); return \"addRequestHeader SUCCESS\";} 2. AddRequestParameterAddRequestParameter GatewayFilter Factory同样是采用 name 和 value . 12345678910spring: cloud: gateway: routes: - id: add_request_parameter_route uri: http://localhost:9999 predicates: - Path=/addRequestParameter filters: - AddRequestParameter= name,zhangsan 接收端： 12345@GetMapping(value = \"/addRequestParameter\")public String addRequestParameter(@RequestParam(\"name\") String name){ System.out.println(\"name:\"+name); return \"addRequestParameter SUCCESS\";} 说明： 我们使用addRequestParamter filter来将参数信息添加到所有匹配请求的下游请求的请求参数中。同样也可以使用路径参数来动态传递,如下： 12345678910spring: cloud: gateway: routes: - id: add_request_parameter_route uri: http://localhost:9999 predicates: - Host= {str}.ouyanghao.com filters: - AddRequestParameter= name,{str} 这里记录一个异常信息： 12reactor.core.Exceptions$ErrorCallbackNotImplemented: java.lang.IllegalArgumentException: Unable to find GatewayFilterFactory with name AddResponseHeader Caused by: java.lang.IllegalArgumentException: Unable to find GatewayFilterFactory with name AddResponseHeader 这个问题我之前以为是导包的问题，结果一顿操作之后，发现在配置过滤器的时候，不能中间加空格，即： 12345filters: - AddResponseHeader = name,lisi# 上面的写法是错误的，不能在等号之前加空格filters: - AddResponseHeader= name,lisi 3. AddResponseHeaderAddResponseHeader Filter Factory同样是采用两个参数 key (name)和 value 形式。 12345678910spring: cloud: gateway: routes: - id: add_response_header_route uri: http://localhost:9999 predicates: - Path=/addResponseHeader filters: - AddResponseHeader= name,lisi 说明： 这样会将name=list 头信息，添加到所有匹配请求的下游响应头中去。同样也可以使用路径参数来动态传递/user/{str}. 4. DedupeResponseHeaderDedupeResponseHeader Filter Factory 采用两个参数，一个是name,一个是策略，中间使用空格隔开，我们看一下源码上的注释： 12345678910111213141516171819202122232425262728293031323334353637383940414243/*Use case: Both your legacy backend and your API gateway add CORS header values. So, your consumer ends up with Access-Control-Allow-Credentials: true, true Access-Control-Allow-Origin: https://musk.mars, https://musk.mars(The one from the gateway will be the first of the two.) To fix, add DedupeResponseHeader=Access-Control-Allow-Credentials Access-Control-Allow-Origin用例：后端程序以及API网关都会往响应头中添加 CORS的头信息，所以，最终的消费者得到的就是具有重复值的，如上所述，所以此时我们需要将重复值去除。Configuration parameters:- name String representing response header names, space separated. Required.- strategy RETAIN_FIRST - Default. Retain the first value only. RETAIN_LAST - Retain the last value only. RETAIN_UNIQUE - Retain all unique values in the order of their first encounter.配置： 名字：响应头的名字，中间添加一个必须的空格。 策略：1.保留第一个，2.保留最后一个，3.保留所有唯一值，以它们第一次出现的顺序保留。Example 1 default-filters: - DedupeResponseHeader=Access-Control-Allow-CredentialsResponse header Access-Control-Allow-Credentials: true, falseModified response header Access-Control-Allow-Credentials: trueExample 2 default-filters: - DedupeResponseHeader=Access-Control-Allow-Credentials, RETAIN_LASTResponse header Access-Control-Allow-Credentials: true, falseModified response header Access-Control-Allow-Credentials: falseExample 3 default-filters: - DedupeResponseHeader=Access-Control-Allow-Credentials, RETAIN_UNIQUEResponse header Access-Control-Allow-Credentials: true, trueModified response header Access-Control-Allow-Credentials: true */public class DedupeResponseHeaderGatewayFilterFactory extends AbstractGatewayFilterFactory&lt;DedupeResponseHeaderGatewayFilterFactory.Config&gt; {} 上面的注释已经解释了问题。 12345678910spring: cloud: gateway: routes: - id: dedupe_response_header_route uri: http://localhost:9999 predicates: - Path=/dedupeResponseHeader filters: - DedupeResponseHeader= Access-Control-Allow-Credentials Access-Control-Allow-Origin, RETAIN_FIRST 剔除重复的响应头信息。 5. HystrixHystrix 是 netflix下的熔断组件，由于已经停止维护，并且这里主要是使用SpringCloudAlibaba系列，使用的是Sentinel，所以这里不详述，就简单把官方示例放在这，后面用来再回来看。 Hystrix是Netflix的一个库，用于实现断路器模式。Hystrix GatewayFilter允许您将断路器引入网关路由，保护您的服务免受级联故障的影响，并允许您在下游故障的情况下提供后备响应。 12345678spring: cloud: gateway: routes: - id: hystrix_route uri: https://example.org filters: - Hystrix=myCommandName 6. FallbackHeaders 该FallbackHeaders工厂可以让你在转发到请求的头部添加Hystrix执行异常的详细信息fallbackUri在以下情况下在外部应用程序，如： 123456789101112131415161718192021spring: cloud: gateway: routes: - id: ingredients uri: lb://ingredients predicates: - Path=//ingredients/** filters: - name: Hystrix args: name: fetchIngredients fallbackUri: forward:/fallback - id: ingredients-fallback uri: http://localhost:9994 predicates: - Path=/fallback filters: - name: FallbackHeaders args: executionExceptionTypeHeaderName: Test-Header 7. MapRequestHeaderMapRequestHeader GatewayFilter 工厂采用两个参数：fromHeader 和 toHeader. 12345678910spring: cloud: gateway: routes: - id: map_request_header_route uri: http://localhost:9999 predicates: - Path=/mapRequestHeader filters: - MapRequestHeader= password, X-Request-username 说明： fromHeader 和 toHeader 在上例中分别为 password 和 X-Request-username . 接收端： 1234567@GetMapping(value = \"/mapRequestHeader\")public String mapRequestHeader( @RequestHeader(value = \"password\", required = false) String password, @RequestHeader(value = \"X-Request-username\", required = false) String username){ System.out.println(\"username:\"+username + \" | password:\"+password); return \"mapRequestHeader Success\";} 我们下面来测试一下： 后台结果如下： 1username:admin,123456 | password:123456 可以看出，password 将值注入到了 X-Request-username . 即将请求的头信息添加到后续的下游请求中。 8. PrefixPathPrefixPath GatewayFilter工厂采用单个prefix参数。 12345678910spring: cloud: gateway: routes: - id: prefix_path_route uri: http://localhost:9999 Predicates: Method= GET filters: - PrefixPath=/user 我们通过下面的命令可以将请求转发到 http://localhost:9999/user/name 1curl localhost:8080/name 接收端： 1234@GetMapping(value = \"/user/name\")public String useName(){ return \"prefixPath success\";} 9. PreserveHostHeader我们从字面意思可以知道:保护Host Header，其实就是保护请求头中的Host字段。PreserveHostHeader 不需要参数。此过滤器将检查该请求属性，以确定是否应发送原始主机头，而不是由HTTP客户端确定的主机头。 如下： 12345678910spring: cloud: gateway: routes: - id: prefix_path_route uri: http://localhost:9999 Predicates: Method= GET filters: - PreserveHostHeader 接收端： 123456@GetMapping(value = \"/preserveHostHeader\")public String preserveHostHeader(@RequestHeader(value = \"Host\", required = false) String host){ System.out.println(\"host:\"+host); return \"preserveHostHeader success\";} 在浏览器地址栏输入：http://localhost:8080/preserveHostHeader,接收端显示结果： 12host:localhost:8080,localhost:8080//会把Host存到请求头中 10. RequestRateLimiterRequestRateLimiter:请求速率限制器。RequestRateLimiter GatewayFilter 工厂是一个RateLimiter 的实现类，用它去决定当前请求是否允许继续执行。如果不允许继续执行，默认会返回一个 HTTP 429 - Too Many Requests （太多连接状态）。 这个filter采用 一个可选的keyResolver 参数 和 指定的速率限制器参数。 keyResolver 是一个实现了KeyResolver接口的实现类的bean。在配置中，使用SpEL按名称引用bean. #{@myKeyResolver} 是SpEL表达式，它引用名称为myKeyResolver的bean。 KeyResolver.java 源码： 123public interface KeyResolver { Mono&lt;String&gt; resolve(ServerWebExchange exchange);} KeyResolver接口允许一个可拔插策略去驱动如何限制请求。 有一个默认实现： 123456789public class PrincipalNameKeyResolver implements KeyResolver { public static final String BEAN_NAME = \"principalNameKeyResolver\"; @Override public Mono&lt;String&gt; resolve(ServerWebExchange exchange) { return exchange.getPrincipal().map(Principal::getName) .switchIfEmpty(Mono.empty()); }} 从上面的代码可以看出：默认的keyResolver 的实现是从 ServerWebExchange 取得Principal 并且回调Principal.getName() 方法。 默认情况下，如果 KeyResolver 没有找到一个key，那么请求将会被拒绝。当然，可以通过 spring.cloud.gateway.filter.request-rate-limiter.deny-empty-key (true or false) 以及 spring.cloud.gateway.filter.request-rate-limiter.empty-key-status-code 属性来设置。 10.1 Redis RateLimiterredis 实现基于Stripe所做的工作。需要导入相关依赖,注意版本要求，参考spring官网。 https://spring.io/projects/spring-cloud 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis-reactive&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--监控依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 配置类： 123456789101112131415161718192021222324@Configurationpublic class GatewayConfiguration { //根据请求路径限流 getPath @Bean public KeyResolver keyResolver(){ return new KeyResolver() { @Override public Mono&lt;String&gt; resolve(ServerWebExchange exchange) { return Mono.just(exchange.getRequest().getPath().toString()); } }; } // 基于请求参数的限流 @Bean public KeyResolver userKeyResolver(){ return exchange -&gt; Mono.just( exchange.getRequest().getQueryParams().getFirst(\"userId\") ); } } 上面的例子是获取到官网的，就是在请求中获取一个叫user的请求参数，用于统计。 SpringCloud Gateway的限流方式是基于令牌桶算法的，使用Redis来存储Key。 配置信息： 123456789101112131415161718spring: cloud: gateway: routes: - id: request_hrate_limiter uri: http://localhost:9999 Predicates: Method= GET filters: # 使用限流过滤器 - name: RequestRateLimiter args: key-resolver: \"#{@userKeyResolver}\" redis-rate-limiter.replenishRate: 2 redis-rate-limiter.burstCapacity: 2 redis: host: 127.0.0.1 port: 6379 说明： redis-rate-limiter.replenishRate : 向令牌桶中填充的速率(一秒放多少个令牌) redis-rate-limiter.burstCapacity : 允许用户在一秒内执行的最大请求数。将此值设置为0，将阻止所有请求。（令牌桶的容量） 为实现一个稳定的速率，通常将上述两个属性设置成相同的值，将burstCapacity 设置大于 replenishRate 可以允许临时暴发。在这种情况下，需要在突发之间允许速率限制器一段时间(根据replenishRate )，因为连续两次突发可能导致请求被丢弃(HTTP 429 - Too Many Requests) 上面的userKeyResolver 是一个简单的获取用户请求参数（注意：不建议用在生产） 速率限制器也可以定义为实现了 RateLimiter 接口的bean。在配置中，使用SpEL按名称引用bean。#{@myRateLimiter} 是SpEL表达式，它引用名称为myRateLimiter的bean。 1234567891011spring: cloud: gateway: routes: - id: requestratelimiter_route uri: https://example.org filters: - name: RequestRateLimiter args: rate-limiter: \"#{@myRateLimiter}\" key-resolver: \"#{@userKeyResolver}\" 11. RedirectToRedirectTo:重定向到。RedirectTo GatewayFilter工厂采用两个参数：status 和 url。这个状态码需要是一个300系列的重定向的HTTP状态码。例如：301. url应该是一个有效的地址，将设置为头部的Location的值。 application.yaml 12345678910spring: cloud: gateway: routes: - id: request_hrate_limiter uri: http://localhost:9999 Predicates: Method= GET filters: - RedirectTo= 302, http://www.163.com 上面配置，当我们访问http://localhost:8080/redirectTo 路径时，并不会映射到http://localhost:9999/redirectTo.而是被转发到了http://www.163.com. 12. RemoveHopByHopHeadersFIlterRemoveHopByHopHeadersFilter GatewayFilter工厂从转发的请求中删除header，被删除的header列表来自IETF。 默认删除的header是： Connection Keep-Alive Proxy-Authenticate Proxy-Authorization TE Trailer Transfer-Encoding Upgrade 如果希望去修改它，可以通过设置spring.cloud.gateway.filter.remove-non-proxy-headers.headers属性来移除header列表。 13. RemoveRequestHeaderRemoveRequestHeader GatewayFilter 工厂采用一个参数：name. 请求头中的指定名字的值将被移除。 application.yaml 12345678910spring: cloud: gateway: routes: - id: remove_request_header uri: http://localhost:9999 Predicates: Method= GET filters: - RemoveRequestHeader=username 接收端： 123456@GetMapping(value = \"/removeRequestHeader\")public String removeRequestHeader( @RequestHeader(value = \"username\", required = false) String username){ System.out.println(\"username:\"+username); return \"removeRequestHeader success\";} 测试： 请求是携带了username 参数，下面是接收端打印的结果： 1username:null 14. RemoveResponseHeader见名知意，在返回客户端之前，删除指定响应头的数据。RemoveResponseHeader GatewayFilter 工厂采用一个参数：name . 12345678910spring: cloud: gateway: routes: - id: remove_response_header uri: http://localhost:9999 Predicates: Method= GET filters: - RemoveResponseHeader=Content-Type 上面的配置可以从响应头中删除 Content-Type 头信息，然后将其返回到客户端。 要删除任何类型的敏感信息，你可以需要配置这个filter在你需要的任何路由上，当然，我们可以在配置文件中配置spring.cloud.gateway.default-filters, 那么可以引用在所有的路由上。 15. RemoveRequestParameterRemoveRequestParameter GatewayFilter 工厂采用一个参数：name . 指定请求参数将会被删除。 这个是新版本2.2.0.RC1中新加的. 12345678910spring: cloud: gateway: routes: - id: remove_response_parameter uri: http://localhost:9999 Predicates: Method= GET filters: - RemoveRequestParameter=username 以上代码可以从请求参数中删除指定参数，在进行路由。 16. RewritePathRewritePath Gateway采用路径 正常表达式和替换参数。使用正则表达式可以灵活地重写请求路径。 application.yaml 12345678910spring: cloud: gateway: routes: - id: remove_response_parameter uri: http://localhost:9999 Predicates: Method= GET filters: - RewritePath=/user/(?&lt;str&gt;.*), /$\\{str} 根据上面的配置，使用路径http://localhost:8080/user/rewritePath 会被映射到 http://localhost:9999/rewritePath. 注意: 由于YAML规范，$\\替换为$ 17. RewriteLocationResponseHeaderRewriteLocationResponseHeader GatewayFilter 工厂 用来重写 响应头的Location 的值，以摆脱后端特定的详细信息。这需要 stripVersionMode , locationHeaderName , hostValue 和 protocolsRegex 参数。 12345678spring: cloud: gateway: routes: - id: rewritelocationresponseheader_route uri: http://example.org filters: - RewriteLocationResponseHeader=AS_IN_REQUEST, Location, , 示例：对于请求api.example.com/some/object/name. Location 响应头的值object-service.prod.example.net/v2/some/object/id 将会被重写为api.example.com/some/object/id。 解释：由于hostValue 和 protocolsRegex 参数都没有提供，所以使用原请求的host，并且stripVersionMode 选择的是AS_IN_REQUEST , 所以在原请求路径不包含版本时，将版本剥离删除。 步骤： api.example.com/some/object/name api.example.com/v2/some/object/id api.example.com/some/object/id 参数stripVersionMode 具有以下可选值：NEVER_STRIP , AS_IN_REQUEST (默认) , ALWAYS_STRIP. NEVER_STRIP 即使原始请求路径不包含任何版本，也不会剥离版本。 AS_IN_REQUEST 仅当原始请求不包含版本时，版本才会被剥离。 ALWAYS_STRIP 即使原始请求路径包含版本，也会删除版本。 参数 hostValue (如果提供) 将用于替换 host:port 响应 Location 头的一部分。如果未提供，Host 则将作为请求头的值使用。 参数 protocolsRegex 必须是有效的正则表达式字符串，协议名称将与该regex 匹配。如果不匹配，过滤器将不执行任何操作。默认值为 http|https|ftp|ftps. 18. RewriteResponseHeaderRewriteResponseHeader GatewayFilter 工厂采用三个参数，分别为：name, regexp 和 replacement . 它使用Java正则表达式以灵活的方式来重写响应头的值。 12345678spring: cloud: gateway: routes: - id: rewriteresponseheader_route uri: https://example.org filters: - RewriteResponseHeader=X-Response-Foo, , password=[^&amp;]+, password=*** 对于响应头值 /42?user=ford&amp;password=omg!what&amp;flag=true , 在下游请求执行之后将被设置为 /42?user=ford&amp;password=***&amp;flag=true ，在YAML文件中，需要使用$\\ 来表示$. 19. SaveSessionSaveSession GatewayFilter 工厂在向下游转发调用之前会强制执行 WebSession::save 操作。 这在将Spring Session之类的东西与惰性数据存储一起使用时特别有用，并且需要确保在进行转发呼叫之前已保存会话状态。 application.yaml 12345678910spring: cloud: gateway: routes: - id: save_session uri: https://example.org predicates: - Path=/foo/** filters: - SaveSession 如果您将Spring Security与Spring Session 集成在一起，并且想要确保安全性详细信息已转发到远程进程，那么这一点至关重要。 20. SecureHeadersSecureHeaders GatewayFilter 工厂添加了许多头到响应中。 文档： https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.0.RC1/reference/html/#secureheaders-gatewayfilter-factory 下面内容摘抄自官网 添加了以下标头（以及默认值）： X-Xss-Protection:1; mode=block Strict-Transport-Security:max-age=631138519 X-Frame-Options:DENY X-Content-Type-Options:nosniff Referrer-Policy:no-referrer Content-Security-Policy:default-src 'self' https:; font-src 'self' https: data:; img-src 'self' https: data:; object-src 'none'; script-src https:; style-src 'self' https: 'unsafe-inline' X-Download-Options:noopen X-Permitted-Cross-Domain-Policies:none 要更改默认值，请在spring.cloud.gateway.filter.secure-headers名称空间中设置适当的属性： 要更改的属性： xss-protection-header strict-transport-security frame-options content-type-options referrer-policy content-security-policy download-options permitted-cross-domain-policies 要禁用默认值，请将该属性设置为spring.cloud.gateway.filter.secure-headers.disable逗号分隔的值。 例： 1spring.cloud.gateway.filter.secure-headers.disable=frame-options,download-options 21. SetPathSetPath GatewayFilter 采用路径template 参数。通过允许路径的模板片段，提供了一种操作请求路径的简单方法。这使用了Spring Framework 中的uri模板。允许多个匹配片段。 application.yaml 12345678910spring: cloud: gateway: routes: - id: remove_response_parameter uri: http://localhost:9999 Predicates: - Path= /set/{subUrl} filters: - SetPath= /{subUrl} 对于请求路径 /set/path ，路径会被设置为/path 然后在转发到下游请求。 22. SetRequestHeaderSetRequestHeader GatewayFilter 工厂采用 name 和 value 参数。 application.yaml 12345678910spring: cloud: gateway: routes: - id: set_request_header uri: http://localhost:9999 Predicates: - Method=GET filters: - SetRequestHeader= username,admin 以上设置，可以将请求头中的username 的原来值修改为admin. 接收端： 123456@GetMapping(value = \"/setRequestHeader\")public String setRequestHeader( @RequestHeader(value = \"username\", required = false) String username){ System.out.println(\"username:\"+username); return \"setRequestHeader success\";} postman测试： 测试结果： 1username:admin 上述测试可以看出，SetRequestHeader 和前面的AddRequestHeader 不同，这个是将原来的值替换为配置的值。 23. SetResponseHeaderSetResponseHeader GatewayFilter 工厂采用两个参数：name 和 value . application.yaml 12345678910spring: cloud: gateway: routes: - id: set_request_header uri: http://localhost:9999 Predicates: - Method=GET filters: - SetResponseHeader= X-Response-username,admin 这个过滤器主要是将 响应头中的 X-Response-username 替换为 admin .同样也可以使用路径参数动态传递。 24. SetStatusSetStatus GatewayFilter工厂采用一个参数：status , 这个参数必须是一个有效的Spring HttpStatus . 它可以是整数值 404 或是枚举的字符串表示形式NOT_FOUND. application.yaml 12345678910111213141516spring: cloud: gateway: routes: - id: set_status1 uri: http://localhost:9999 Predicates: - Method=GET filters: - SetStatus= NOT_FOUND - id: set_status2 uri: http://localhost:9999 Predicates: - Method=GET filters: - SetStatus= 404 无论上述情况的哪一种，响应的HTTP状态都讲设置为404. SetStatus GatewayFilter可以被 配置为响应头中从代理请求返回原始HTTP状态码，如果使用以下属性配置header，则会将其添加到响应头中： 12345spring: cloud: gateway: set-status: original-status-header-name: original-http-status 25. StripPrefixStripPrefix GatewayFilter工厂采用一个参数：part , 这个参数在请求转发到下游之前去除路径的前 part 部分。 12345678910spring: cloud: gateway: routes: - id: strip_prefix uri: http://localhost:9999 Predicates: - Method=GET filters: - StripPrefix= 2 根据以上配置，可以将/user/name/stripPrefix 地址 切除前面两段，所以最后转发到下游的地址是/stripPrefix. 26. RetryRetry GatewayFilter 工厂重试机制，参考官网： https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.0.RC1/reference/html/#retry-gatewayfilter-factory 27. RequestSize当请求大小高于允许的限制大小时，RequestSize GatewayFilter工厂将会阻止转发到下游服务。过滤器将RequestSize 参数作为请求的允许大小限制（以字节为单位） application.yaml 123456789101112spring: cloud: gateway: routes: - id: request_size_route uri: http://localhost:8080/upload predicates: - Path=/upload filters: - name: RequestSize args: maxSize: 5000000 当请求由于大小而被拒绝时，RequestSize GatewayFilter 工厂将响应状态设置为 403 Payload Too Large 并带有head名为errorMessage 的数据。如下： 1errorMessage: Request size is larger than permissible limit. Request size is 6.0 MB where permissible limit is 5.0MB 如果未在路由定义中作为过滤器参数提供，则默认请求大小设置为5MB。 28. Modify Request Body这个过滤器用于在将请求转发到下游服务之前，将请求体进行修改。 注意：只能通过java来配置此过滤器。 123456789101112131415161718192021222324252627@Beanpublic RouteLocator routes(RouteLocatorBuilder builder) { return builder.routes() .route(\"rewrite_request_obj\", r -&gt; r.host(\"*.rewriterequestobj.org\") .filters(f -&gt; f.prefixPath(\"/httpbin\") .modifyRequestBody(String.class, Hello.class, MediaType.APPLICATION_JSON_VALUE, (exchange, s) -&gt; return Mono.just(new Hello(s.toUpperCase())))).uri(uri)) .build();}static class Hello { String message; public Hello() { } public Hello(String message) { this.message = message; } public String getMessage() { return message; } public void setMessage(String message) { this.message = message; }} 29. Modify Response Body该过滤器在响应发送会客户端之前，对响应体进行修改。同样也只支持Java配置。 123456789@Beanpublic RouteLocator routes(RouteLocatorBuilder builder) { return builder.routes() .route(\"rewrite_response_upper\", r -&gt; r.host(\"*.rewriteresponseupper.org\") .filters(f -&gt; f.prefixPath(\"/httpbin\") .modifyResponseBody(String.class, String.class, (exchange, s) -&gt; Mono.just(s.toUpperCase()))).uri(uri) .build();} 30. Default Filter如果想添加一个过滤器去应用在所有的路由上，可以使用 spring.cloud.gateway.default-filters 来配置，这个属性接收一个Filter列表。 application.yaml 123456spring: cloud: gateway: default-filters: - AddResponseHeader=X-Response-Default-Foo, Default-Bar - PrefixPath=/httpbin 总结：这一节主要介绍SpringCloud Gateway中的过滤器。官方文档如下： https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.0.RC1/reference/html/#gatewayfilter-factories","link":"/2020/01/18/SSM/springcloudalibaba/22.gateway%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"title":"三、Mybatis映射文件","text":"Mybatis映射文件 基本CRUD增加1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;select id=\"saveRole\" resultType=\"role\"&gt; insert into tb_role ( &lt;trim suffixOverrides=\",\"&gt; &lt;if test=\"roleName!=null\"&gt; role_name, &lt;/if&gt; &lt;if test=\"description != null\"&gt; description, &lt;/if&gt; &lt;if test=\"status != null\"&gt; status, &lt;/if&gt; &lt;if test=\"createTime != null\"&gt; create_time, &lt;/if&gt; &lt;if test=\"createUser != null\"&gt; create_user, &lt;/if&gt; &lt;if test=\"modifyTime != null\"&gt; modify_time, &lt;/if&gt; &lt;if test=\"modifyUser != null\"&gt; modify_user &lt;/if&gt; &lt;/trim&gt; ) VALUES ( &lt;trim suffixOverrides=\",\"&gt; &lt;if test=\"roleName!=null\"&gt; #{roleName}, &lt;/if&gt; &lt;if test=\"description != null\"&gt; #{description}, &lt;/if&gt; &lt;if test=\"status != null\"&gt; #{status}, &lt;/if&gt; &lt;if test=\"createTime != null\"&gt; #{createTime}, &lt;/if&gt; &lt;if test=\"createUser != null\"&gt; #{createUser}, &lt;/if&gt; &lt;if test=\"modifyTime != null\"&gt; #{modifyTime}, &lt;/if&gt; &lt;if test=\"modifyUser != null\"&gt; #{modifyUser} &lt;/if&gt; &lt;/trim&gt; )&lt;/select&gt; 这个增加方法使用if 进行判断，所以只是将不为空的字段添加。 增加并返回ID123456789&lt;!--设置保存的时候需要返回插入时的id--&gt;&lt;insert id=\"saveUser\" useGeneratedKeys=\"true\" keyProperty=\"id\" parameterType=\"User\" &gt; insert into tb_user (user_id, username,password,email,phone,gender,birthday,create_time, create_user,modify_time,modify_user) values ( #{user.userId},#{user.username},#{user.password},#{user.email},#{user.phone},#{user.gender}, #{user.birthday},#{user.createTime},#{user.createUser},#{user.modifyTime},#{user.modifyUser})&lt;/insert&gt; 删除123&lt;delete id=\"deleteRoleById\"&gt; delete from tb_role where id = #{id}&lt;/delete&gt; 这是一个非常简单的删除语句，这里不赘述。 更新123456789101112131415161718192021222324252627&lt;update id=\"updateRole\"&gt; update tb_role &lt;set&gt; &lt;if test=\"roleName!=null\"&gt; role_name = #{roleName}, &lt;/if&gt; &lt;if test=\"description != null\"&gt; description = #{description}, &lt;/if&gt; &lt;if test=\"status != null\"&gt; status = #{status}, &lt;/if&gt; &lt;if test=\"createTime != null\"&gt; create_time = #{createTime}, &lt;/if&gt; &lt;if test=\"createUser != null\"&gt; create_user = #{createUser}, &lt;/if&gt; &lt;if test=\"modifyTime != null\"&gt; modify_time = #{modifyTime}, &lt;/if&gt; &lt;if test=\"modifyUser != null\"&gt; modify_user = #{modifyUser} &lt;/if&gt; &lt;/set&gt; where id = #{id}&lt;/update&gt; 提示：这里采用了选择性更新，即只有字段不为空的时候，才会进行更新操作。 查询123&lt;select id=\"selectRolesByStatus\" resultType=\"role\"&gt; select * from tb_role where status = #{status}&lt;/select&gt; 提示：这里仅仅介绍一下最简单的查询，后面重点介绍与查询相关的。 增删改查标签相关属性请参考： https://mybatis.org/mybatis-3/zh/sqlmap-xml.html#insert_update_and_delete 增删改查标签属性Select 元素的属性 属性 描述 id 在命名空间中唯一的标识符，可以被用来引用这条语句。 parameterType 将会传入这条语句的参数类的完全限定名或别名。这个属性是可选的，因为 MyBatis 可以通过类型处理器（TypeHandler） 推断出具体传入语句的参数，默认值为未设置（unset）。 resultType 从这条语句中返回的期望类型的类的完全限定名或别名。 注意如果返回的是集合，那应该设置为集合包含的类型，而不是集合本身。可以使用 resultType 或 resultMap，但不能同时使用。 resultMap 外部 resultMap 的命名引用。结果集的映射是 MyBatis 最强大的特性，如果你对其理解透彻，许多复杂映射的情形都能迎刃而解。可以使用 resultMap 或 resultType，但不能同时使用。 flushCache 将其设置为 true 后，只要语句被调用，都会导致本地缓存和二级缓存被清空，默认值：false。 useCache 将其设置为 true 后，将会导致本条语句的结果被二级缓存缓存起来，默认值：对 select 元素为 true。 timeout 这个设置是在抛出异常之前，驱动程序等待数据库返回请求结果的秒数。默认值为未设置（unset）（依赖驱动）。 fetchSize 这是一个给驱动的提示，尝试让驱动程序每次批量返回的结果行数和这个设置值相等。 默认值为未设置（unset）（依赖驱动）。 statementType STATEMENT，PREPARED 或 CALLABLE 中的一个。这会让 MyBatis 分别使用 Statement，PreparedStatement 或 CallableStatement，默认值：PREPARED。 resultSetType FORWARD_ONLY，SCROLL_SENSITIVE, SCROLL_INSENSITIVE 或 DEFAULT（等价于 unset） 中的一个，默认值为 unset （依赖驱动）。 databaseId 如果配置了数据库厂商标识（databaseIdProvider），MyBatis 会加载所有的不带 databaseId 或匹配当前 databaseId 的语句；如果带或者不带的语句都有，则不带的会被忽略。 resultOrdered 这个设置仅针对嵌套结果 select 语句适用：如果为 true，就是假设包含了嵌套结果集或是分组，这样的话当返回一个主结果行的时候，就不会发生有对前面结果集的引用的情况。 这就使得在获取嵌套的结果集的时候不至于导致内存不够用。默认值：false。 resultSets 这个设置仅对多结果集的情况适用。它将列出语句执行后返回的结果集并给每个结果集一个名称，名称是逗号分隔的。 Insert, Update, Delete 元素的属性 属性 描述 id 命名空间中的唯一标识符，可被用来代表这条语句。 parameterType 将要传入语句的参数的完全限定类名或别名。这个属性是可选的，因为 MyBatis 可以通过类型处理器推断出具体传入语句的参数，默认值为未设置（unset）。 parameterMap 这是引用外部 parameterMap 的已经被废弃的方法。请使用内联参数映射和 parameterType 属性。 flushCache 将其设置为 true 后，只要语句被调用，都会导致本地缓存和二级缓存被清空，默认值：true（对于 insert、update 和 delete 语句）。 timeout 这个设置是在抛出异常之前，驱动程序等待数据库返回请求结果的秒数。默认值为未设置（unset）（依赖驱动）。 statementType STATEMENT，PREPARED 或 CALLABLE 的一个。这会让 MyBatis 分别使用 Statement，PreparedStatement 或 CallableStatement，默认值：PREPARED。 useGeneratedKeys （仅对 insert 和 update 有用）这会令 MyBatis 使用 JDBC 的 getGeneratedKeys 方法来取出由数据库内部生成的主键（比如：像 MySQL 和 SQL Server 这样的关系数据库管理系统的自动递增字段），默认值：false。 keyProperty （仅对 insert 和 update 有用）唯一标记一个属性，MyBatis 会通过 getGeneratedKeys 的返回值或者通过 insert 语句的 selectKey 子元素设置它的键值，默认值：未设置（unset）。如果希望得到多个生成的列，也可以是逗号分隔的属性名称列表。 keyColumn （仅对 insert 和 update 有用）通过生成的键值设置表中的列名，这个设置仅在某些数据库（像 PostgreSQL）是必须的，当主键列不是表中的第一列的时候需要设置。如果希望使用多个生成的列，也可以设置为逗号分隔的属性名称列表。 databaseId 如果配置了数据库厂商标识（databaseIdProvider），MyBatis 会加载所有的不带 databaseId 或匹配当前 databaseId 的语句；如果带或者不带的语句都有，则不带的会被忽略。 结果映射结果映射（resultMap） constructor - 用于在实例化类时，注入结果到构造方法中idArg - ID 参数；标记出作为 ID 的结果可以帮助提高整体性能arg - 将被注入到构造方法的一个普通结果 id – 一个 ID 结果；标记出作为 ID 的结果可以帮助提高整体性能 result – 注入到字段或 JavaBean 属性的普通结果 association – 一个复杂类型的关联；许多结果将包装成这种类型嵌套结果映射 – 关联本身可以是一个 resultMap 元素，或者从别处引用一个 collection – 一个复杂类型的集合嵌套结果映射 – 集合本身可以是一个 resultMap 元素，或者从别处引用一个 discriminator – 使用结果值来决定使用哪个 resultMapcase – 基于某些值的结果映射嵌套结果映射 – case 本身可以是一个 resultMap 元素，因此可以具有相同的结构和元素，或者从别处引用一个 Id 和 Result 的属性 属性 描述 property 映射到列结果的字段或属性。如果用来匹配的 JavaBean 存在给定名字的属性，那么它将会被使用。否则 MyBatis 将会寻找给定名称的字段。 无论是哪一种情形，你都可以使用通常的点式分隔形式进行复杂属性导航。 比如，你可以这样映射一些简单的东西：“username”，或者映射到一些复杂的东西上：“address.street.number”。 column 数据库中的列名，或者是列的别名。一般情况下，这和传递给 resultSet.getString(columnName) 方法的参数一样。 javaType 一个 Java 类的完全限定名，或一个类型别名（关于内置的类型别名，可以参考上面的表格）。 如果你映射到一个 JavaBean，MyBatis 通常可以推断类型。然而，如果你映射到的是 HashMap，那么你应该明确地指定 javaType 来保证行为与期望的相一致。 jdbcType JDBC 类型，所支持的 JDBC 类型参见这个表格之后的“支持的 JDBC 类型”。 只需要在可能执行插入、更新和删除的且允许空值的列上指定 JDBC 类型。这是 JDBC 的要求而非 MyBatis 的要求。如果你直接面向 JDBC 编程，你需要对可能存在空值的列指定这个类型。 typeHandler 我们在前面讨论过默认的类型处理器。使用这个属性，你可以覆盖默认的类型处理器。 这个属性值是一个类型处理器实现类的完全限定名，或者是类型别名。 支持的 JDBC 类型为了以后可能的使用场景，MyBatis 通过内置的 jdbcType 枚举类型支持下面的 JDBC 类型。 BIT FLOAT CHAR TIMESTAMP OTHER UNDEFINED TINYINT REAL VARCHAR BINARY BLOB NVARCHAR SMALLINT DOUBLE LONGVARCHAR VARBINARY CLOB NCHAR INTEGER NUMERIC DATE LONGVARBINARY BOOLEAN NCLOB BIGINT DECIMAL TIME NULL CURSOR ARRAY 单表基本结果映射属性设值1234567891011121314&lt;resultMap id=\"base_map\" type=\"role\"&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\" /&gt; &lt;result column=\"role_name\" jdbcType=\"VARCHAR\" property=\"roleName\"/&gt; &lt;result column=\"description\" jdbcType=\"VARCHAR\" property=\"description\"/&gt; &lt;result column=\"status\" jdbcType=\"INTEGER\" property=\"status\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"create_user\" jdbcType=\"VARCHAR\" property=\"createUser\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;result column=\"modify_user\" jdbcType=\"VARCHAR\" property=\"modifyUser\"/&gt;&lt;/resultMap&gt;&lt;select id=\"selectAllRoles\" resultMap=\"base_map\"&gt; select * from tb_role&lt;/select&gt; java实体： 123456789101112//空参数，全参数，get，set，toStringpublic class Role implements Serializable { private Integer id; private String roleName; private String description; private Integer status; private Date createTime; private String createUser; private Date modifyTime; private String modifyUser;} 提示：可以看出，这里我们不再直接使用了user作为返回类型(resultType),而是使用了结果映射(resultMap)来映射实体。以上方式使用的实体映射是使用的setter进行设置参数的。我们在setId方法上加一段输入语句之后，再次运行，结果如下： 1234public void setId(Integer id) { System.out.println(\"setId of role is running\"); this.id = id;} 那么我们如何使用构造函数来进行属性设置赋值呢？ 123456789101112&lt;resultMap id=\"base_map\" type=\"role\"&gt; &lt;constructor&gt; &lt;idArg column=\"id\" javaType=\"Integer\"/&gt; &lt;arg column=\"role_name\" javaType=\"String\"/&gt; &lt;arg column=\"description\" javaType=\"String\"/&gt; &lt;arg column=\"status\" javaType=\"Integer\"/&gt; &lt;arg column=\"create_time\" javaType=\"Date\"/&gt; &lt;arg column=\"create_user\" javaType=\"String\"/&gt; &lt;arg column=\"modify_time\" javaType=\"Date\" /&gt; &lt;arg column=\"modify_user\" javaType=\"String\" /&gt; &lt;/constructor&gt;&lt;/resultMap&gt; 构造方法设值1234567891011public Role(Integer id, String roleName, String description, Integer status, Date createTime, String createUser, Date modifyTime, String modifyUser) { System.out.println(\"all args' constructor of role is running \"); this.id = id; this.roleName = roleName; this.description = description; this.status = status; this.createTime = createTime; this.createUser = createUser; this.modifyTime = modifyTime; this.modifyUser = modifyUser;} 测试结果： 关联关系一对一​ 前面我们看到了单表操作，我们通过直接返回对象或是使用resultMap的方式来映射实体。这里我们看一下实体一对一的关系如何映射。 123456789101112131415一对一关系的映射：association标签的属性元素property CDATA 属性，必须column CDATA 数据库表的字段名javaType CDATA 属性的java类型jdbcType CDATA 数据库表的字段的类型select CDATA 嵌套查询时使用。resultMap CDATA 关联外部的手动映射关系时使用typeHandler CDATA 类型处理器notNullColumn CDATA columnPrefix CDATA 字段前缀，一对一中有涉及到resultSet CDATA foreignColumn CDATA autoMapping (true|false) 是否自定映射fetchType (lazy|eager) 是否懒加载 业务：用户与身份证是一对一的关系。 User类： 12345678910111213141516171819202122@NoArgsConstructor@AllArgsConstructor@Getter@Setter@ToStringpublic class User implements Serializable { private Integer id; private String userId; private String username; private String password; private String email; private String phone; private Integer gender; private Date birthday; private Integer status; private Date createTime; private String createUser; private Date modifyTime; private String modifyUser; private Card card;} 提示：这里使用了lombok 简化实例开发，依赖如下: 12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.8&lt;/version&gt;&lt;/dependency&gt; Card类： 1234567891011121314@NoArgsConstructor@AllArgsConstructor@Getter@Setter@ToStringpublic class Card implements Serializable { private Integer id; private Integer uid; private String cardId; private String address; private Date createTime; private Date modifyTime;} 一对一自动映射​ 通过上面的实例类关系我们可以发现，card是User类中的一个属性，但是如何通过Mybatis的自动映射机制将card表中的数据之间填充到User属性中。我们可以在查询字段上使用别名来映射，如下，uid字段是user的card属性的属性，则可以通过card.uid 来映射到User类的card属性的uid字段。 123456789101112131415&lt;select id=\"findUserWithCardByUserId\" resultType=\"user\"&gt; SELECT a.id,a.user_id,a.username,a.password,a.email,a.phone, a.gender,a.birthday,a.status,a.create_time,a.create_user, a.modify_time,a.modify_user, b.id as \"card.id\" , b.uid as \"card.uid\", b.card_id as \"card.cardId\", b.address as \"card.address\", b.create_time as \"card.createTime\" , b.modify_time as \"card.modifyTime\" FROM tb_user a INNER JOIN tb_card b on a.id = b.uid where a.id = #{id};&lt;/select&gt; 一对一手动映射手动映射就是通过结果集的方式列进行映射,如下： 123456789101112131415161718192021222324252627282930313233343536373839&lt;resultMap id=\"BaseResultMapWithCard\" type=\"user\"&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;result column=\"user_id\" jdbcType=\"VARCHAR\" property=\"userId\"/&gt; &lt;result column=\"username\" jdbcType=\"VARCHAR\" property=\"username\"/&gt; &lt;result column=\"password\" jdbcType=\"VARCHAR\" property=\"password\"/&gt; &lt;result column=\"email\" jdbcType=\"VARCHAR\" property=\"email\"/&gt; &lt;result column=\"phone\" jdbcType=\"VARCHAR\" property=\"phone\"/&gt; &lt;result column=\"gender\" jdbcType=\"INTEGER\" property=\"gender\"/&gt; &lt;result column=\"birthday\" jdbcType=\"DATE\" property=\"birthday\"/&gt; &lt;result column=\"status\" jdbcType=\"INTEGER\" property=\"status\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"create_user\" jdbcType=\"VARCHAR\" property=\"createUser\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;result column=\"modify_user\" jdbcType=\"VARCHAR\" property=\"modifyUser\"/&gt; &lt;association property=\"card\" javaType=\"card\"&gt; &lt;id column=\"bid\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;result column=\"uid\" jdbcType=\"INTEGER\" property=\"uid\"/&gt; &lt;result column=\"card_id\" jdbcType=\"VARCHAR\" property=\"cardId\"/&gt; &lt;result column=\"address\" jdbcType=\"VARCHAR\" property=\"address\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;/association&gt;&lt;/resultMap&gt;&lt;select id=\"findUserWithCardByUserId\" resultMap=\"BaseResultMapWithCard\"&gt; select a.id,a.user_id,a.username,a.password,a.email,a.phone,a.gender, a.birthday,a.status,a.create_time,a.create_user,a.modify_time,a.modify_user, b.id bid, b.uid, b.card_id, b.address, b.create_time, b.modify_time FROM tb_user a INNER JOIN tb_card b on a.id = b.uid where a.id = #{id}&lt;/select&gt; 通过上述的SQL查询和结果集的手动映射关系，这样就可以实现字段和实体的查询了。 当然，Mybatis还提供下面这种方式来实现： 1234567891011121314151617181920212223242526272829&lt;resultMap id=\"BaseResultMapWithCard\" type=\"user\"&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;result column=\"user_id\" jdbcType=\"VARCHAR\" property=\"userId\"/&gt; &lt;result column=\"username\" jdbcType=\"VARCHAR\" property=\"username\"/&gt; &lt;result column=\"password\" jdbcType=\"VARCHAR\" property=\"password\"/&gt; &lt;result column=\"email\" jdbcType=\"VARCHAR\" property=\"email\"/&gt; &lt;result column=\"phone\" jdbcType=\"VARCHAR\" property=\"phone\"/&gt; &lt;result column=\"gender\" jdbcType=\"INTEGER\" property=\"gender\"/&gt; &lt;result column=\"birthday\" jdbcType=\"DATE\" property=\"birthday\"/&gt; &lt;result column=\"status\" jdbcType=\"INTEGER\" property=\"status\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"create_user\" jdbcType=\"VARCHAR\" property=\"createUser\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;result column=\"modify_user\" jdbcType=\"VARCHAR\" property=\"modifyUser\"/&gt; &lt;association property=\"card\" javaType=\"card\" column=\"id\" select=\"selectCard\"&gt;&lt;/association&gt;&lt;/resultMap&gt;&lt;select id=\"findUserWithCardByUserId\" resultMap=\"BaseResultMapWithCard\"&gt; select a.id,a.user_id,a.username,a.password,a.email,a.phone,a.gender, a.birthday,a.status,a.create_time,a.create_user,a.modify_time,a.modify_user FROM tb_user a where a.id = #{id}&lt;/select&gt;&lt;select id=\"selectCard\" resultType=\"card\"&gt; select * from tb_card where uid = #{id}&lt;/select&gt; 这样的操作其实就是先查询出User的信息，然后在取user表的id字段来查询card表的数据，这样就相当于向MySQL发送了两条SQL，我们通过日志可以观察到现象： ​ 两种方式都可以实现同样地结果，如果需要控制SQL发送条数的话，可以使用关联方式，如果需要在一定程度上降低SQL的查询时间，则可以将其拆分为多个查询SQL。 拓展： 下面我们看一下下面这个SQL如何进行映射，我们假设，一个User有一个主身份证和一个副身份证，那么我们需要如何查询映射： User: 123456789101112131415161718192021222324@NoArgsConstructor@AllArgsConstructor@Getter@Setter@ToStringpublic class User implements Serializable { private Integer id; private String userId; private String username; private String password; private String email; private String phone; private Integer gender; private Date birthday; private Integer status; private Date createTime; private String createUser; private Date modifyTime; private String modifyUser; private Card card;//主 private Card card1;//副} 对应的SQL映射如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;resultMap id=\"BaseResultMapWithCard\" type=\"user\"&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;result column=\"user_id\" jdbcType=\"VARCHAR\" property=\"userId\"/&gt; &lt;result column=\"username\" jdbcType=\"VARCHAR\" property=\"username\"/&gt; &lt;result column=\"password\" jdbcType=\"VARCHAR\" property=\"password\"/&gt; &lt;result column=\"email\" jdbcType=\"VARCHAR\" property=\"email\"/&gt; &lt;result column=\"phone\" jdbcType=\"VARCHAR\" property=\"phone\"/&gt; &lt;result column=\"gender\" jdbcType=\"INTEGER\" property=\"gender\"/&gt; &lt;result column=\"birthday\" jdbcType=\"DATE\" property=\"birthday\"/&gt; &lt;result column=\"status\" jdbcType=\"INTEGER\" property=\"status\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"create_user\" jdbcType=\"VARCHAR\" property=\"createUser\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;result column=\"modify_user\" jdbcType=\"VARCHAR\" property=\"modifyUser\"/&gt; &lt;association property=\"card\" javaType=\"card\" resultMap=\"cardResultMap\" columnPrefix=\"b1_\" /&gt; &lt;association property=\"card1\" javaType=\"card\" resultMap=\"cardResultMap\" columnPrefix=\"b2_\" /&gt;&lt;/resultMap&gt;&lt;resultMap id=\"cardResultMap\" type=\"card\"&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;result column=\"uid\" jdbcType=\"INTEGER\" property=\"uid\"/&gt; &lt;result column=\"card_id\" jdbcType=\"VARCHAR\" property=\"cardId\"/&gt; &lt;result column=\"address\" jdbcType=\"VARCHAR\" property=\"address\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt;&lt;/resultMap&gt;&lt;select id=\"findUserWithCardByUserId\" resultMap=\"BaseResultMapWithCard\" &gt; select a.id,a.user_id,a.username,a.password,a.email,a.phone,a.gender, a.birthday,a.status,a.create_time,a.create_user,a.modify_time,a.modify_user, b1.id b1_id, b1.uid b1_uid, b1.card_id b1_card_id, b1.address b1_address, b1.create_time b1_create_time, b1.modify_time b1_modify_time, b2.id b2_id, b2.uid b2_uid, b2.card_id b2_card_id, b2.address b2_address, b2.create_time b2_create_time, b2.modify_time b2_modify_time from tb_user a inner join tb_card b1 on a.id = b1.uid inner join tb_card b2 on a.id = b2.uid where a.id = 1&lt;/select&gt; ​ ​ 当连接多个表时，我们可能会不得不使用列别名来避免在 ResultSet 中产生重复的列名。指定 association标签的columnPrefix 列名前缀允许你将带有这些前缀的列映射到一个外部的结果映射中。 关联关系一对多12345678910111213141516// 下面是collection标签的各个属性元素property CDATA #REQUIRED 必须，指定的是java实体类的属性名column CDATA 指定的是表的字段名（查询出来的，有可能是字段别名）javaType CDATA 集合一般不使用这个ofType CDATA 属性的java类型，例如：string，integerjdbcType CDATA 数据库的字段类型select CDATA 当我们需要进行嵌套查询的时候，执行另外一个查询语句resultMap CDATA 返回值的映射关typeHandler CDATA 类型处理notNullColumn CDATA columnPrefix CDATA 当我们需要进行区分的时候，可以指定前缀，后面有案例resultSet CDATA foreignColumn CDATA 外键autoMapping (true|false) 是否需要自动映射fetchType (lazy|eager) 是否进行懒加载 ​ 在实际开发中，权限往往是无关业务，但是又是至关重要的一环。在设计权限的时候，我们往往不会讲权限之间与用户之前关联，为了更加好的管理，我们会在用户与权限之间引入一个角色，用角色来统一管理具有相同权限的用户，一般一个用户存在于多个角色，比如即使CEO又是系统开发人员（哈哈），这里就是一个一对多的关系，下面我们看看，在Mybatis中一对多的关系如何映射： User: 12345678910111213141516171819202122@NoArgsConstructor@AllArgsConstructor@Getter@Setter@ToStringpublic class User implements Serializable { private Integer id; private String userId; private String username; private String password; private String email; private String phone; private Integer gender; private Date birthday; private Integer status; private Date createTime; private String createUser; private Date modifyTime; private String modifyUser; private List&lt;Role&gt; roles;} Role: 12345678910111213141516@NoArgsConstructor@AllArgsConstructor@Getter@Setter@ToStringpublic class Role implements Serializable { private Integer id; private String roleName; private String description; private Integer status; private Date createTime; private String createUser; private Date modifyTime; private String modifyUser;} 根据id查询的SQLxml文件： 这里与前面的一对多的关联关系有所不同 ，一对多关联关系使用的是association，java类型使用的是javaType。而多对多关联关系使用的标签是collection，java类型属性使用的是ofType。 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;resultMap id=\"BaseResultWithRole\" type=\"com.ooyhao.mybatis.bean.User\"&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;result column=\"user_id\" jdbcType=\"VARCHAR\" property=\"userId\"/&gt; &lt;result column=\"username\" jdbcType=\"VARCHAR\" property=\"username\"/&gt; &lt;result column=\"password\" jdbcType=\"VARCHAR\" property=\"password\"/&gt; &lt;result column=\"email\" jdbcType=\"VARCHAR\" property=\"email\"/&gt; &lt;result column=\"phone\" jdbcType=\"VARCHAR\" property=\"phone\"/&gt; &lt;result column=\"gender\" jdbcType=\"INTEGER\" property=\"gender\"/&gt; &lt;result column=\"birthday\" jdbcType=\"DATE\" property=\"birthday\"/&gt; &lt;result column=\"status\" jdbcType=\"INTEGER\" property=\"status\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"create_user\" jdbcType=\"VARCHAR\" property=\"createUser\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;result column=\"modify_user\" jdbcType=\"VARCHAR\" property=\"modifyUser\"/&gt; &lt;collection property=\"roles\" ofType=\"role\"&gt; &lt;id column=\"cid\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;result column=\"role_name\" jdbcType=\"VARCHAR\" property=\"roleName\"/&gt; &lt;result column=\"description\" jdbcType=\"VARCHAR\" property=\"description\"/&gt; &lt;result column=\"status\" jdbcType=\"INTEGER\" property=\"status\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"create_user\" jdbcType=\"VARCHAR\" property=\"createUser\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;result column=\"modify_user\" jdbcType=\"VARCHAR\" property=\"modifyUser\"/&gt; &lt;/collection&gt;&lt;/resultMap&gt;&lt;select id=\"findUserWithRolesByUserId\" resultMap=\"BaseResultWithRole\"&gt; select a.id,a.user_id,a.username,a.password,a.email,a.phone,a.gender, a.birthday,a.status,a.create_time,a.create_user,a.modify_time,a.create_user, c.id cid, c.role_name, c.description, c.status, c.create_time, c.create_user, c.modify_time, c.create_user from tb_user a left join tb_user_role b on a.id = b.user_id left join tb_role c on c.id = b.role_id where a.id = #{id}&lt;/select&gt; 测试结果如下： 12345678910111213141516171819202122232425262728293031{ \"birthday\": 1551369600000, \"createTime\": 1551433926000, \"createUser\": \"admin\", \"email\": \"12345678@qq.com\", \"gender\": 1, \"id\": 1, \"modifyTime\": 1551679675000, \"password\": \"admin123456789\", \"phone\": \"12345678901\", \"roles\": [{ \"createTime\": 1551433926000, \"createUser\": \"admin\", \"description\": \"超级管理员\", \"id\": 1, \"modifyTime\": 1551679675000, \"roleName\": \"admin\", \"status\": 0 }, { \"createTime\": 1551433926000, \"createUser\": \"admin\", \"description\": \"开发人员\", \"id\": 2, \"modifyTime\": 1551679675000, \"roleName\": \"develop\", \"status\": 0 }], \"status\": 0, \"userId\": \"oms20190001\", \"username\": \"admin\"} 除了上述方式进行关联查询，我们还可以将SQL进行拆分： 关联嵌套查询： 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;resultMap id=\"BaseResultWithRole\" type=\"com.ooyhao.mybatis.bean.User\"&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;result column=\"user_id\" jdbcType=\"VARCHAR\" property=\"userId\"/&gt; &lt;result column=\"username\" jdbcType=\"VARCHAR\" property=\"username\"/&gt; &lt;result column=\"password\" jdbcType=\"VARCHAR\" property=\"password\"/&gt; &lt;result column=\"email\" jdbcType=\"VARCHAR\" property=\"email\"/&gt; &lt;result column=\"phone\" jdbcType=\"VARCHAR\" property=\"phone\"/&gt; &lt;result column=\"gender\" jdbcType=\"INTEGER\" property=\"gender\"/&gt; &lt;result column=\"birthday\" jdbcType=\"DATE\" property=\"birthday\"/&gt; &lt;result column=\"status\" jdbcType=\"INTEGER\" property=\"status\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"create_user\" jdbcType=\"VARCHAR\" property=\"createUser\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;result column=\"modify_user\" jdbcType=\"VARCHAR\" property=\"modifyUser\"/&gt; &lt;collection property=\"roles\" ofType=\"role\" column=\"id\" select=\"selectRole\" /&gt;&lt;/resultMap&gt;&lt;resultMap id=\"selectRole\" type=\"role\"&gt; &lt;id column=\"cid\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;result column=\"role_name\" jdbcType=\"VARCHAR\" property=\"roleName\"/&gt; &lt;result column=\"description\" jdbcType=\"VARCHAR\" property=\"description\"/&gt; &lt;result column=\"status\" jdbcType=\"INTEGER\" property=\"status\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"create_user\" jdbcType=\"VARCHAR\" property=\"createUser\"/&gt; &lt;result column=\"modify_time\" jdbcType=\"TIMESTAMP\" property=\"modifyTime\"/&gt; &lt;result column=\"modify_user\" jdbcType=\"VARCHAR\" property=\"modifyUser\"/&gt;&lt;/resultMap&gt;&lt;select id=\"findUserWithRolesByUserId\" resultMap=\"BaseResultWithRole\"&gt; select a.id,a.user_id,a.username,a.password,a.email,a.phone,a.gender, a.birthday,a.status,a.create_time,a.create_user,a.modify_time,a.create_user from tb_user a where a.id = #{id}&lt;/select&gt;&lt;select id=\"selectRole\" resultType=\"role\" &gt; select b.* from tb_user_role a left join tb_role b on a.role_id = b.id where a.user_id = #{id}&lt;/select&gt; 注：多对多其实就是双向的一对多关系，不再赘述。 鉴别器摘自官网： 有时候，一个数据库查询可能会返回多个不同的结果集（但总体上还是有一定的联系的）。 鉴别器（discriminator）元素就是被设计来应对这种情况的，另外也能处理其它情况，例如类的继承层次结构。 鉴别器的概念很好理解——它很像 Java 语言中的 switch 语句。 一个鉴别器的定义需要指定 column 和 javaType 属性。column 指定了 MyBatis 查询被比较值的地方。 而 javaType 用来确保使用正确的相等测试（虽然很多情况下字符串的相等测试都可以工作）。例如： 123456789101112131415161718192021222324252627282930313233343536373839&lt;resultMap id=\"vehicleResult\" type=\"Vehicle\"&gt; &lt;id property=\"id\" column=\"id\" /&gt; &lt;result property=\"vin\" column=\"vin\"/&gt; &lt;result property=\"year\" column=\"year\"/&gt; &lt;result property=\"make\" column=\"make\"/&gt; &lt;result property=\"model\" column=\"model\"/&gt; &lt;result property=\"color\" column=\"color\"/&gt; &lt;discriminator javaType=\"int\" column=\"vehicle_type\"&gt; &lt;case value=\"1\" resultMap=\"carResult\"/&gt; &lt;case value=\"2\" resultMap=\"truckResult\"/&gt; &lt;case value=\"3\" resultMap=\"vanResult\"/&gt; &lt;case value=\"4\" resultMap=\"suvResult\"/&gt; &lt;/discriminator&gt;&lt;/resultMap&gt;---------------------------------------也可以这样-----------------------------------------&lt;resultMap id=\"vehicleResult\" type=\"Vehicle\"&gt; &lt;id property=\"id\" column=\"id\" /&gt; &lt;result property=\"vin\" column=\"vin\"/&gt; &lt;result property=\"year\" column=\"year\"/&gt; &lt;result property=\"make\" column=\"make\"/&gt; &lt;result property=\"model\" column=\"model\"/&gt; &lt;result property=\"color\" column=\"color\"/&gt; &lt;discriminator javaType=\"int\" column=\"vehicle_type\"&gt; &lt;case value=\"1\" resultType=\"carResult\"&gt; &lt;result property=\"doorCount\" column=\"door_count\" /&gt; &lt;/case&gt; &lt;case value=\"2\" resultType=\"truckResult\"&gt; &lt;result property=\"boxSize\" column=\"box_size\" /&gt; &lt;result property=\"extendedCab\" column=\"extended_cab\" /&gt; &lt;/case&gt; &lt;case value=\"3\" resultType=\"vanResult\"&gt; &lt;result property=\"powerSlidingDoor\" column=\"power_sliding_door\" /&gt; &lt;/case&gt; &lt;case value=\"4\" resultType=\"suvResult\"&gt; &lt;result property=\"allWheelDrive\" column=\"all_wheel_drive\" /&gt; &lt;/case&gt; &lt;/discriminator&gt;&lt;/resultMap&gt; 提示：请注意，这些都是结果映射，如果你完全不设置任何的 result 元素，MyBatis 将为你自动匹配列和属性。所以上面的例子大多都要比实际的更复杂。 这也表明，大多数数据库的复杂度都比较高，我们不太可能一直依赖于这种机制。 下面通过一个案例来使用一下鉴别器： 数据如下： 我们通过接口的方式来使用鉴别器创建不同的交通工具实体： 123456789101112131415161718192021222324252627282930313233public interface Vehicle {}@NoArgsConstructor@AllArgsConstructor@Getter@Setter@ToStringpublic class Bus implements Vehicle { private Integer id; private String name;}@NoArgsConstructor@AllArgsConstructor@Getter@Setter@ToStringpublic class Car implements Vehicle{ private Integer id; private String name;}@NoArgsConstructor@AllArgsConstructor@Getter@Setter@ToStringpublic class Subway implements Vehicle { private Integer id; private String name;} Sql.xml文件： 123456789101112131415161718&lt;resultMap id=\"BaseResultMap\" type=\"com.ooyhao.mybatis.bean.Vehicle\"&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;discriminator javaType=\"INTEGER\" jdbcType=\"INTEGER\" column=\"vehicle_type\" &gt; &lt;case value=\"1\" resultType=\"car\"&gt; &lt;result property=\"name\" column=\"vehicle_name\" jdbcType=\"VARCHAR\" /&gt; &lt;/case&gt; &lt;case value=\"2\" resultType=\"bus\"&gt; &lt;result property=\"name\" column=\"vehicle_name\" jdbcType=\"VARCHAR\"/&gt; &lt;/case&gt; &lt;case value=\"3\" resultType=\"subway\"&gt; &lt;result property=\"name\" column=\"vehicle_name\" jdbcType=\"VARCHAR\"/&gt; &lt;/case&gt; &lt;/discriminator&gt;&lt;/resultMap&gt;&lt;select id=\"findVehicleById\" resultMap=\"BaseResultMap\"&gt; select * from tb_vehicle where id = #{id}&lt;/select&gt; 在case以外的，就相当于在每一个case中都会存在，而在case中的则是根据条件来选择的。 id为1时： id为3时： 源码地址： https://gitee.com/ooyhao/JavaRepo_Public/tree/master/Mybatis","link":"/2020/01/18/SSM/mybatis/3Mybatis%E6%98%A0%E5%B0%84%E6%96%87%E4%BB%B6/"}],"tags":[{"name":"mybatis","slug":"mybatis","link":"/tags/mybatis/"},{"name":"nacos","slug":"nacos","link":"/tags/nacos/"},{"name":"sentinel","slug":"sentinel","link":"/tags/sentinel/"},{"name":"gateway","slug":"gateway","link":"/tags/gateway/"},{"name":"feign","slug":"feign","link":"/tags/feign/"},{"name":"rabbitmq","slug":"rabbitmq","link":"/tags/rabbitmq/"},{"name":"ribbon","slug":"ribbon","link":"/tags/ribbon/"}],"categories":[{"name":"SSM","slug":"SSM","link":"/categories/SSM/"},{"name":"springcloudbalibaba","slug":"SSM/springcloudbalibaba","link":"/categories/SSM/springcloudbalibaba/"},{"name":"mybatis","slug":"SSM/mybatis","link":"/categories/SSM/mybatis/"},{"name":"中间件","slug":"中间件","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"rabbitmq","slug":"中间件/rabbitmq","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/rabbitmq/"}]}